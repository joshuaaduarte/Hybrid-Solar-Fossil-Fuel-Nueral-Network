{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2cd122d",
   "metadata": {},
   "source": [
    "# Project Two\n",
    "## Pavan M Reddy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d678adb5",
   "metadata": {},
   "source": [
    "## Task 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "230f3090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9900990099009901, 0.896551724137931, 1.009090909090909, 0.9558641975308642], [0.9900990099009901, 1.0, 1.0, 0.9969135802469136], [0.9900990099009901, 1.0551724137931036, 0.9935064935064936, 0.9722222222222222], [1.0, 0.896551724137931, 1.009090909090909, 0.9540123456790124], [0.9900990099009901, 1.0, 1.0, 1.0030864197530864], [0.9900990099009901, 1.0551724137931036, 0.9935064935064936, 0.9691358024691358], [1.188118811881188, 0.896551724137931, 1.009090909090909, 1.098456790123457], [1.7821782178217822, 1.0, 1.0, 1.4320987654320987]]\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.23 0.4 0.7 0.72 0.7\n",
      "-0.15 -0.12 0.01\n",
      "E3 =  0.0023304004322608684 icount = 8\n",
      "next ws: 1.2264341588876744 0.3957113223001962 0.6957952455947807 0.7187347373356996 0.6986778919002751\n",
      "next bs: -0.15420935585818193 -0.123030736217891 0.0078784846474763\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2264341588876744 0.3957113223001962 0.6957952455947807 0.7187347373356996 0.6986778919002751\n",
      "-0.15420935585818193 -0.123030736217891 0.0078784846474763\n",
      "E3 =  0.0011208050823701072 icount = 8\n",
      "next ws: 1.2237307002954811 0.39238966526058233 0.692525663164791 0.7177614507501813 0.6976596251353808\n",
      "next bs: -0.15748125247002986 -0.12538236196979707 0.006235455724596163\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2237307002954811 0.39238966526058233 0.692525663164791 0.7177614507501813 0.6976596251353808\n",
      "-0.15748125247002986 -0.12538236196979707 0.006235455724596163\n",
      "E3 =  0.0005694711971933216 icount = 8\n",
      "next ws: 1.2212760124942954 0.38922634213151786 0.6893831595751246 0.7168561263055452 0.6967132913148046\n",
      "next bs: -0.16062314487088403 -0.12763749121753512 0.004662143098987402\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2212760124942954 0.38922634213151786 0.6893831595751246 0.7168561263055452 0.6967132913148046\n",
      "-0.16062314487088403 -0.12763749121753512 0.004662143098987402\n",
      "E3 =  0.00035176283578148936 icount = 8\n",
      "next ws: 1.2155078523887517 0.3784189811906852 0.6775880837817743 0.7144048000682417 0.6941998145312959\n",
      "next bs: -0.17230251712890143 -0.13600992077209792 -0.0011710398522733981\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2155078523887517 0.3784189811906852 0.6775880837817743 0.7144048000682417 0.6941998145312959\n",
      "-0.17230251712890143 -0.13600992077209792 -0.0011710398522733981\n",
      "E3 =  0.0016797078268747107 icount = 8\n",
      "next ws: 1.2189392309467209 0.3822045801977516 0.6812466781789995 0.7156107060068335 0.6954841484028559\n",
      "next bs: -0.16863484339962156 -0.1333897170548162 0.0006479050822977917\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2189392309467209 0.3822045801977516 0.6812466781789995 0.7156107060068335 0.6954841484028559\n",
      "-0.16863484339962156 -0.1333897170548162 0.0006479050822977917\n",
      "E3 =  0.0008216333952222394 icount = 8\n",
      "next ws: 1.2218425714150614 0.3852945947715687 0.684217359081142 0.7166098045509699 0.6965480734788105\n",
      "next bs: -0.16565529842974683 -0.13125752277534503 0.0021308124049852425\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2218425714150614 0.3852945947715687 0.684217359081142 0.7166098045509699 0.6965480734788105\n",
      "-0.16565529842974683 -0.13125752277534503 0.0021308124049852425\n",
      "E3 =  0.00044417137698123886 icount = 8\n",
      "next ws: 1.2258282164520131 0.38905132425794764 0.6877709068984224 0.7179003895621714 0.6979302575789561\n",
      "next bs: -0.16208569321927208 -0.1286995086831426 0.0039125921928405034\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2258282164520131 0.38905132425794764 0.6877709068984224 0.7179003895621714 0.6979302575789561\n",
      "-0.16208569321927208 -0.1286995086831426 0.0039125921928405034\n",
      "E3 =  0.00039430050380493987 icount = 8\n",
      "next ws: 1.222086315201817 0.3832698487284558 0.681831771573015 0.7164149881793634 0.6963896171029743\n",
      "next bs: -0.1680040391981293 -0.13294829156692792 0.0009472380603631567\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.222086315201817 0.3832698487284558 0.681831771573015 0.7164149881793634 0.6963896171029743\n",
      "-0.1680040391981293 -0.13294829156692792 0.0009472380603631567\n",
      "E3 =  0.0006022902727817152 icount = 8\n",
      "next ws: 1.225149615306589 0.3863969185693395 0.6848230425535159 0.7174480624620733 0.697492103547914\n",
      "next bs: -0.16500243125907924 -0.13079789465075428 0.0024447521454367327\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.225149615306589 0.3863969185693395 0.6848230425535159 0.7174480624620733 0.697492103547914\n",
      "-0.16500243125907924 -0.13079789465075428 0.0024447521454367327\n",
      "E3 =  0.00037283618711337794 icount = 8\n",
      "next ws: 1.2436775756477836 0.3955471368447029 0.6930248357695544 0.7216212203699761 0.7021451631882852\n",
      "next bs: -0.1567231555895225 -0.12485794436304141 0.006587820566583621\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2436775756477836 0.3955471368447029 0.6930248357695544 0.7216212203699761 0.7021451631882852\n",
      "-0.1567231555895225 -0.12485794436304141 0.006587820566583621\n",
      "E3 =  0.002199294216083167 icount = 8\n",
      "next ws: 1.2402052077061227 0.39130090864283246 0.688860053754281 0.7203773193762014 0.7008415806319326\n",
      "next bs: -0.16089239071003572 -0.12786655289871554 0.004475340635333047\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2402052077061227 0.39130090864283246 0.688860053754281 0.7203773193762014 0.7008415806319326\n",
      "-0.16089239071003572 -0.12786655289871554 0.004475340635333047\n",
      "E3 =  0.001068342247457052 icount = 8\n",
      "next ws: 1.2375033631666228 0.38788616111745433 0.685495641928551 0.719391272086396 0.6998076567725898\n",
      "next bs: -0.16425894571504246 -0.13029174276875483 0.0027756667334821565\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2375033631666228 0.38788616111745433 0.685495641928551 0.719391272086396 0.6998076567725898\n",
      "-0.16425894571504246 -0.13029174276875483 0.0027756667334821565\n",
      "E3 =  0.0005591840629772685 icount = 8\n",
      "next ws: 1.2348043736383252 0.38417317002563217 0.6817917537794155 0.7183689384812942 0.6987388403405326\n",
      "next bs: -0.1679607705780251 -0.13295480326597695 0.0009120366070774876\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2348043736383252 0.38417317002563217 0.6817917537794155 0.7183689384812942 0.6987388403405326\n",
      "-0.1679607705780251 -0.13295480326597695 0.0009120366070774876\n",
      "E3 =  0.0003991424095178773 icount = 8\n",
      "next ws: 1.1830706842822987 0.40277043178621363 0.6973441941364044 0.742321916118297 0.7369833982752259\n",
      "next bs: -0.15216976822198802 -0.12161103766591498 0.008838366227559609\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.1830706842822987 0.40277043178621363 0.6973441941364044 0.742321916118297 0.7369833982752259\n",
      "-0.15216976822198802 -0.12161103766591498 0.008838366227559609\n",
      "E3 =  0.012064893122949543 icount = 8\n",
      "next ws: 1.175958793077181 0.3943435536005123 0.6891112148026566 0.7396744731962283 0.7341545274570819\n",
      "next bs: -0.16041465032533794 -0.12773139434704314 0.004327764962045294\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.175958793077181 0.3943435536005123 0.6891112148026566 0.7396744731962283 0.7341545274570819\n",
      "-0.16041465032533794 -0.12773139434704314 0.004327764962045294\n",
      "E3 =  0.0056459258537032994 icount = 8\n",
      "next ws: 1.17099864835171 0.3884046351825693 0.683300317457445 0.7377995113482512 0.7321421650835188\n",
      "next bs: -0.16623313574449325 -0.13203517948425678 0.0011681216183574042\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.17099864835171 0.3884046351825693 0.683300317457445 0.7377995113482512 0.7321421650835188\n",
      "-0.16623313574449325 -0.13203517948425678 0.0011681216183574042\n",
      "E3 =  0.0026633665855129727 icount = 8\n",
      "next ws: 1.167461058938615 0.38409875322812126 0.6790772183385893 0.7364425129895482 0.7306818802100499\n",
      "next bs: -0.17046080228550978 -0.13515434979236213 -0.001115554484283074\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.167461058938615 0.38409875322812126 0.6790772183385893 0.7364425129895482 0.7306818802100499\n",
      "-0.17046080228550978 -0.13515434979236213 -0.001115554484283074\n",
      "E3 =  0.001283238587839526 icount = 8\n",
      "next ws: 1.164777052129941 0.3807370901090618 0.6757661798942247 0.7353947561742071 0.7295533885823193\n",
      "next bs: -0.1737740952126002 -0.1375943995618591 -0.0028984546376652244\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.164777052129941 0.3807370901090618 0.6757661798942247 0.7353947561742071 0.7295533885823193\n",
      "-0.1737740952126002 -0.1375943995618591 -0.0028984546376652244\n",
      "E3 =  0.000655254128778413 icount = 8\n",
      "next ws: 1.1623227006167953 0.3774563681322022 0.6725018589606904 0.7344068474244198 0.7284915428538334\n",
      "next bs: -0.17703748561440674 -0.13999427975069687 -0.004649295361623389\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.1623227006167953 0.3774563681322022 0.6725018589606904 0.7344068474244198 0.7284915428538334\n",
      "-0.17703748561440674 -0.13999427975069687 -0.004649295361623389\n",
      "E3 =  0.00041378582851962943 icount = 8\n",
      "next ws: 1.155985870259448 0.3614102647982093 0.6538385595896244 0.7312594578674627 0.7252241343416739\n",
      "next bs: -0.19539935388745774 -0.15347936154193073 -0.014473063401229487\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.155985870259448 0.3614102647982093 0.6538385595896244 0.7312594578674627 0.7252241343416739\n",
      "-0.19539935388745774 -0.15347936154193073 -0.014473063401229487\n",
      "E3 =  0.003872292257304887 icount = 8\n",
      "next ws: 1.1605712263572872 0.36648530129985607 0.6587548335328186 0.7330145288522137 0.7271629310095135\n",
      "next bs: -0.19047208229845083 -0.14987624759098778 -0.011859998205222474\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.1605712263572872 0.36648530129985607 0.6587548335328186 0.7330145288522137 0.7271629310095135\n",
      "-0.19047208229845083 -0.14987624759098778 -0.011859998205222474\n",
      "E3 =  0.0018380946987153924 icount = 8\n",
      "next ws: 1.1640486624161233 0.37022809632953346 0.6623693908361727 0.7343203399435307 0.728603077107352\n",
      "next bs: -0.1868484143678162 -0.14722004635009675 -0.009928507125545057\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.1640486624161233 0.37022809632953346 0.6623693908361727 0.7343203399435307 0.728603077107352\n",
      "-0.1868484143678162 -0.14722004635009675 -0.009928507125545057\n",
      "E3 =  0.0009101291070356737 icount = 8\n",
      "next ws: 1.1671769918035626 0.3734037514052771 0.6654174682089989 0.7354590370884613 0.7298607949620566\n",
      "next bs: -0.18379093841875982 -0.14497487957181648 -0.008292671702270858\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.1671769918035626 0.3734037514052771 0.6654174682089989 0.7354590370884613 0.7298607949620566\n",
      "-0.18379093841875982 -0.14497487957181648 -0.008292671702270858\n",
      "E3 =  0.0005137693796898051 icount = 8\n",
      "next ws: 1.1732783908661468 0.37812679193722737 0.6698443952638018 0.7373976820964104 0.7320390189022836\n",
      "next bs: -0.17934084365987 -0.14170201716549097 -0.00590393774458868\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.1732783908661468 0.37812679193722737 0.6698443952638018 0.7373976820964104 0.7320390189022836\n",
      "-0.17934084365987 -0.14170201716549097 -0.00590393774458868\n",
      "E3 =  0.0006672260752738724 icount = 8\n",
      "next ws: 1.170623771143426 0.37440279314749714 0.6661279788035627 0.7363060030050412 0.7308653837764308\n",
      "next bs: -0.18305527891542384 -0.14444103311323356 -0.007909004291731879\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.170623771143426 0.37440279314749714 0.6661279788035627 0.7363060030050412 0.7308653837764308\n",
      "-0.18305527891542384 -0.14444103311323356 -0.007909004291731879\n",
      "E3 =  0.0004667491637744217 icount = 8\n",
      "next ws: 1.1498686665623672 0.3999735756224973 0.6863063486166414 0.6945787805099609 0.7039764821493603\n",
      "next bs: -0.1624821206006896 -0.12929289314532164 0.0031622468394151525\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.1498686665623672 0.3999735756224973 0.6863063486166414 0.6945787805099609 0.7039764821493603\n",
      "-0.1624821206006896 -0.12929289314532164 0.0031622468394151525\n",
      "E3 =  0.00403742445952513 icount = 8\n",
      "next ws: 1.1546358806731771 0.405531131846702 0.6916907470037065 0.6962707020028446 0.7058485935096488\n",
      "next bs: -0.1570855210968272 -0.12554452964302823 0.005801006591576717\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.1546358806731771 0.405531131846702 0.6916907470037065 0.6962707020028446 0.7058485935096488\n",
      "-0.1570855210968272 -0.12554452964302823 0.005801006591576717\n",
      "E3 =  0.0018923786517418835 icount = 8\n",
      "next ws: 1.1580286943996592 0.40949680179073666 0.6955219432941673 0.6974665855456641 0.7071672492020082\n",
      "next bs: -0.1532445557113491 -0.12287017797771277 0.007688693953089819\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.1580286943996592 0.40949680179073666 0.6955219432941673 0.6974665855456641 0.7071672492020082\n",
      "-0.1532445557113491 -0.12287017797771277 0.007688693953089819\n",
      "E3 =  0.0009071131971644992 icount = 8\n",
      "next ws: 1.1606263892893292 0.41254721074540435 0.6984542362276424 0.6983781567341151 0.7081699959108821\n",
      "next bs: -0.15030332927739684 -0.12081877081950744 0.009139381910151193\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.1606263892893292 0.41254721074540435 0.6984542362276424 0.6983781567341151 0.7081699959108821\n",
      "-0.15030332927739684 -0.12081877081950744 0.009139381910151193\n",
      "E3 =  0.000460595137093609 icount = 8\n",
      "next ws: 1.1630778885373607 0.41545711694896326 0.7012193472321739 0.699236459210893 0.7091125013528717\n",
      "next bs: -0.1475266383815076 -0.11887959054981592 0.010512651193809102\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.1630778885373607 0.41545711694896326 0.7012193472321739 0.699236459210893 0.7091125013528717\n",
      "-0.1475266383815076 -0.11887959054981592 0.010512651193809102\n",
      "E3 =  0.00028667222349910103 icount = 8\n",
      "next ws: 1.1714705245646795 0.42659672234586804 0.7106162005062585 0.7022114366360884 0.7123769875766794\n",
      "next bs: -0.13798550767907175 -0.11220808410057635 0.015243499819821189\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.1630778885373607 0.41545711694896326 0.7012193472321739 0.699236459210893 0.7091125013528717\n",
      "-0.1475266383815076 -0.11887959054981592 0.010512651193809102\n",
      "Tdbin, Twbin, qdot, Tdbout, ypredicted:\n",
      "20.0 13.0 310.8 30.97 31.090793913544566\n",
      "20.0 14.5 308.0 32.3 31.678835486931895\n",
      "20.0 15.3 306.0 31.5 31.973926195676942\n",
      "20.2 13.0 310.8 30.91 31.27579387700364\n",
      "20.0 14.5 308.0 32.5 31.678835486931895\n",
      "20.0 15.3 306.0 31.4 31.973926195676942\n",
      "24.0 13.0 310.8 35.59 34.79079318272606\n",
      "36.0 14.5 308.0 46.4 46.47883256365786\n",
      "Stored 'Y3_FP' (list)\n"
     ]
    }
   ],
   "source": [
    "'''#Intro to Neural Network Modeling \n",
    "# Python Neural Network Model of Spray Cooling Test System\n",
    "\n",
    ">>>>> start CodeP2.1F22\n",
    "    V.P. Carey, ME249, Fall 2022'''\n",
    "\n",
    "# version 3 print function\n",
    "from __future__ import print_function\n",
    "\n",
    "# import math, numpy and other usefuk packages\n",
    "import math\n",
    "import numpy \n",
    "\n",
    "%matplotlib inline\n",
    "# importing the required module \n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.figsize'] = [10, 8] # for square canvas\n",
    "\n",
    "\n",
    "#assembling data array\n",
    "#store array where rows are data vectors [x01, x02, x03, y3]\n",
    "xydata = []\n",
    "\n",
    "xydata = [[20./20.2, 13.0/14.5, 310.8/308.0, 30.97/32.4], [20./20.2, 14.5/14.5, 308.0/308.0, 32.3/32.4]]\n",
    "xydata.append([20./20.2, 15.3/14.5, 306.0/308.0, 31.5/32.4])\n",
    "xydata.append([20.2/20.2, 13.0/14.5, 310.8/308.0, 30.91/32.4]) \n",
    "xydata.append([20./20.2, 14.5/14.5, 308.0/308.0, 32.5/32.4]) \n",
    "xydata.append([20./20.2, 15.3/14.5, 306.0/308.0, 31.4/32.4]) \n",
    "xydata.append([24./20.2, 13.0/14.5, 310.8/308.0, 35.59/32.4]) \n",
    "xydata.append([36./20.2, 14.5/14.5, 308.0/308.0, 46.4/32.4]) \n",
    "print (xydata)\n",
    "\n",
    "#set starting values \n",
    "w01n =  1.23 \n",
    "w02n =  0.40 \n",
    "w03n =  0.70\n",
    "b1n =  -0.15\n",
    "w12n =  0.72\n",
    "b2n =  -0.12\n",
    "w23n =  0.7\n",
    "b3n =  0.01\n",
    "\n",
    "#start of batch loop  \n",
    "\n",
    "for k in range (0,200):\n",
    "    icount = 0\n",
    "    #initialize error and derivative parameters\n",
    "    E3ti = 0.\n",
    "    dE3da3 = 0.\n",
    "    dE3dw01ti = 0.\n",
    "    dE3dw02ti = 0.\n",
    "    dE3dw03ti = 0.\n",
    "    dE3db1ti = 0.\n",
    "    dE3dw12ti = 0.\n",
    "    dE3db2ti = 0.\n",
    "    dE3dw23ti = 0.\n",
    "    dE3db3ti = 0.\n",
    " \n",
    "    w01 = w01n \n",
    "    w02 = w02n\n",
    "    w03 = w03n\n",
    "    b1 = b1n \n",
    "    w12 = w12n\n",
    "    b2 = b2n \n",
    "    w23 = w23n \n",
    "    b3 = b3n \n",
    "    \n",
    "    #doing calcuations for each data point \n",
    "    for i in range(0,8):\n",
    "        #compute activation functions and their derivatives\n",
    "        z1 = w01*xydata[i][0]+w02*xydata[i][1]+w03*xydata[i][2]+b1 \n",
    "        sig1 = z1\n",
    "        sigp1 = 1.0\n",
    "        if z1 < 0.0:\n",
    "            sig1 = math.exp(z1) - 1.0\n",
    "            sigp1 = math.exp(z1)\n",
    "        a1 = sig1\n",
    "\n",
    "        z2 = w12*a1+b2 \n",
    "        sig2 = z2\n",
    "        sigp2 = 1.0\n",
    "        if z2 < 0.0:\n",
    "            sig2 = math.exp(z2) - 1.0\n",
    "            sigp2 = math.exp(z2)\n",
    "        a2 = sig2\n",
    "\n",
    "        z3 = w23*a2+b3 \n",
    "        sig3 = z3\n",
    "        sigp3 = 1.0\n",
    "        if z3 < 0.0:\n",
    "            sig3 = math.exp(z3) - 1.0\n",
    "            sigp3 = math.exp(z3)\n",
    "        a3 = sig3\n",
    "        \n",
    "        \n",
    "        #compute derivatives for backpropagation\n",
    "        #add to sum for batch average calculation\n",
    "        E3ti = E3ti +(a3 - xydata[i][3])*(a3 - xydata[i][3])\n",
    "        dE3da3 = 2.*(a3 - xydata[i][3])\n",
    "        \n",
    "        dE3dw01ti = dE3dw01ti + dE3da3*sigp3*w23*sigp2*w12*sigp1*xydata[i][0]\n",
    "        dE3dw02ti = dE3dw02ti + dE3da3*sigp3*w23*sigp2*w12*sigp1*xydata[i][1]\n",
    "        dE3dw03ti = dE3dw03ti + dE3da3*sigp3*w23*sigp2*w12*sigp1*xydata[i][2]\n",
    "        dE3db1ti = dE3db1ti + dE3da3*sigp3*w23*sigp2*w12*sigp1\n",
    "        \n",
    "        dE3dw12ti = dE3dw12ti + dE3da3*sigp3*w23*sigp2*a1\n",
    "        dE3db2ti = dE3db2ti + dE3da3*sigp3*w23*sigp2\n",
    "        \n",
    "        dE3dw23ti = dE3dw23ti + dE3da3*sigp3*a2\n",
    "        dE3db3ti = dE3db3ti + dE3da3*sigp3\n",
    "        \n",
    "        icount = i + 1\n",
    "        # end  calculations for each data point in batch\n",
    "        \n",
    "    #compute batch averaged values\n",
    "    E3 = E3ti/icount\n",
    "    dE3dw01 = dE3dw01ti/icount\n",
    "    dE3dw02 = dE3dw02ti/icount\n",
    "    dE3dw03 = dE3dw03ti/icount\n",
    "    dE3db1 = dE3db1ti/icount\n",
    "    dE3dw12 = dE3dw12ti/icount\n",
    "    dE3db2 = dE3db2ti/icount\n",
    "    dE3dw23 = dE3dw23ti/icount\n",
    "    dE3db3 = dE3db3ti/icount\n",
    "    \n",
    "    #set gam = learning rate\n",
    "    gam = 0.165\n",
    "    if E3 < 0.07: \n",
    "        gam = 0.08\n",
    "\n",
    "    w01n = w01 + gam*(-E3)/dE3dw01\n",
    "    w02n = w02 + gam*(-E3)/dE3dw02\n",
    "    w03n = w03 + gam*(-E3)/dE3dw03\n",
    "    b1n = b1 + gam*(-E3)/dE3db1\n",
    "    w12n = w12 + gam*(-E3)/dE3dw12\n",
    "    b2n = b2 + gam*(-E3)/dE3db2\n",
    "    \n",
    "    w23n = w23 + gam*(-E3)/dE3dw23\n",
    "    b3n = b3 + gam*(-E3)/dE3db3\n",
    "    \n",
    "    #printing for each iteration\n",
    "    print ('last w01, w02, w03, w12, w23:')\n",
    "    print ('last b1, b2, b3:')\n",
    "    print (w01, w02, w03, w12, w23)\n",
    "    print (b1, b2, b3)\n",
    "    print ('E3 = ', E3, 'icount =', icount)\n",
    "    print ('next ws:', w01n, w02n, w03n, w12n, w23n)\n",
    "    print ('next bs:', b1n, b2n, b3n)\n",
    "    \n",
    "    #quit if squared error is below target\n",
    "    if E3 < 0.00035:\n",
    "        break\n",
    "    \n",
    "\n",
    "print ('last w01, w02, w03, w12, w23:')\n",
    "print ('last b1, b2, b3:')\n",
    "print (w01, w02, w03, w12, w23)\n",
    "print (b1, b2, b3)\n",
    "#decomment print statements below if you want to print neuron outputs\n",
    "#print ('z1 =', z1)\n",
    "#print ('a1 =', a1)\n",
    "#print ('z2 =', z2)\n",
    "#print ('a2 =', a2)\n",
    "#print ('z3 =', z3)\n",
    "#print ('a3 =', a3)\n",
    "\n",
    "#print comparison of data and trained network predictions\n",
    "# restore raw data values  \n",
    "xydatar = [[20., 13.0, 310.8, 30.97], [20., 14.5, 308.0, 32.3]]\n",
    "xydatar.append([20., 15.3, 306.0, 31.5])\n",
    "xydatar.append([20.2, 13.0, 310.8, 30.91]) \n",
    "xydatar.append([20., 14.5, 308.0, 32.5]) \n",
    "xydatar.append([20., 15.3, 306.0, 31.4]) \n",
    "xydatar.append([24., 13.0, 310.8, 35.59]) \n",
    "xydatar.append([36., 14.5, 308.0, 46.4])\n",
    "print ('Tdbin, Twbin, qdot, Tdbout, ypredicted:')\n",
    "Y3_FP = []\n",
    "for i in range(0,8): \n",
    "    z1 = w01*xydata[i][0]+w02*xydata[i][1]+w03*xydata[i][2]+b1 \n",
    "    sig1 = z1\n",
    "    sigp1 = 1.0\n",
    "    if z1 < 0.0:\n",
    "        sig1 = math.exp(z1) - 1.0\n",
    "        sigp1 = math.exp(z1)\n",
    "    a1 = sig1\n",
    "\n",
    "    z2 = w12*a1+b2 \n",
    "    sig2 = z2\n",
    "    sigp2 = 1.0\n",
    "    if z2 < 0.0:\n",
    "        sig2 = math.exp(z2) - 1.0\n",
    "        sigp2 = math.exp(z2)\n",
    "    a2 = sig2\n",
    "\n",
    "    z3 = w23*a2+b3 \n",
    "    sig3 = z3\n",
    "    sigp3 = 1.0\n",
    "    if z3 < 0.0:\n",
    "        sig3 = math.exp(z3) - 1.0\n",
    "        sigp3 = math.exp(z3)\n",
    "    a3 = sig3\n",
    "\n",
    "    print (xydatar[i][0], xydatar[i][1], xydatar[i][2], xydatar[i][3], a3*32.4)\n",
    "    Y3_FP.append(a3*32.4)\n",
    "%store Y3_FP\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e738a",
   "metadata": {},
   "source": [
    "## Task 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d892719d",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece8f3e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.990099\n",
      "1    0.990099\n",
      "2    0.990099\n",
      "3    1.000000\n",
      "4    0.990099\n",
      "5    1.000000\n",
      "6    1.188119\n",
      "7    1.782178\n",
      "Name: x01, dtype: float64 0    0.896552\n",
      "1    1.000000\n",
      "2    1.055172\n",
      "3    0.896552\n",
      "4    1.000000\n",
      "5    1.055172\n",
      "6    0.896552\n",
      "7    1.000000\n",
      "Name: x02, dtype: float64 0    1.009091\n",
      "1    1.000000\n",
      "2    0.993506\n",
      "3    1.009091\n",
      "4    1.000000\n",
      "5    0.993506\n",
      "6    1.009091\n",
      "7    1.000000\n",
      "Name: x03, dtype: float64 0    0.955835\n",
      "1    0.996883\n",
      "2    0.972192\n",
      "3    0.953983\n",
      "4    1.003055\n",
      "5    0.969106\n",
      "6    1.098423\n",
      "7    1.432055\n",
      "Name: y3, dtype: float64\n",
      "[[0.9900990099009901, 0.896551724137931, 1.009090909090909], [0.9900990099009901, 1.0, 1.0], [0.9900990099009901, 1.0551724137931036, 0.9935064935064936], [1.0, 0.896551724137931, 1.009090909090909], [0.9900990099009901, 1.0, 1.0], [1.0, 1.0551724137931036, 0.9935064935064936], [1.188118811881188, 0.896551724137931, 1.009090909090909], [1.7821782178217822, 1.0, 1.0]]\n",
      "[[0.99009901 0.89655172 1.00909091]\n",
      " [0.99009901 1.         1.        ]\n",
      " [0.99009901 1.05517241 0.99350649]\n",
      " [1.         0.89655172 1.00909091]\n",
      " [0.99009901 1.         1.        ]\n",
      " [1.         1.05517241 0.99350649]\n",
      " [1.18811881 0.89655172 1.00909091]\n",
      " [1.78217822 1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "'''>>>>> start CodeP2.2F22\n",
    "    V.P. Carey ME249, Fall 2022\n",
    "\n",
    "Intro to Neural Network Modeling \n",
    "Keras model for comparison with first principles model'''\n",
    "\n",
    "#import useful packages\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#raw data in dictionary form x01, x02, x03, y3\n",
    "my_dict = { \n",
    "    'x01' : [20., 20., 20., 20.2, 20., 20.2, 24.0, 36.],\n",
    "    'x02' : [13., 14.5, 15.3, 13., 14.5, 15.3, 13., 14.5],\n",
    "    'x03' : [310.8, 308.0, 306.0, 310.8, 308.0, 306.0, 310.8, 308.0],\n",
    "    'y3' : [30.97, 32.3, 31.5, 30.91, 32.5, 31.4, 35.59, 46.4]\n",
    "}\n",
    "#normalized inputs in array\n",
    "xdata = []\n",
    "xdata = [[20./20.2, 13.0/14.5, 310.8/308.0], [20./20.2, 14.5/14.5, 308.0/308.0]] \n",
    "xdata.append([20./20.2, 15.3/14.5, 306.0/308.0])\n",
    "xdata.append([20.2/20.2, 13.0/14.5, 310.8/308.0]) \n",
    "xdata.append([20./20.2, 14.5/14.5, 308.0/308.0]) \n",
    "xdata.append([20.2/20.2, 15.3/14.5, 306.0/308.0]) \n",
    "xdata.append([24./20.2, 13.0/14.5, 310.8/308.0]) \n",
    "xdata.append([36./20.2, 14.5/14.5, 308.0/308.0]) \n",
    "\n",
    "#data frame\n",
    "df = pd.DataFrame(my_dict)\n",
    "#devide by the median to normalize \n",
    "df.x01= df.x01/20.2\n",
    "df.x02= df.x02/14.5\n",
    "df.x03= df.x03/308.0\n",
    "#normalize output array\n",
    "df.y3= df.y3/32.401\n",
    "df.head\n",
    "print (df.x01, df.x02, df.x03, df.y3)\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "print (xdata)\n",
    "print (xarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2016a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "Weights and biases of the layers before training the model: \n",
      "\n",
      "dense_one\n",
      "Weights\n",
      "Shape:  (3, 1) \n",
      " [[1.23]\n",
      " [0.4 ]\n",
      " [0.7 ]]\n",
      "Bias\n",
      "Shape:  (1,) \n",
      " [-0.15] \n",
      "\n",
      "dense_two\n",
      "Weights\n",
      "Shape:  (1, 1) \n",
      " [[0.72]]\n",
      "Bias\n",
      "Shape:  (1,) \n",
      " [-0.12] \n",
      "\n",
      "dense_three\n",
      "Weights\n",
      "Shape:  (1, 1) \n",
      " [[0.7]]\n",
      "Bias\n",
      "Shape:  (1,) \n",
      " [0.01] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x7fe4f8eb3e90>,\n",
       " <keras.layers.core.Dense at 0x7fe4f8eb3710>,\n",
       " <keras.layers.core.Dense at 0x7fe4f8eb3250>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "#As seen below, we have created three dense layers each with just one neuron. \n",
    "#A dense layer is a layer in neural network that’s fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 3 in this case. \n",
    "#The activation function we have chosen is ReLU, which stands for rectified linear unit.\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 1.2\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=1.2)\n",
    "\n",
    "# define three layer model with one neuron in each layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, activation=K.elu, input_shape=[3],  kernel_initializer=initializer, name=\"dense_one\"),\n",
    "    keras.layers.Dense(1, activation=K.elu,  kernel_initializer=initializer, name=\"dense_two\"),\n",
    "    keras.layers.Dense(1, activation=K.elu,  kernel_initializer=initializer, name=\"dense_three\")\n",
    "  ])\n",
    "\n",
    "\n",
    "#set starting values to those used in first principles model\n",
    "w01n =  1.23 \n",
    "w02n =  0.40 \n",
    "w03n =  0.70\n",
    "b1n =  -0.15\n",
    "w12n =  0.72\n",
    "b2n =  -0.12\n",
    "w23n =  0.7\n",
    "b3n =  0.01\n",
    "\n",
    "weights0 =  [[ w01n], [w02n], [ w03n]]\n",
    "w0array= np.array(weights0)\n",
    "print(np.shape(w0array))\n",
    "bias0 = [b1n]\n",
    "bias0array= np.array(bias0)\n",
    "L0=[]\n",
    "L0.append(w0array)\n",
    "L0.append(bias0array)\n",
    "model.layers[0].set_weights(L0) \n",
    "\n",
    "weights1 =  [[ w12n]]\n",
    "w1array= np.array(weights1)\n",
    "print(np.shape(w1array))\n",
    "bias1 = [b2n]\n",
    "bias1array= np.array(bias1)\n",
    "L1=[]\n",
    "L1.append(w1array)\n",
    "L1.append(bias1array)\n",
    "model.layers[1].set_weights(L1)\n",
    "\n",
    "weights2 =  [[ w23n]]\n",
    "w2array= np.array(weights2)\n",
    "print(np.shape(w2array))\n",
    "bias2 = [b3n]\n",
    "bias2array= np.array(bias2)\n",
    "L2=[]\n",
    "L2.append(w2array)\n",
    "L2.append(bias2array)\n",
    "model.layers[2].set_weights(L2)\n",
    "\n",
    "\n",
    "print(\"Weights and biases of the layers before training the model: \\n\")\n",
    "for layer in model.layers:\n",
    "  print(layer.name)\n",
    "  print(\"Weights\")\n",
    "  print(\"Shape: \",layer.get_weights()[0].shape,'\\n',layer.get_weights()[0])\n",
    "  print(\"Bias\")\n",
    "  print(\"Shape: \",layer.get_weights()[1].shape,'\\n',layer.get_weights()[1],'\\n')\n",
    "model.layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c487a908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean absolute error. After the compilation of the model, we’ll use the fit method with 100 epochs.\n",
    "\n",
    "#Running model.fit successive times extends the calculation to addtional epochs.\n",
    "\n",
    "rms = keras.optimizers.RMSprop(0.00035)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4691dfee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "8/8 [==============================] - 0s 535us/step - loss: 0.0142\n",
      "Epoch 2/400\n",
      "8/8 [==============================] - 0s 167us/step - loss: 0.0143\n",
      "Epoch 3/400\n",
      "8/8 [==============================] - 0s 178us/step - loss: 0.0143\n",
      "Epoch 4/400\n",
      "8/8 [==============================] - 0s 173us/step - loss: 0.0142\n",
      "Epoch 5/400\n",
      "8/8 [==============================] - 0s 155us/step - loss: 0.0143\n",
      "Epoch 6/400\n",
      "8/8 [==============================] - 0s 187us/step - loss: 0.0142\n",
      "Epoch 7/400\n",
      "8/8 [==============================] - 0s 181us/step - loss: 0.0143\n",
      "Epoch 8/400\n",
      "8/8 [==============================] - 0s 149us/step - loss: 0.0143\n",
      "Epoch 9/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0142\n",
      "Epoch 10/400\n",
      "8/8 [==============================] - 0s 155us/step - loss: 0.0143\n",
      "Epoch 11/400\n",
      "8/8 [==============================] - 0s 159us/step - loss: 0.0142\n",
      "Epoch 12/400\n",
      "8/8 [==============================] - 0s 153us/step - loss: 0.0143\n",
      "Epoch 13/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0143\n",
      "Epoch 14/400\n",
      "8/8 [==============================] - 0s 142us/step - loss: 0.0142\n",
      "Epoch 15/400\n",
      "8/8 [==============================] - 0s 147us/step - loss: 0.0143\n",
      "Epoch 16/400\n",
      "8/8 [==============================] - 0s 162us/step - loss: 0.0142\n",
      "Epoch 17/400\n",
      "8/8 [==============================] - 0s 169us/step - loss: 0.0143\n",
      "Epoch 18/400\n",
      "8/8 [==============================] - 0s 191us/step - loss: 0.0143\n",
      "Epoch 19/400\n",
      "8/8 [==============================] - 0s 134us/step - loss: 0.0142\n",
      "Epoch 20/400\n",
      "8/8 [==============================] - 0s 145us/step - loss: 0.0143\n",
      "Epoch 21/400\n",
      "8/8 [==============================] - 0s 145us/step - loss: 0.0142\n",
      "Epoch 22/400\n",
      "8/8 [==============================] - 0s 126us/step - loss: 0.0143\n",
      "Epoch 23/400\n",
      "8/8 [==============================] - 0s 116us/step - loss: 0.0143\n",
      "Epoch 24/400\n",
      "8/8 [==============================] - 0s 150us/step - loss: 0.0142\n",
      "Epoch 25/400\n",
      "8/8 [==============================] - 0s 158us/step - loss: 0.0143\n",
      "Epoch 26/400\n",
      "8/8 [==============================] - 0s 164us/step - loss: 0.0142\n",
      "Epoch 27/400\n",
      "8/8 [==============================] - 0s 161us/step - loss: 0.0143\n",
      "Epoch 28/400\n",
      "8/8 [==============================] - 0s 164us/step - loss: 0.0143\n",
      "Epoch 29/400\n",
      "8/8 [==============================] - 0s 194us/step - loss: 0.0142\n",
      "Epoch 30/400\n",
      "8/8 [==============================] - 0s 152us/step - loss: 0.0143\n",
      "Epoch 31/400\n",
      "8/8 [==============================] - 0s 163us/step - loss: 0.0142\n",
      "Epoch 32/400\n",
      "8/8 [==============================] - 0s 164us/step - loss: 0.0143\n",
      "Epoch 33/400\n",
      "8/8 [==============================] - 0s 158us/step - loss: 0.0142\n",
      "Epoch 34/400\n",
      "8/8 [==============================] - 0s 160us/step - loss: 0.0143\n",
      "Epoch 35/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0143\n",
      "Epoch 36/400\n",
      "8/8 [==============================] - 0s 181us/step - loss: 0.0142\n",
      "Epoch 37/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0143\n",
      "Epoch 38/400\n",
      "8/8 [==============================] - 0s 153us/step - loss: 0.0142\n",
      "Epoch 39/400\n",
      "8/8 [==============================] - 0s 161us/step - loss: 0.0143\n",
      "Epoch 40/400\n",
      "8/8 [==============================] - 0s 144us/step - loss: 0.0143\n",
      "Epoch 41/400\n",
      "8/8 [==============================] - 0s 167us/step - loss: 0.0142\n",
      "Epoch 42/400\n",
      "8/8 [==============================] - 0s 169us/step - loss: 0.0143\n",
      "Epoch 43/400\n",
      "8/8 [==============================] - 0s 173us/step - loss: 0.0142\n",
      "Epoch 44/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0143\n",
      "Epoch 45/400\n",
      "8/8 [==============================] - 0s 167us/step - loss: 0.0143\n",
      "Epoch 46/400\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0142\n",
      "Epoch 47/400\n",
      "8/8 [==============================] - 0s 148us/step - loss: 0.0143\n",
      "Epoch 48/400\n",
      "8/8 [==============================] - 0s 190us/step - loss: 0.0142\n",
      "Epoch 49/400\n",
      "8/8 [==============================] - 0s 162us/step - loss: 0.0143\n",
      "Epoch 50/400\n",
      "8/8 [==============================] - 0s 173us/step - loss: 0.0143\n",
      "Epoch 51/400\n",
      "8/8 [==============================] - 0s 139us/step - loss: 0.0142\n",
      "Epoch 52/400\n",
      "8/8 [==============================] - 0s 145us/step - loss: 0.0143\n",
      "Epoch 53/400\n",
      "8/8 [==============================] - 0s 133us/step - loss: 0.0142\n",
      "Epoch 54/400\n",
      "8/8 [==============================] - 0s 134us/step - loss: 0.0143\n",
      "Epoch 55/400\n",
      "8/8 [==============================] - 0s 147us/step - loss: 0.0143\n",
      "Epoch 56/400\n",
      "8/8 [==============================] - 0s 180us/step - loss: 0.0142\n",
      "Epoch 57/400\n",
      "8/8 [==============================] - 0s 161us/step - loss: 0.0143\n",
      "Epoch 58/400\n",
      "8/8 [==============================] - 0s 153us/step - loss: 0.0142\n",
      "Epoch 59/400\n",
      "8/8 [==============================] - 0s 156us/step - loss: 0.0143\n",
      "Epoch 60/400\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0143\n",
      "Epoch 61/400\n",
      "8/8 [==============================] - 0s 184us/step - loss: 0.0143\n",
      "Epoch 62/400\n",
      "8/8 [==============================] - 0s 188us/step - loss: 0.0142\n",
      "Epoch 63/400\n",
      "8/8 [==============================] - 0s 152us/step - loss: 0.0142\n",
      "Epoch 64/400\n",
      "8/8 [==============================] - 0s 154us/step - loss: 0.0142\n",
      "Epoch 65/400\n",
      "8/8 [==============================] - 0s 131us/step - loss: 0.0142\n",
      "Epoch 66/400\n",
      "8/8 [==============================] - 0s 131us/step - loss: 0.0142\n",
      "Epoch 67/400\n",
      "8/8 [==============================] - 0s 145us/step - loss: 0.0142\n",
      "Epoch 68/400\n",
      "8/8 [==============================] - 0s 137us/step - loss: 0.0146\n",
      "Epoch 69/400\n",
      "8/8 [==============================] - 0s 156us/step - loss: 0.0142\n",
      "Epoch 70/400\n",
      "8/8 [==============================] - 0s 163us/step - loss: 0.0142\n",
      "Epoch 71/400\n",
      "8/8 [==============================] - 0s 163us/step - loss: 0.0145\n",
      "Epoch 72/400\n",
      "8/8 [==============================] - 0s 148us/step - loss: 0.0142\n",
      "Epoch 73/400\n",
      "8/8 [==============================] - 0s 173us/step - loss: 0.0142\n",
      "Epoch 74/400\n",
      "8/8 [==============================] - 0s 180us/step - loss: 0.0145\n",
      "Epoch 75/400\n",
      "8/8 [==============================] - 0s 133us/step - loss: 0.0142\n",
      "Epoch 76/400\n",
      "8/8 [==============================] - 0s 140us/step - loss: 0.0143\n",
      "Epoch 77/400\n",
      "8/8 [==============================] - 0s 123us/step - loss: 0.0144\n",
      "Epoch 78/400\n",
      "8/8 [==============================] - 0s 132us/step - loss: 0.0142\n",
      "Epoch 79/400\n",
      "8/8 [==============================] - 0s 141us/step - loss: 0.0144\n",
      "Epoch 80/400\n",
      "8/8 [==============================] - 0s 152us/step - loss: 0.0142\n",
      "Epoch 81/400\n",
      "8/8 [==============================] - 0s 155us/step - loss: 0.0142\n",
      "Epoch 82/400\n",
      "8/8 [==============================] - 0s 182us/step - loss: 0.0144\n",
      "Epoch 83/400\n",
      "8/8 [==============================] - 0s 163us/step - loss: 0.0142\n",
      "Epoch 84/400\n",
      "8/8 [==============================] - 0s 158us/step - loss: 0.0144\n",
      "Epoch 85/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0142\n",
      "Epoch 86/400\n",
      "8/8 [==============================] - 0s 175us/step - loss: 0.0142\n",
      "Epoch 87/400\n",
      "8/8 [==============================] - 0s 170us/step - loss: 0.0144\n",
      "Epoch 88/400\n",
      "8/8 [==============================] - 0s 165us/step - loss: 0.0142\n",
      "Epoch 89/400\n",
      "8/8 [==============================] - 0s 165us/step - loss: 0.0144\n",
      "Epoch 90/400\n",
      "8/8 [==============================] - 0s 136us/step - loss: 0.0142\n",
      "Epoch 91/400\n",
      "8/8 [==============================] - 0s 129us/step - loss: 0.0142\n",
      "Epoch 92/400\n",
      "8/8 [==============================] - 0s 145us/step - loss: 0.0144\n",
      "Epoch 93/400\n",
      "8/8 [==============================] - 0s 144us/step - loss: 0.0142\n",
      "Epoch 94/400\n",
      "8/8 [==============================] - 0s 134us/step - loss: 0.0144\n",
      "Epoch 95/400\n",
      "8/8 [==============================] - 0s 150us/step - loss: 0.0142\n",
      "Epoch 96/400\n",
      "8/8 [==============================] - 0s 142us/step - loss: 0.0142\n",
      "Epoch 97/400\n",
      "8/8 [==============================] - 0s 148us/step - loss: 0.0144\n",
      "Epoch 98/400\n",
      "8/8 [==============================] - 0s 179us/step - loss: 0.0142\n",
      "Epoch 99/400\n",
      "8/8 [==============================] - 0s 136us/step - loss: 0.0144\n",
      "Epoch 100/400\n",
      "8/8 [==============================] - 0s 153us/step - loss: 0.0142\n",
      "Epoch 101/400\n",
      "8/8 [==============================] - 0s 163us/step - loss: 0.0142\n",
      "Epoch 102/400\n",
      "8/8 [==============================] - 0s 116us/step - loss: 0.0143\n",
      "Epoch 103/400\n",
      "8/8 [==============================] - 0s 130us/step - loss: 0.0142\n",
      "Epoch 104/400\n",
      "8/8 [==============================] - 0s 136us/step - loss: 0.0144\n",
      "Epoch 105/400\n",
      "8/8 [==============================] - 0s 186us/step - loss: 0.0142\n",
      "Epoch 106/400\n",
      "8/8 [==============================] - 0s 137us/step - loss: 0.0142\n",
      "Epoch 107/400\n",
      "8/8 [==============================] - 0s 124us/step - loss: 0.0143\n",
      "Epoch 108/400\n",
      "8/8 [==============================] - 0s 149us/step - loss: 0.0142\n",
      "Epoch 109/400\n",
      "8/8 [==============================] - 0s 195us/step - loss: 0.0144\n",
      "Epoch 110/400\n",
      "8/8 [==============================] - 0s 183us/step - loss: 0.0142\n",
      "Epoch 111/400\n",
      "8/8 [==============================] - 0s 183us/step - loss: 0.0142\n",
      "Epoch 112/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0143\n",
      "Epoch 113/400\n",
      "8/8 [==============================] - 0s 204us/step - loss: 0.0142\n",
      "Epoch 114/400\n",
      "8/8 [==============================] - 0s 217us/step - loss: 0.0144\n",
      "Epoch 115/400\n",
      "8/8 [==============================] - 0s 234us/step - loss: 0.0142\n",
      "Epoch 116/400\n",
      "8/8 [==============================] - 0s 190us/step - loss: 0.0142\n",
      "Epoch 117/400\n",
      "8/8 [==============================] - 0s 197us/step - loss: 0.0143\n",
      "Epoch 118/400\n",
      "8/8 [==============================] - 0s 146us/step - loss: 0.0142\n",
      "Epoch 119/400\n",
      "8/8 [==============================] - 0s 264us/step - loss: 0.0143\n",
      "Epoch 120/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0142\n",
      "Epoch 121/400\n",
      "8/8 [==============================] - 0s 148us/step - loss: 0.0142\n",
      "Epoch 122/400\n",
      "8/8 [==============================] - 0s 166us/step - loss: 0.0143\n",
      "Epoch 123/400\n",
      "8/8 [==============================] - 0s 197us/step - loss: 0.0142\n",
      "Epoch 124/400\n",
      "8/8 [==============================] - 0s 180us/step - loss: 0.0143\n",
      "Epoch 125/400\n",
      "8/8 [==============================] - 0s 229us/step - loss: 0.0142\n",
      "Epoch 126/400\n",
      "8/8 [==============================] - 0s 217us/step - loss: 0.0144\n",
      "Epoch 127/400\n",
      "8/8 [==============================] - 0s 208us/step - loss: 0.0142\n",
      "Epoch 128/400\n",
      "8/8 [==============================] - 0s 157us/step - loss: 0.0142\n",
      "Epoch 129/400\n",
      "8/8 [==============================] - 0s 162us/step - loss: 0.0143\n",
      "Epoch 130/400\n",
      "8/8 [==============================] - 0s 141us/step - loss: 0.0142\n",
      "Epoch 131/400\n",
      "8/8 [==============================] - 0s 174us/step - loss: 0.0144\n",
      "Epoch 132/400\n",
      "8/8 [==============================] - 0s 133us/step - loss: 0.0142\n",
      "Epoch 133/400\n",
      "8/8 [==============================] - 0s 145us/step - loss: 0.0142\n",
      "Epoch 134/400\n",
      "8/8 [==============================] - 0s 137us/step - loss: 0.0143\n",
      "Epoch 135/400\n",
      "8/8 [==============================] - 0s 125us/step - loss: 0.0142\n",
      "Epoch 136/400\n",
      "8/8 [==============================] - 0s 124us/step - loss: 0.0144\n",
      "Epoch 137/400\n",
      "8/8 [==============================] - 0s 135us/step - loss: 0.0142\n",
      "Epoch 138/400\n",
      "8/8 [==============================] - 0s 143us/step - loss: 0.0142\n",
      "Epoch 139/400\n",
      "8/8 [==============================] - 0s 167us/step - loss: 0.0143\n",
      "Epoch 140/400\n",
      "8/8 [==============================] - 0s 154us/step - loss: 0.0142\n",
      "Epoch 141/400\n",
      "8/8 [==============================] - 0s 193us/step - loss: 0.0143\n",
      "Epoch 142/400\n",
      "8/8 [==============================] - 0s 166us/step - loss: 0.0142\n",
      "Epoch 143/400\n",
      "8/8 [==============================] - 0s 212us/step - loss: 0.0142\n",
      "Epoch 144/400\n",
      "8/8 [==============================] - 0s 242us/step - loss: 0.0143\n",
      "Epoch 145/400\n",
      "8/8 [==============================] - 0s 236us/step - loss: 0.0142\n",
      "Epoch 146/400\n",
      "8/8 [==============================] - 0s 294us/step - loss: 0.0143\n",
      "Epoch 147/400\n",
      "8/8 [==============================] - 0s 316us/step - loss: 0.0142\n",
      "Epoch 148/400\n",
      "8/8 [==============================] - 0s 150us/step - loss: 0.0142\n",
      "Epoch 149/400\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0143\n",
      "Epoch 150/400\n",
      "8/8 [==============================] - 0s 161us/step - loss: 0.0142\n",
      "Epoch 151/400\n",
      "8/8 [==============================] - 0s 177us/step - loss: 0.0143\n",
      "Epoch 152/400\n",
      "8/8 [==============================] - 0s 148us/step - loss: 0.0141\n",
      "Epoch 153/400\n",
      "8/8 [==============================] - 0s 140us/step - loss: 0.0142\n",
      "Epoch 154/400\n",
      "8/8 [==============================] - 0s 139us/step - loss: 0.0143\n",
      "Epoch 155/400\n",
      "8/8 [==============================] - 0s 141us/step - loss: 0.0142\n",
      "Epoch 156/400\n",
      "8/8 [==============================] - 0s 147us/step - loss: 0.0143\n",
      "Epoch 157/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0141\n",
      "Epoch 158/400\n",
      "8/8 [==============================] - 0s 138us/step - loss: 0.0142\n",
      "Epoch 159/400\n",
      "8/8 [==============================] - 0s 147us/step - loss: 0.0143\n",
      "Epoch 160/400\n",
      "8/8 [==============================] - 0s 131us/step - loss: 0.0142\n",
      "Epoch 161/400\n",
      "8/8 [==============================] - 0s 149us/step - loss: 0.0143\n",
      "Epoch 162/400\n",
      "8/8 [==============================] - 0s 178us/step - loss: 0.0142\n",
      "Epoch 163/400\n",
      "8/8 [==============================] - 0s 176us/step - loss: 0.0143\n",
      "Epoch 164/400\n",
      "8/8 [==============================] - 0s 195us/step - loss: 0.0142\n",
      "Epoch 165/400\n",
      "8/8 [==============================] - 0s 195us/step - loss: 0.0142\n",
      "Epoch 166/400\n",
      "8/8 [==============================] - 0s 368us/step - loss: 0.0143\n",
      "Epoch 167/400\n",
      "8/8 [==============================] - 0s 177us/step - loss: 0.0142\n",
      "Epoch 168/400\n",
      "8/8 [==============================] - 0s 165us/step - loss: 0.0143\n",
      "Epoch 169/400\n",
      "8/8 [==============================] - 0s 189us/step - loss: 0.0142\n",
      "Epoch 170/400\n",
      "8/8 [==============================] - 0s 184us/step - loss: 0.0142\n",
      "Epoch 171/400\n",
      "8/8 [==============================] - 0s 196us/step - loss: 0.0143\n",
      "Epoch 172/400\n",
      "8/8 [==============================] - 0s 212us/step - loss: 0.0142\n",
      "Epoch 173/400\n",
      "8/8 [==============================] - 0s 255us/step - loss: 0.0143\n",
      "Epoch 174/400\n",
      "8/8 [==============================] - 0s 175us/step - loss: 0.0141\n",
      "Epoch 175/400\n",
      "8/8 [==============================] - 0s 159us/step - loss: 0.0142\n",
      "Epoch 176/400\n",
      "8/8 [==============================] - 0s 177us/step - loss: 0.0143\n",
      "Epoch 177/400\n",
      "8/8 [==============================] - 0s 204us/step - loss: 0.0142\n",
      "Epoch 178/400\n",
      "8/8 [==============================] - 0s 211us/step - loss: 0.0143\n",
      "Epoch 179/400\n",
      "8/8 [==============================] - 0s 141us/step - loss: 0.0141\n",
      "Epoch 180/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0142\n",
      "Epoch 181/400\n",
      "8/8 [==============================] - 0s 183us/step - loss: 0.0143\n",
      "Epoch 182/400\n",
      "8/8 [==============================] - 0s 135us/step - loss: 0.0142\n",
      "Epoch 183/400\n",
      "8/8 [==============================] - 0s 154us/step - loss: 0.0143\n",
      "Epoch 184/400\n",
      "8/8 [==============================] - 0s 295us/step - loss: 0.0141\n",
      "Epoch 185/400\n",
      "8/8 [==============================] - 0s 150us/step - loss: 0.0142\n",
      "Epoch 186/400\n",
      "8/8 [==============================] - 0s 179us/step - loss: 0.0143\n",
      "Epoch 187/400\n",
      "8/8 [==============================] - 0s 147us/step - loss: 0.0142\n",
      "Epoch 188/400\n",
      "8/8 [==============================] - 0s 150us/step - loss: 0.0143\n",
      "Epoch 189/400\n",
      "8/8 [==============================] - 0s 189us/step - loss: 0.0141\n",
      "Epoch 190/400\n",
      "8/8 [==============================] - 0s 190us/step - loss: 0.0142\n",
      "Epoch 191/400\n",
      "8/8 [==============================] - 0s 167us/step - loss: 0.0143\n",
      "Epoch 192/400\n",
      "8/8 [==============================] - 0s 179us/step - loss: 0.0142\n",
      "Epoch 193/400\n",
      "8/8 [==============================] - 0s 194us/step - loss: 0.0143\n",
      "Epoch 194/400\n",
      "8/8 [==============================] - 0s 245us/step - loss: 0.0141\n",
      "Epoch 195/400\n",
      "8/8 [==============================] - 0s 160us/step - loss: 0.0143\n",
      "Epoch 196/400\n",
      "8/8 [==============================] - 0s 149us/step - loss: 0.0141\n",
      "Epoch 197/400\n",
      "8/8 [==============================] - 0s 150us/step - loss: 0.0142\n",
      "Epoch 198/400\n",
      "8/8 [==============================] - 0s 165us/step - loss: 0.0143\n",
      "Epoch 199/400\n",
      "8/8 [==============================] - 0s 147us/step - loss: 0.0142\n",
      "Epoch 200/400\n",
      "8/8 [==============================] - 0s 150us/step - loss: 0.0143\n",
      "Epoch 201/400\n",
      "8/8 [==============================] - 0s 141us/step - loss: 0.0141\n",
      "Epoch 202/400\n",
      "8/8 [==============================] - 0s 162us/step - loss: 0.0142\n",
      "Epoch 203/400\n",
      "8/8 [==============================] - 0s 137us/step - loss: 0.0143\n",
      "Epoch 204/400\n",
      "8/8 [==============================] - 0s 162us/step - loss: 0.0142\n",
      "Epoch 205/400\n",
      "8/8 [==============================] - 0s 159us/step - loss: 0.0143\n",
      "Epoch 206/400\n",
      "8/8 [==============================] - 0s 149us/step - loss: 0.0141\n",
      "Epoch 207/400\n",
      "8/8 [==============================] - 0s 170us/step - loss: 0.0142\n",
      "Epoch 208/400\n",
      "8/8 [==============================] - 0s 183us/step - loss: 0.0143\n",
      "Epoch 209/400\n",
      "8/8 [==============================] - 0s 147us/step - loss: 0.0142\n",
      "Epoch 210/400\n",
      "8/8 [==============================] - 0s 195us/step - loss: 0.0143\n",
      "Epoch 211/400\n",
      "8/8 [==============================] - 0s 231us/step - loss: 0.0141\n",
      "Epoch 212/400\n",
      "8/8 [==============================] - 0s 201us/step - loss: 0.0142\n",
      "Epoch 213/400\n",
      "8/8 [==============================] - 0s 262us/step - loss: 0.0143\n",
      "Epoch 214/400\n",
      "8/8 [==============================] - 0s 294us/step - loss: 0.0142\n",
      "Epoch 215/400\n",
      "8/8 [==============================] - 0s 210us/step - loss: 0.0143\n",
      "Epoch 216/400\n",
      "8/8 [==============================] - 0s 174us/step - loss: 0.0141\n",
      "Epoch 217/400\n",
      "8/8 [==============================] - 0s 140us/step - loss: 0.0142\n",
      "Epoch 218/400\n",
      "8/8 [==============================] - 0s 157us/step - loss: 0.0143\n",
      "Epoch 219/400\n",
      "8/8 [==============================] - 0s 188us/step - loss: 0.0142\n",
      "Epoch 220/400\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0143\n",
      "Epoch 221/400\n",
      "8/8 [==============================] - 0s 222us/step - loss: 0.0141\n",
      "Epoch 222/400\n",
      "8/8 [==============================] - 0s 183us/step - loss: 0.0142\n",
      "Epoch 223/400\n",
      "8/8 [==============================] - 0s 159us/step - loss: 0.0143\n",
      "Epoch 224/400\n",
      "8/8 [==============================] - 0s 159us/step - loss: 0.0142\n",
      "Epoch 225/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0143\n",
      "Epoch 226/400\n",
      "8/8 [==============================] - 0s 183us/step - loss: 0.0141\n",
      "Epoch 227/400\n",
      "8/8 [==============================] - 0s 158us/step - loss: 0.0142\n",
      "Epoch 228/400\n",
      "8/8 [==============================] - 0s 160us/step - loss: 0.0143\n",
      "Epoch 229/400\n",
      "8/8 [==============================] - 0s 186us/step - loss: 0.0142\n",
      "Epoch 230/400\n",
      "8/8 [==============================] - 0s 196us/step - loss: 0.0143\n",
      "Epoch 231/400\n",
      "8/8 [==============================] - 0s 173us/step - loss: 0.0141\n",
      "Epoch 232/400\n",
      "8/8 [==============================] - 0s 175us/step - loss: 0.0143\n",
      "Epoch 233/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0141\n",
      "Epoch 234/400\n",
      "8/8 [==============================] - 0s 217us/step - loss: 0.0142\n",
      "Epoch 235/400\n",
      "8/8 [==============================] - 0s 146us/step - loss: 0.0143\n",
      "Epoch 236/400\n",
      "8/8 [==============================] - 0s 160us/step - loss: 0.0141\n",
      "Epoch 237/400\n",
      "8/8 [==============================] - 0s 153us/step - loss: 0.0143\n",
      "Epoch 238/400\n",
      "8/8 [==============================] - 0s 163us/step - loss: 0.0141\n",
      "Epoch 239/400\n",
      "8/8 [==============================] - 0s 170us/step - loss: 0.0142\n",
      "Epoch 240/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0143\n",
      "Epoch 241/400\n",
      "8/8 [==============================] - 0s 187us/step - loss: 0.0142\n",
      "Epoch 242/400\n",
      "8/8 [==============================] - 0s 158us/step - loss: 0.0143\n",
      "Epoch 243/400\n",
      "8/8 [==============================] - 0s 131us/step - loss: 0.0141\n",
      "Epoch 244/400\n",
      "8/8 [==============================] - 0s 149us/step - loss: 0.0142\n",
      "Epoch 245/400\n",
      "8/8 [==============================] - 0s 159us/step - loss: 0.0143\n",
      "Epoch 246/400\n",
      "8/8 [==============================] - 0s 152us/step - loss: 0.0142\n",
      "Epoch 247/400\n",
      "8/8 [==============================] - 0s 156us/step - loss: 0.0143\n",
      "Epoch 248/400\n",
      "8/8 [==============================] - 0s 144us/step - loss: 0.0141\n",
      "Epoch 249/400\n",
      "8/8 [==============================] - 0s 139us/step - loss: 0.0142\n",
      "Epoch 250/400\n",
      "8/8 [==============================] - 0s 146us/step - loss: 0.0143\n",
      "Epoch 251/400\n",
      "8/8 [==============================] - 0s 151us/step - loss: 0.0142\n",
      "Epoch 252/400\n",
      "8/8 [==============================] - 0s 173us/step - loss: 0.0143\n",
      "Epoch 253/400\n",
      "8/8 [==============================] - 0s 201us/step - loss: 0.0141\n",
      "Epoch 254/400\n",
      "8/8 [==============================] - 0s 150us/step - loss: 0.0142\n",
      "Epoch 255/400\n",
      "8/8 [==============================] - 0s 169us/step - loss: 0.0143\n",
      "Epoch 256/400\n",
      "8/8 [==============================] - 0s 162us/step - loss: 0.0142\n",
      "Epoch 257/400\n",
      "8/8 [==============================] - 0s 145us/step - loss: 0.0143\n",
      "Epoch 258/400\n",
      "8/8 [==============================] - 0s 178us/step - loss: 0.0141\n",
      "Epoch 259/400\n",
      "8/8 [==============================] - 0s 147us/step - loss: 0.0142\n",
      "Epoch 260/400\n",
      "8/8 [==============================] - 0s 181us/step - loss: 0.0143\n",
      "Epoch 261/400\n",
      "8/8 [==============================] - 0s 161us/step - loss: 0.0142\n",
      "Epoch 262/400\n",
      "8/8 [==============================] - 0s 176us/step - loss: 0.0143\n",
      "Epoch 263/400\n",
      "8/8 [==============================] - 0s 158us/step - loss: 0.0141\n",
      "Epoch 264/400\n",
      "8/8 [==============================] - 0s 186us/step - loss: 0.0142\n",
      "Epoch 265/400\n",
      "8/8 [==============================] - 0s 176us/step - loss: 0.0143\n",
      "Epoch 266/400\n",
      "8/8 [==============================] - 0s 176us/step - loss: 0.0142\n",
      "Epoch 267/400\n",
      "8/8 [==============================] - 0s 194us/step - loss: 0.0143\n",
      "Epoch 268/400\n",
      "8/8 [==============================] - 0s 149us/step - loss: 0.0141\n",
      "Epoch 269/400\n",
      "8/8 [==============================] - 0s 156us/step - loss: 0.0143\n",
      "Epoch 270/400\n",
      "8/8 [==============================] - 0s 216us/step - loss: 0.0141\n",
      "Epoch 271/400\n",
      "8/8 [==============================] - 0s 186us/step - loss: 0.0142\n",
      "Epoch 272/400\n",
      "8/8 [==============================] - 0s 209us/step - loss: 0.0143\n",
      "Epoch 273/400\n",
      "8/8 [==============================] - 0s 236us/step - loss: 0.0141\n",
      "Epoch 274/400\n",
      "8/8 [==============================] - 0s 150us/step - loss: 0.0143\n",
      "Epoch 275/400\n",
      "8/8 [==============================] - 0s 156us/step - loss: 0.0141\n",
      "Epoch 276/400\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0142\n",
      "Epoch 277/400\n",
      "8/8 [==============================] - 0s 159us/step - loss: 0.0143\n",
      "Epoch 278/400\n",
      "8/8 [==============================] - 0s 163us/step - loss: 0.0142\n",
      "Epoch 279/400\n",
      "8/8 [==============================] - 0s 194us/step - loss: 0.0143\n",
      "Epoch 280/400\n",
      "8/8 [==============================] - 0s 215us/step - loss: 0.0141\n",
      "Epoch 281/400\n",
      "8/8 [==============================] - 0s 228us/step - loss: 0.0142\n",
      "Epoch 282/400\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0143\n",
      "Epoch 283/400\n",
      "8/8 [==============================] - 0s 180us/step - loss: 0.0142\n",
      "Epoch 284/400\n",
      "8/8 [==============================] - 0s 179us/step - loss: 0.0143\n",
      "Epoch 285/400\n",
      "8/8 [==============================] - 0s 182us/step - loss: 0.0141\n",
      "Epoch 286/400\n",
      "8/8 [==============================] - 0s 150us/step - loss: 0.0142\n",
      "Epoch 287/400\n",
      "8/8 [==============================] - 0s 145us/step - loss: 0.0143\n",
      "Epoch 288/400\n",
      "8/8 [==============================] - 0s 233us/step - loss: 0.0142\n",
      "Epoch 289/400\n",
      "8/8 [==============================] - 0s 124us/step - loss: 0.0143\n",
      "Epoch 290/400\n",
      "8/8 [==============================] - 0s 138us/step - loss: 0.0141\n",
      "Epoch 291/400\n",
      "8/8 [==============================] - 0s 122us/step - loss: 0.0142\n",
      "Epoch 292/400\n",
      "8/8 [==============================] - 0s 140us/step - loss: 0.0143\n",
      "Epoch 293/400\n",
      "8/8 [==============================] - 0s 145us/step - loss: 0.0142\n",
      "Epoch 294/400\n",
      "8/8 [==============================] - 0s 132us/step - loss: 0.0143\n",
      "Epoch 295/400\n",
      "8/8 [==============================] - 0s 140us/step - loss: 0.0141\n",
      "Epoch 296/400\n",
      "8/8 [==============================] - 0s 152us/step - loss: 0.0142\n",
      "Epoch 297/400\n",
      "8/8 [==============================] - 0s 141us/step - loss: 0.0143\n",
      "Epoch 298/400\n",
      "8/8 [==============================] - 0s 155us/step - loss: 0.0142\n",
      "Epoch 299/400\n",
      "8/8 [==============================] - 0s 143us/step - loss: 0.0143\n",
      "Epoch 300/400\n",
      "8/8 [==============================] - 0s 190us/step - loss: 0.0141\n",
      "Epoch 301/400\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0143\n",
      "Epoch 302/400\n",
      "8/8 [==============================] - 0s 154us/step - loss: 0.0141\n",
      "Epoch 303/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0142\n",
      "Epoch 304/400\n",
      "8/8 [==============================] - 0s 163us/step - loss: 0.0143\n",
      "Epoch 305/400\n",
      "8/8 [==============================] - 0s 188us/step - loss: 0.0141\n",
      "Epoch 306/400\n",
      "8/8 [==============================] - 0s 190us/step - loss: 0.0143\n",
      "Epoch 307/400\n",
      "8/8 [==============================] - 0s 192us/step - loss: 0.0141\n",
      "Epoch 308/400\n",
      "8/8 [==============================] - 0s 188us/step - loss: 0.0142\n",
      "Epoch 309/400\n",
      "8/8 [==============================] - 0s 207us/step - loss: 0.0143\n",
      "Epoch 310/400\n",
      "8/8 [==============================] - 0s 202us/step - loss: 0.0141\n",
      "Epoch 311/400\n",
      "8/8 [==============================] - 0s 222us/step - loss: 0.0143\n",
      "Epoch 312/400\n",
      "8/8 [==============================] - 0s 197us/step - loss: 0.0141\n",
      "Epoch 313/400\n",
      "8/8 [==============================] - 0s 198us/step - loss: 0.0142\n",
      "Epoch 314/400\n",
      "8/8 [==============================] - 0s 174us/step - loss: 0.0143\n",
      "Epoch 315/400\n",
      "8/8 [==============================] - 0s 194us/step - loss: 0.0142\n",
      "Epoch 316/400\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0143\n",
      "Epoch 317/400\n",
      "8/8 [==============================] - 0s 161us/step - loss: 0.0141\n",
      "Epoch 318/400\n",
      "8/8 [==============================] - 0s 146us/step - loss: 0.0142\n",
      "Epoch 319/400\n",
      "8/8 [==============================] - 0s 189us/step - loss: 0.0143\n",
      "Epoch 320/400\n",
      "8/8 [==============================] - 0s 170us/step - loss: 0.0142\n",
      "Epoch 321/400\n",
      "8/8 [==============================] - 0s 191us/step - loss: 0.0143\n",
      "Epoch 322/400\n",
      "8/8 [==============================] - 0s 219us/step - loss: 0.0141\n",
      "Epoch 323/400\n",
      "8/8 [==============================] - 0s 169us/step - loss: 0.0142\n",
      "Epoch 324/400\n",
      "8/8 [==============================] - 0s 159us/step - loss: 0.0143\n",
      "Epoch 325/400\n",
      "8/8 [==============================] - 0s 153us/step - loss: 0.0142\n",
      "Epoch 326/400\n",
      "8/8 [==============================] - 0s 165us/step - loss: 0.0143\n",
      "Epoch 327/400\n",
      "8/8 [==============================] - 0s 157us/step - loss: 0.0141\n",
      "Epoch 328/400\n",
      "8/8 [==============================] - 0s 150us/step - loss: 0.0142\n",
      "Epoch 329/400\n",
      "8/8 [==============================] - 0s 170us/step - loss: 0.0143\n",
      "Epoch 330/400\n",
      "8/8 [==============================] - 0s 169us/step - loss: 0.0142\n",
      "Epoch 331/400\n",
      "8/8 [==============================] - 0s 160us/step - loss: 0.0143\n",
      "Epoch 332/400\n",
      "8/8 [==============================] - 0s 193us/step - loss: 0.0141\n",
      "Epoch 333/400\n",
      "8/8 [==============================] - 0s 147us/step - loss: 0.0142\n",
      "Epoch 334/400\n",
      "8/8 [==============================] - 0s 140us/step - loss: 0.0142\n",
      "Epoch 335/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0142\n",
      "Epoch 336/400\n",
      "8/8 [==============================] - 0s 140us/step - loss: 0.0143\n",
      "Epoch 337/400\n",
      "8/8 [==============================] - 0s 144us/step - loss: 0.0141\n",
      "Epoch 338/400\n",
      "8/8 [==============================] - 0s 135us/step - loss: 0.0143\n",
      "Epoch 339/400\n",
      "8/8 [==============================] - 0s 163us/step - loss: 0.0141\n",
      "Epoch 340/400\n",
      "8/8 [==============================] - 0s 158us/step - loss: 0.0142\n",
      "Epoch 341/400\n",
      "8/8 [==============================] - 0s 169us/step - loss: 0.0143\n",
      "Epoch 342/400\n",
      "8/8 [==============================] - 0s 154us/step - loss: 0.0141\n",
      "Epoch 343/400\n",
      "8/8 [==============================] - 0s 144us/step - loss: 0.0143\n",
      "Epoch 344/400\n",
      "8/8 [==============================] - 0s 181us/step - loss: 0.0141\n",
      "Epoch 345/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0142\n",
      "Epoch 346/400\n",
      "8/8 [==============================] - 0s 182us/step - loss: 0.0143\n",
      "Epoch 347/400\n",
      "8/8 [==============================] - 0s 233us/step - loss: 0.0141\n",
      "Epoch 348/400\n",
      "8/8 [==============================] - 0s 147us/step - loss: 0.0143\n",
      "Epoch 349/400\n",
      "8/8 [==============================] - 0s 150us/step - loss: 0.0141\n",
      "Epoch 350/400\n",
      "8/8 [==============================] - 0s 282us/step - loss: 0.0142\n",
      "Epoch 351/400\n",
      "8/8 [==============================] - 0s 138us/step - loss: 0.0143\n",
      "Epoch 352/400\n",
      "8/8 [==============================] - 0s 143us/step - loss: 0.0141\n",
      "Epoch 353/400\n",
      "8/8 [==============================] - 0s 138us/step - loss: 0.0143\n",
      "Epoch 354/400\n",
      "8/8 [==============================] - 0s 159us/step - loss: 0.0141\n",
      "Epoch 355/400\n",
      "8/8 [==============================] - 0s 212us/step - loss: 0.0142\n",
      "Epoch 356/400\n",
      "8/8 [==============================] - 0s 136us/step - loss: 0.0143\n",
      "Epoch 357/400\n",
      "8/8 [==============================] - 0s 156us/step - loss: 0.0142\n",
      "Epoch 358/400\n",
      "8/8 [==============================] - 0s 190us/step - loss: 0.0143\n",
      "Epoch 359/400\n",
      "8/8 [==============================] - 0s 140us/step - loss: 0.0141\n",
      "Epoch 360/400\n",
      "8/8 [==============================] - 0s 173us/step - loss: 0.0142\n",
      "Epoch 361/400\n",
      "8/8 [==============================] - 0s 142us/step - loss: 0.0142\n",
      "Epoch 362/400\n",
      "8/8 [==============================] - 0s 158us/step - loss: 0.0142\n",
      "Epoch 363/400\n",
      "8/8 [==============================] - 0s 167us/step - loss: 0.0143\n",
      "Epoch 364/400\n",
      "8/8 [==============================] - 0s 162us/step - loss: 0.0141\n",
      "Epoch 365/400\n",
      "8/8 [==============================] - 0s 174us/step - loss: 0.0142\n",
      "Epoch 366/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0142\n",
      "Epoch 367/400\n",
      "8/8 [==============================] - 0s 180us/step - loss: 0.0142\n",
      "Epoch 368/400\n",
      "8/8 [==============================] - 0s 227us/step - loss: 0.0143\n",
      "Epoch 369/400\n",
      "8/8 [==============================] - 0s 161us/step - loss: 0.0141\n",
      "Epoch 370/400\n",
      "8/8 [==============================] - 0s 145us/step - loss: 0.0142\n",
      "Epoch 371/400\n",
      "8/8 [==============================] - 0s 140us/step - loss: 0.0142\n",
      "Epoch 372/400\n",
      "8/8 [==============================] - 0s 177us/step - loss: 0.0142\n",
      "Epoch 373/400\n",
      "8/8 [==============================] - 0s 187us/step - loss: 0.0143\n",
      "Epoch 374/400\n",
      "8/8 [==============================] - 0s 151us/step - loss: 0.0141\n",
      "Epoch 375/400\n",
      "8/8 [==============================] - 0s 151us/step - loss: 0.0143\n",
      "Epoch 376/400\n",
      "8/8 [==============================] - 0s 217us/step - loss: 0.0141\n",
      "Epoch 377/400\n",
      "8/8 [==============================] - 0s 240us/step - loss: 0.0142\n",
      "Epoch 378/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0143\n",
      "Epoch 379/400\n",
      "8/8 [==============================] - 0s 160us/step - loss: 0.0141\n",
      "Epoch 380/400\n",
      "8/8 [==============================] - 0s 145us/step - loss: 0.0143\n",
      "Epoch 381/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0141\n",
      "Epoch 382/400\n",
      "8/8 [==============================] - 0s 155us/step - loss: 0.0142\n",
      "Epoch 383/400\n",
      "8/8 [==============================] - 0s 180us/step - loss: 0.0142\n",
      "Epoch 384/400\n",
      "8/8 [==============================] - 0s 231us/step - loss: 0.0141\n",
      "Epoch 385/400\n",
      "8/8 [==============================] - 0s 263us/step - loss: 0.0143\n",
      "Epoch 386/400\n",
      "8/8 [==============================] - 0s 150us/step - loss: 0.0141\n",
      "Epoch 387/400\n",
      "8/8 [==============================] - 0s 148us/step - loss: 0.0142\n",
      "Epoch 388/400\n",
      "8/8 [==============================] - 0s 152us/step - loss: 0.0142\n",
      "Epoch 389/400\n",
      "8/8 [==============================] - 0s 147us/step - loss: 0.0141\n",
      "Epoch 390/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0143\n",
      "Epoch 391/400\n",
      "8/8 [==============================] - 0s 145us/step - loss: 0.0141\n",
      "Epoch 392/400\n",
      "8/8 [==============================] - 0s 176us/step - loss: 0.0142\n",
      "Epoch 393/400\n",
      "8/8 [==============================] - 0s 150us/step - loss: 0.0142\n",
      "Epoch 394/400\n",
      "8/8 [==============================] - 0s 193us/step - loss: 0.0141\n",
      "Epoch 395/400\n",
      "8/8 [==============================] - 0s 174us/step - loss: 0.0143\n",
      "Epoch 396/400\n",
      "8/8 [==============================] - 0s 198us/step - loss: 0.0141\n",
      "Epoch 397/400\n",
      "8/8 [==============================] - 0s 228us/step - loss: 0.0142\n",
      "Epoch 398/400\n",
      "8/8 [==============================] - 0s 185us/step - loss: 0.0142\n",
      "Epoch 399/400\n",
      "8/8 [==============================] - 0s 166us/step - loss: 0.0142\n",
      "Epoch 400/400\n",
      "8/8 [==============================] - 0s 149us/step - loss: 0.0143\n",
      "best epoch =  396\n",
      "smallest loss = 0.01412753015756607\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 80, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = tf.keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(xarray,df.y3,epochs=400,callbacks=[es])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6f7bdd-ec76-487b-9419-dc018320be80",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42f3d300",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2167145 ]\n",
      " [0.31941473]\n",
      " [0.72139275]]\n",
      "w01 =  1.2167145 w02 =  0.31941473 w03 =  0.72139275\n",
      "[-0.13823985]\n",
      "b1 =  [-0.13823985]\n",
      "[[0.7061412]]\n",
      "w12 =  0.7061412\n",
      "[-0.10798812]\n",
      "b2 =  [-0.10798812]\n",
      "[[0.68419325]]\n",
      "w23 =  0.68419325\n",
      "[0.02227388]\n",
      "b3 =  [0.02227388]\n",
      "x01/20.2,  x02/14.5,   x03/308.0,  y3/32.4,  a3:\n",
      "0.9900990099009901 0.896551724137931 1.009090909090909 0.9558346964599856 [[0.9536769]]\n",
      "0.9900990099009901 1.0 1.0 0.9968828122588808 [[0.9664727]]\n",
      "0.9900990099009901 1.0551724137931036 0.9935064935064936 0.9721922162896206 [[0.97272366]]\n",
      "1.0 0.896551724137931 1.009090909090909 0.9539829017622912 [[0.95949703]]\n",
      "0.9900990099009901 1.0 1.0 1.003055461251196 [[0.9664727]]\n",
      "1.0 1.0551724137931036 0.9935064935064936 0.9691058917934631 [[0.97854394]]\n",
      "1.188118811881188 0.896551724137931 1.009090909090909 1.0984228881824636 [[1.0700808]]\n",
      "1.7821782178217822 1.0 1.0 1.4320545662170918 [[1.4320883]]\n",
      "  \n",
      "x01,  x02,   x03,  y3,  a3*32.4:\n",
      "20.0 13.0 310.8 30.969044165303533 [[30.899132]]\n",
      "20.0 14.5 308.0 32.29900311718774 [[31.313717]]\n",
      "20.0 15.3 306.0 31.499027807783705 [[31.516249]]\n",
      "20.2 13.0 310.8 30.909046017098234 [[31.087706]]\n",
      "20.0 14.5 308.0 32.498996944538746 [[31.313717]]\n",
      "20.2 15.3 306.0 31.3990308941082 [[31.704824]]\n",
      "23.999999999999996 13.0 310.8 35.58890157711182 [[34.67062]]\n",
      "36.0 14.5 308.0 46.398567945433776 [[46.399662]]\n",
      "Stored 'Y3_keras' (list)\n",
      "Stored 'Y3_data' (list)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#For results of training network:\n",
    "#keras.layer.get_weights() function retrieves weight values\n",
    "first_layer_weights = model.layers[0].get_weights()[0]\n",
    "w01 = first_layer_weights[0][0]\n",
    "w02 = first_layer_weights[1][0]\n",
    "w03 = first_layer_weights[2][0]\n",
    "first_layer_bias  = model.layers[0].get_weights()[1]\n",
    "b1 = first_layer_bias\n",
    "second_layer_weights = model.layers[1].get_weights()[0]\n",
    "w12 = second_layer_weights[0][0]\n",
    "second_layer_bias  = model.layers[1].get_weights()[1]\n",
    "b2 = second_layer_bias\n",
    "third_layer_weights = model.layers[2].get_weights()[0]\n",
    "w23 = third_layer_weights[0][0]\n",
    "third_layer_bias  = model.layers[2].get_weights()[1]\n",
    "b3 = third_layer_bias\n",
    "\n",
    "#print weights and biases\n",
    "print (first_layer_weights)\n",
    "print ('w01 = ', w01, 'w02 = ', w02, 'w03 = ', w03)\n",
    "print (first_layer_bias)\n",
    "print ('b1 = ', b1)\n",
    "print (second_layer_weights)\n",
    "print ('w12 = ', w12)\n",
    "print (second_layer_bias)\n",
    "print ('b2 = ', b2)\n",
    "print (third_layer_weights)\n",
    "print ('w23 = ', w23)\n",
    "print (third_layer_bias)\n",
    "print ('b3 = ', b3)\n",
    "\n",
    "#use model.predict() function to print model predictions for data conditions\n",
    "xarray= np.array(xdata)\n",
    "print ('x01/20.2,  x02/14.5,   x03/308.0,  y3/32.4,  a3:')\n",
    "test = []\n",
    "for i in range(0,8): \n",
    "    test = [[xarray[i][0], xarray[i][1], xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    print (xarray[i][0], xarray[i][1], xarray[i][2], df.y3[i], a3)\n",
    "print('  ')\n",
    "print ('x01,  x02,   x03,  y3,  a3*32.4:')\n",
    "Y3_keras = []\n",
    "Y3_data = []\n",
    "for i in range(0,8): \n",
    "    test = [[xarray[i][0], xarray[i][1], xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    Y3_keras.append(a3*32.4)\n",
    "    Y3_data.append(df.y3[i]*32.4)\n",
    "    print (xarray[i][0]*20.2, xarray[i][1]*14.5, xarray[i][2]*308.0, df.y3[i]*32.4, a3*32.4)\n",
    "%store Y3_keras\n",
    "%store Y3_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb53019-f7d9-4411-8d1b-d1343abf9fa5",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e249947-a2d8-4e5d-9ca3-84a9319bab3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.969044165303533, 32.29900311718774, 31.499027807783705, 30.909046017098234, 32.498996944538746, 31.3990308941082, 35.58890157711182, 46.398567945433776]\n",
      "[31.090793913544566, 31.678835486931895, 31.973926195676942, 31.27579387700364, 31.678835486931895, 31.973926195676942, 34.79079318272606, 46.47883256365786]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.969044165303533, 32.29900311718774, 31.499027807783705, 30.909046017098234, 32.498996944538746, 31.3990308941082, 35.58890157711182, 46.398567945433776]\n",
      "[array([[30.899132]], dtype=float32), array([[31.313717]], dtype=float32), array([[31.516249]], dtype=float32), array([[31.087706]], dtype=float32), array([[31.313717]], dtype=float32), array([[31.704824]], dtype=float32), array([[34.67062]], dtype=float32), array([[46.399662]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot predicted y3 vs. data y3\n",
    "#First principles\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print(Y3_data)\n",
    "print(Y3_FP)\n",
    "plt.scatter(Y3_FP,Y3_data)\n",
    "plt.xlabel('Predicted y3 first principles', fontsize='16')\n",
    "plt.ylabel('data y3', fontsize='16')\n",
    "plt.loglog()\n",
    "plt.show()\n",
    "#Keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print(Y3_data)\n",
    "print(Y3_keras)\n",
    "plt.scatter(Y3_keras,Y3_data)\n",
    "plt.xlabel('Predicted y3 Keras', fontsize='16')\n",
    "plt.ylabel('data y3', fontsize='16')\n",
    "plt.loglog()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85451e94-8863-40d4-96e2-fd59ed44c017",
   "metadata": {},
   "source": [
    "### d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77ea54b9-bc54-4696-9613-64d8089e6ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9900990099009901, 0.896551724137931, 1.009090909090909, 0.9558641975308642], [0.9900990099009901, 1.0, 1.0, 0.9969135802469136], [0.9900990099009901, 1.0551724137931036, 0.9935064935064936, 0.9722222222222222], [1.0, 0.896551724137931, 1.009090909090909, 0.9540123456790124], [0.9900990099009901, 1.0, 1.0, 1.0030864197530864], [0.9900990099009901, 1.0551724137931036, 0.9935064935064936, 0.9691358024691358], [1.188118811881188, 0.896551724137931, 1.009090909090909, 1.098456790123457], [1.7821782178217822, 1.0, 1.0, 1.4320987654320987]]\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.476 0.48 0.84 0.864 0.84\n",
      "-0.18 -0.144 0.012\n",
      "E3 =  0.7524187529130215 icount = 8\n",
      "next ws: 1.389586920811888 0.3778290672663652 0.7404347683861738 0.8335888649876556 0.8085858514025894\n",
      "next bs: -0.2797345528128705 -0.23017065363032008 -0.06038334904946889\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.389586920811888 0.3778290672663652 0.7404347683861738 0.8335888649876556 0.8085858514025894\n",
      "-0.2797345528128705 -0.23017065363032008 -0.06038334904946889\n",
      "E3 =  0.10510575901559652 icount = 8\n",
      "next ws: 1.3548111630463677 0.33533736056481295 0.6989934313447775 0.8196907083917494 0.7934229079412809\n",
      "next bs: -0.3212443120405743 -0.2647727267108525 -0.08836209577158584\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3548111630463677 0.33533736056481295 0.6989934313447775 0.8196907083917494 0.7934229079412809\n",
      "-0.3212443120405743 -0.2647727267108525 -0.08836209577158584\n",
      "E3 =  0.01564667259423112 icount = 8\n",
      "next ws: 1.3472367768289328 0.3250486987111557 0.6889307508779218 0.8163993991314437 0.7897664794825724\n",
      "next bs: -0.3313218403926867 -0.2730331830646335 -0.09491613107272476\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3472367768289328 0.3250486987111557 0.6889307508779218 0.8163993991314437 0.7897664794825724\n",
      "-0.3313218403926867 -0.2730331830646335 -0.09491613107272476\n",
      "E3 =  0.00814125996386269 icount = 8\n",
      "next ws: 1.3401319499713287 0.31390082607372816 0.6779801159107751 0.8131529361538785 0.7861923889249108\n",
      "next bs: -0.34228565997428345 -0.28198403878323464 -0.10198521688196084\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3401319499713287 0.31390082607372816 0.6779801159107751 0.8131529361538785 0.7861923889249108\n",
      "-0.34228565997428345 -0.28198403878323464 -0.10198521688196084\n",
      "E3 =  0.005578041137913015 icount = 8\n",
      "next ws: 1.3139249725809203 0.39085716346386584 0.7471385780021005 0.7938708286914287 0.7695191908777127\n",
      "next bs: -0.27267505846729045 -0.2253799737803857 -0.0574835317945101\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3139249725809203 0.39085716346386584 0.7471385780021005 0.7938708286914287 0.7695191908777127\n",
      "-0.27267505846729045 -0.2253799737803857 -0.0574835317945101\n",
      "E3 =  0.023304828314577097 icount = 8\n",
      "next ws: 1.3050146857752527 0.3797084617755676 0.7362468817003011 0.7903599865167958 0.7656733888889443\n",
      "next bs: -0.28358318349043427 -0.2340396160319786 -0.06414729269324632\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3050146857752527 0.3797084617755676 0.7362468817003011 0.7903599865167958 0.7656733888889443\n",
      "-0.28358318349043427 -0.2340396160319786 -0.06414729269324632\n",
      "E3 =  0.011147943260818145 icount = 8\n",
      "next ws: 1.2984873226459617 0.3711964934667883 0.727916817301971 0.787715992160764 0.7627668070308371\n",
      "next bs: -0.29192474622695924 -0.24063245344394746 -0.06919525285686234\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2984873226459617 0.3711964934667883 0.727916817301971 0.787715992160764 0.7627668070308371\n",
      "-0.29192474622695924 -0.24063245344394746 -0.06919525285686234\n",
      "E3 =  0.005543017882234 icount = 8\n",
      "next ws: 1.2931530315797757 0.36364838964778523 0.7205032523042185 0.7854746850400813 0.7603085990198218\n",
      "next bs: -0.2993465453581773 -0.24647872331021278 -0.07365459345579414\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2931530315797757 0.36364838964778523 0.7205032523042185 0.7854746850400813 0.7603085990198218\n",
      "-0.2993465453581773 -0.24647872331021278 -0.07365459345579414\n",
      "E3 =  0.003122937183438932 icount = 8\n",
      "next ws: 1.286512131338586 0.35088460910177227 0.7077565255093877 0.7824094574383563 0.7570262014315762\n",
      "next bs: -0.3120914852206625 -0.2564895509345531 -0.08126591178188527\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.286512131338586 0.35088460910177227 0.7077565255093877 0.7824094574383563 0.7570262014315762\n",
      "-0.3120914852206625 -0.2564895509345531 -0.08126591178188527\n",
      "E3 =  0.003858662619913384 icount = 8\n",
      "next ws: 1.2960498774645344 0.3584447593985732 0.7150353564942695 0.7857280205183521 0.7609928858865876\n",
      "next bs: -0.3047938564497188 -0.25077981716729253 -0.07694349371687037\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2960498774645344 0.3584447593985732 0.7150353564942695 0.7857280205183521 0.7609928858865876\n",
      "-0.3047938564497188 -0.25077981716729253 -0.07694349371687037\n",
      "E3 =  0.0029361514900926268 icount = 8\n",
      "next ws: 1.2848038155474186 0.3087454971502373 0.661123134805166 0.7796853182347451 0.7548593136972546\n",
      "next bs: -0.3583532911509539 -0.29286296577517595 -0.10896847042317771\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2848038155474186 0.3087454971502373 0.661123134805166 0.7796853182347451 0.7548593136972546\n",
      "-0.3583532911509539 -0.29286296577517595 -0.10896847042317771\n",
      "E3 =  0.03428538531952395 icount = 8\n",
      "next ws: 1.2972681074599737 0.3221540179554849 0.6741531132277441 0.7849043322362097 0.7611174438942204\n",
      "next bs: -0.3452986360510676 -0.28268444285917627 -0.1012851176003544\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2972681074599737 0.3221540179554849 0.6741531132277441 0.7849043322362097 0.7611174438942204\n",
      "-0.3452986360510676 -0.28268444285917627 -0.1012851176003544\n",
      "E3 =  0.016169326076140193 icount = 8\n",
      "next ws: 1.3066797943322934 0.3318227782557314 0.6835367132117613 0.7887094963001251 0.7656487546909204\n",
      "next bs: -0.33589642144864085 -0.27530460388511696 -0.09566819342406743\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3066797943322934 0.3318227782557314 0.6835367132117613 0.7887094963001251 0.7656487546909204\n",
      "-0.33589642144864085 -0.27530460388511696 -0.09566819342406743\n",
      "E3 =  0.007962694030422001 icount = 8\n",
      "next ws: 1.3152174382296349 0.3397887225207973 0.6912482716270443 0.7919974490557055 0.7695809678792763\n",
      "next bs: -0.3281682242314808 -0.2692093013506626 -0.09100133262909806\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3152174382296349 0.3397887225207973 0.6912482716270443 0.7919974490557055 0.7695809678792763\n",
      "-0.3281682242314808 -0.2692093013506626 -0.09100133262909806\n",
      "E3 =  0.004465085521423762 icount = 8\n",
      "next ws: 1.3334502596621456 0.3506560836098484 0.7016752152161142 0.7977237076591627 0.7768548616317684\n",
      "next bs: -0.3177124053824351 -0.26092831949442985 -0.08462844659718773\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3334502596621456 0.3506560836098484 0.7016752152161142 0.7977237076591627 0.7768548616317684\n",
      "-0.3177124053824351 -0.26092831949442985 -0.08462844659718773\n",
      "E3 =  0.005849098419696436 icount = 8\n",
      "next ws: 1.3269561704499335 0.3403123914816423 0.6914857074561133 0.7948432697298601 0.77368240831118\n",
      "next bs: -0.327911635541111 -0.269064487191878 -0.09094906802800165\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3269561704499335 0.3403123914816423 0.6914857074561133 0.7948432697298601 0.77368240831118\n",
      "-0.327911635541111 -0.269064487191878 -0.09094906802800165\n",
      "E3 =  0.004204319641481585 icount = 8\n",
      "next ws: 1.2859040187116617 0.374814777255065 0.7234455955469848 0.7227967490281627 0.7378149038684005\n",
      "next bs: -0.29578921819299425 -0.24353219995527367 -0.07119518654909283\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2859040187116617 0.374814777255065 0.7234455955469848 0.7227967490281627 0.7378149038684005\n",
      "-0.29578921819299425 -0.24353219995527367 -0.07119518654909283\n",
      "E3 =  0.013227757070069736 icount = 8\n",
      "next ws: 1.2944844887138642 0.38406851030389577 0.7324250092169766 0.7258329260971178 0.7414926664587328\n",
      "next bs: -0.286791524737029 -0.23702869637655002 -0.06639680468134906\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2944844887138642 0.38406851030389577 0.7324250092169766 0.7258329260971178 0.7414926664587328\n",
      "-0.286791524737029 -0.23702869637655002 -0.06639680468134906\n",
      "E3 =  0.006269547216799125 icount = 8\n",
      "next ws: 1.3010470884305474 0.39083954801264875 0.7389813683614755 0.7280867857502662 0.7442153255958853\n",
      "next bs: -0.28022070099903346 -0.23225937615593228 -0.06286038871376767\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3010470884305474 0.39083954801264875 0.7389813683614755 0.7280867857502662 0.7442153255958853\n",
      "-0.28022070099903346 -0.23225937615593228 -0.06286038871376767\n",
      "E3 =  0.003107520336658293 icount = 8\n",
      "next ws: 1.3071349786001543 0.3965527696364363 0.7444901278485023 0.7300786637717309 0.7466334381683277\n",
      "next bs: -0.2746979284804208 -0.2282383184644257 -0.05986785595464326\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3071349786001543 0.3965527696364363 0.7444901278485023 0.7300786637717309 0.7466334381683277\n",
      "-0.2746979284804208 -0.2282383184644257 -0.05986785595464326\n",
      "E3 =  0.001772102105473724 icount = 8\n",
      "next ws: 1.3222809520765044 0.40514106777704456 0.752634927611674 0.7339154147391509 0.7515438810533844\n",
      "next bs: -0.26652172349084 -0.2222690456509088 -0.05541099727052241\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3222809520765044 0.40514106777704456 0.752634927611674 0.7339154147391509 0.7515438810533844\n",
      "-0.26652172349084 -0.2222690456509088 -0.05541099727052241\n",
      "E3 =  0.0027412441563334894 icount = 8\n",
      "next ws: 1.317717683156935 0.3984005093387028 0.745976668493542 0.7321799977826219 0.7495527536940108\n",
      "next bs: -0.27318400636413165 -0.22715859774897015 -0.05908571023091215\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.317717683156935 0.3984005093387028 0.745976668493542 0.7321799977826219 0.7495527536940108\n",
      "-0.27318400636413165 -0.22715859774897015 -0.05908571023091215\n",
      "E3 =  0.0017307605013544554 icount = 8\n",
      "next ws: 1.3079387068145212 0.35672106098813805 0.6990230631979499 0.7274353106792716 0.7444757688125536\n",
      "next bs: -0.31963984108398136 -0.2611726307111395 -0.08458102230194504\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3079387068145212 0.35672106098813805 0.6990230631979499 0.7274353106792716 0.7444757688125536\n",
      "-0.31963984108398136 -0.2611726307111395 -0.08458102230194504\n",
      "E3 =  0.02170809116680366 icount = 8\n",
      "next ws: 1.3186325406415846 0.368292747913536 0.710260737182605 0.731326371147661 0.7492768576462657\n",
      "next bs: -0.308380135621165 -0.2529819233696386 -0.07848323915676253\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3186325406415846 0.368292747913536 0.710260737182605 0.731326371147661 0.7492768576462657\n",
      "-0.308380135621165 -0.2529819233696386 -0.07848323915676253\n",
      "E3 =  0.010229418365459257 icount = 8\n",
      "next ws: 1.3266483327169851 0.37661514911976207 0.7183296804306372 0.7341539233366637 0.7527479598422018\n",
      "next bs: -0.3002943610454127 -0.24706858319123565 -0.07405251020969536\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3266483327169851 0.37661514911976207 0.7183296804306372 0.7341539233366637 0.7527479598422018\n",
      "-0.3002943610454127 -0.24706858319123565 -0.07405251020969536\n",
      "E3 =  0.005007889551219617 icount = 8\n",
      "next ws: 1.3336976498112056 0.38334848508802677 0.7248377979025825 0.7365339234342086 0.7556783340460822\n",
      "next bs: -0.2937711315236825 -0.24227952864503188 -0.07044755917046745\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3336976498112056 0.38334848508802677 0.7248377979025825 0.7365339234342086 0.7556783340460822\n",
      "-0.2937711315236825 -0.24227952864503188 -0.07044755917046745\n",
      "E3 =  0.0027389312015435137 icount = 8\n",
      "next ws: 1.3456123405787952 0.391605210762641 0.7327416188415662 0.7399915352949762 0.7600839455732925\n",
      "next bs: -0.2858431640591582 -0.23644031166352705 -0.0660349894097503\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3456123405787952 0.391605210762641 0.7327416188415662 0.7399915352949762 0.7600839455732925\n",
      "-0.2858431640591582 -0.23644031166352705 -0.0660349894097503\n",
      "E3 =  0.002766687628379055 icount = 8\n",
      "next ws: 1.3393631389168643 0.3802338983855973 0.7213908235753044 0.7374321710672134 0.7571714914127928\n",
      "next bs: -0.29719214280283207 -0.24483845986808833 -0.0724182870325825\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3393631389168643 0.3802338983855973 0.7213908235753044 0.7374321710672134 0.7571714914127928\n",
      "-0.29719214280283207 -0.24483845986808833 -0.0724182870325825\n",
      "E3 =  0.002977709229382554 icount = 8\n",
      "next ws: 1.3508359130541785 0.3884443366067928 0.7292616494224937 0.7408295471189766 0.7614981910838972\n",
      "next bs: -0.2892982189194009 -0.23901722644049034 -0.06801061503634613\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3508359130541785 0.3884443366067928 0.7292616494224937 0.7408295471189766 0.7614981910838972\n",
      "-0.2892982189194009 -0.23901722644049034 -0.06801061503634613\n",
      "E3 =  0.0028076449675731655 icount = 8\n",
      "next ws: 1.3439261933578268 0.37485951504190884 0.7156407141286181 0.7379399944658587 0.758225518027089\n",
      "next bs: -0.3029125077033767 -0.24910309383467008 -0.07569098481252606\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3439261933578268 0.37485951504190884 0.7156407141286181 0.7379399944658587 0.758225518027089\n",
      "-0.3029125077033767 -0.24910309383467008 -0.07569098481252606\n",
      "E3 =  0.0037581109762630585 icount = 8\n",
      "next ws: 1.352837361326239 0.3822535213246308 0.7227610795242314 0.7407827562327505 0.7617970103958173\n",
      "next bs: -0.2957737391389799 -0.24383511099976607 -0.07169666579857316\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.352837361326239 0.3822535213246308 0.7227610795242314 0.7407827562327505 0.7617970103958173\n",
      "-0.2957737391389799 -0.24383511099976607 -0.07169666579857316\n",
      "E3 =  0.0026294531523268576 icount = 8\n",
      "next ws: 1.3351460357494538 0.5136896979310273 0.8216542121745108 0.730075790030596 0.7512826585566836\n",
      "next bs: -0.19499261003175133 -0.1691781884034647 -0.01482324535935882\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3351460357494538 0.5136896979310273 0.8216542121745108 0.730075790030596 0.7512826585566836\n",
      "-0.19499261003175133 -0.1691781884034647 -0.01482324535935882\n",
      "E3 =  0.06258220408009196 icount = 8\n",
      "next ws: 1.3191351549257075 0.49472620947331 0.8031451650271676 0.7250181704659154 0.7455847102005105\n",
      "next bs: -0.2135304218483986 -0.182712196010942 -0.02499111057563072\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3191351549257075 0.49472620947331 0.8031451650271676 0.7250181704659154 0.7455847102005105\n",
      "-0.2135304218483986 -0.182712196010942 -0.02499111057563072\n",
      "E3 =  0.02928046786325484 icount = 8\n",
      "next ws: 1.3080136832575688 0.4814220521486353 0.7901474063787478 0.7214144201003816 0.74148412734044\n",
      "next bs: -0.22654731341072298 -0.19214967891661164 -0.032027553532876694\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3080136832575688 0.4814220521486353 0.7901474063787478 0.7214144201003816 0.74148412734044\n",
      "-0.22654731341072298 -0.19214967891661164 -0.032027553532876694\n",
      "E3 =  0.013718573227708211 icount = 8\n",
      "next ws: 1.3002662068968678 0.47201440193957644 0.7809429792075172 0.7188495634979162 0.7385460498604218\n",
      "next bs: -0.23576413389298329 -0.19879882611999078 -0.036957790644532404\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3002662068968678 0.47201440193957644 0.7809429792075172 0.7188495634979162 0.7385460498604218\n",
      "-0.23576413389298329 -0.19879882611999078 -0.036957790644532404\n",
      "E3 =  0.006470855311511164 icount = 8\n",
      "next ws: 1.294776630535757 0.46519093186192967 0.7742513304291521 0.7169946972079877 0.7364131719334323\n",
      "next bs: -0.24246345007044165 -0.20361462662989124 -0.0405144810880352\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.294776630535757 0.46519093186192967 0.7742513304291521 0.7169946972079877 0.7364131719334323\n",
      "-0.24246345007044165 -0.20361462662989124 -0.0405144810880352\n",
      "E3 =  0.0031099683595198603 icount = 8\n",
      "next ws: 1.29068310569654 0.4598960246119656 0.769037336187812 0.7155782272518177 0.7347830795875776\n",
      "next bs: -0.24768156988577208 -0.2073559908668791 -0.04326967099315373\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.29068310569654 0.4598960246119656 0.769037336187812 0.7155782272518177 0.7347830795875776\n",
      "-0.24768156988577208 -0.2073559908668791 -0.04326967099315373\n",
      "E3 =  0.0015738324208162667 icount = 8\n",
      "next ws: 1.2871231248512163 0.4548782211405064 0.7640491287644677 0.7142974869183988 0.7333153588826491\n",
      "next bs: -0.25266961972778135 -0.21092533073026778 -0.04589236153006919\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2871231248512163 0.4548782211405064 0.7640491287644677 0.7142974869183988 0.7333153588826491\n",
      "-0.25266961972778135 -0.21092533073026778 -0.04589236153006919\n",
      "E3 =  0.0009546676073172952 icount = 8\n",
      "next ws: 1.2807675662133358 0.4394741664191656 0.7473488397773542 0.7115768741390591 0.7303189134475417\n",
      "next bs: -0.2692386861256058 -0.22276057321881787 -0.05457132662302347\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2807675662133358 0.4394741664191656 0.7473488397773542 0.7115768741390591 0.7303189134475417\n",
      "-0.2692386861256058 -0.22276057321881787 -0.05457132662302347\n",
      "E3 =  0.0034161700284291692 icount = 8\n",
      "next ws: 1.2859393676763384 0.4448101967658767 0.752496158786872 0.7132589991661847 0.732334370465429\n",
      "next bs: -0.26407822901991274 -0.2190885112824201 -0.05188955033952137\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2859393676763384 0.4448101967658767 0.752496158786872 0.7132589991661847 0.732334370465429\n",
      "-0.26407822901991274 -0.2190885112824201 -0.05188955033952137\n",
      "E3 =  0.0017212236224152188 icount = 8\n",
      "next ws: 1.2910893322488104 0.44959490707880884 0.7570765766580178 0.714845856855063 0.7342483107686679\n",
      "next bs: -0.2594831837363443 -0.2158110538823388 -0.04948935563770556\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2910893322488104 0.44959490707880884 0.7570765766580178 0.714845856855063 0.7342483107686679\n",
      "-0.2594831837363443 -0.2158110538823388 -0.04948935563770556\n",
      "E3 =  0.0010445330840217165 icount = 8\n",
      "next ws: 1.3276292039927968 0.4603341583221971 0.7668974930195483 0.720428520171226 0.7417775720879648\n",
      "next bs: -0.24959399451352687 -0.208741807938752 -0.0442987737452187\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3276292039927968 0.4603341583221971 0.7668974930195483 0.720428520171226 0.7417775720879648\n",
      "-0.24959399451352687 -0.208741807938752 -0.0442987737452187\n",
      "E3 =  0.0052480706589025814 icount = 8\n",
      "next ws: 1.322548916495335 0.4538157073744569 0.7604970517600963 0.7186833552075514 0.7397596348342684\n",
      "next bs: -0.25600120126406867 -0.21335774241647593 -0.047722770415021876\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.322548916495335 0.4538157073744569 0.7604970517600963 0.7186833552075514 0.7397596348342684\n",
      "-0.25600120126406867 -0.21335774241647593 -0.047722770415021876\n",
      "E3 =  0.0025969714814803044 icount = 8\n",
      "next ws: 1.318436889493621 0.448161910360348 0.7549123062977593 0.7172233788031324 0.7380750257982189\n",
      "next bs: -0.26158903754552876 -0.21737362734358617 -0.05069355998223739\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.318436889493621 0.448161910360348 0.7549123062977593 0.7172233788031324 0.7380750257982189\n",
      "-0.26158903754552876 -0.21737362734358617 -0.05069355998223739\n",
      "E3 =  0.0014424329278480657 icount = 8\n",
      "next ws: 1.3135273930819504 0.43959064878182 0.7462360923887481 0.7153241934407751 0.7359210837650658\n",
      "next bs: -0.27025196522368855 -0.22358688160324314 -0.05527940778022459\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3135273930819504 0.43959064878182 0.7462360923887481 0.7153241934407751 0.7359210837650658\n",
      "-0.27025196522368855 -0.22358688160324314 -0.05527940778022459\n",
      "E3 =  0.0015606926085200408 icount = 8\n",
      "next ws: 1.321927448824573 0.4459396358822812 0.7522657038393644 0.717671668903487 0.7388289554063606\n",
      "next bs: -0.26419935062282324 -0.2192572999456713 -0.052093177354534975\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.321927448824573 0.4459396358822812 0.7522657038393644 0.717671668903487 0.7388289554063606\n",
      "-0.26419935062282324 -0.2192572999456713 -0.052093177354534975\n",
      "E3 =  0.0014300703974328697 icount = 8\n",
      "next ws: 1.3163529073237095 0.43520193064038976 0.7412818887969634 0.7154500742591041 0.7363258187855379\n",
      "next bs: -0.27515658271776866 -0.22712099498981364 -0.05790310294963282\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3163529073237095 0.43520193064038976 0.7412818887969634 0.7154500742591041 0.7363258187855379\n",
      "-0.27515658271776866 -0.22712099498981364 -0.05790310294963282\n",
      "E3 =  0.002094031830551139 icount = 8\n",
      "next ws: 1.3226222704062978 0.44075483088273837 0.7466016690024407 0.7173522576211528 0.7386513229374415\n",
      "next bs: -0.26982034502417446 -0.22330318333566743 -0.055091949657424644\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3226222704062978 0.44075483088273837 0.7466016690024407 0.7173522576211528 0.7386513229374415\n",
      "-0.26982034502417446 -0.22330318333566743 -0.055091949657424644\n",
      "E3 =  0.0013562736806324882 icount = 8\n",
      "next ws: 1.2822468460346237 0.46272604537202344 0.7660038904942147 0.7770966840828892 0.5485600209969342\n",
      "next bs: -0.25023359474276885 -0.20925258380183936 -0.044713455723698343\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2822468460346237 0.46272604537202344 0.7660038904942147 0.7770966840828892 0.5485600209969342\n",
      "-0.25023359474276885 -0.20925258380183936 -0.044713455723698343\n",
      "E3 =  0.03454516762107202 icount = 8\n",
      "next ws: 1.2978069762019526 0.48072736494810864 0.7834970792244547 0.7827432468721311 0.5530468593995481\n",
      "next bs: -0.23270627246930148 -0.1956321597822757 -0.03724183563753935\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2978069762019526 0.48072736494810864 0.7834970792244547 0.7827432468721311 0.5530468593995481\n",
      "-0.23270627246930148 -0.1956321597822757 -0.03724183563753935\n",
      "E3 =  0.015859731177100416 icount = 8\n",
      "next ws: 1.30826264616462 0.49280561335552125 0.7952208632805895 0.7864538584403037 0.5559626546001188\n",
      "next bs: -0.22095833460002554 -0.18643654075042657 -0.03215622741174048\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.30826264616462 0.49280561335552125 0.7952208632805895 0.7864538584403037 0.5559626546001188\n",
      "-0.22095833460002554 -0.18643654075042657 -0.03215622741174048\n",
      "E3 =  0.007322917677048811 icount = 8\n",
      "next ws: 1.3153978638464872 0.501030590034499 0.8031906741031161 0.7889474907741533 0.5579085794605227\n",
      "next bs: -0.2129708031778602 -0.1801547158440515 -0.028663767361059043\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3153978638464872 0.501030590034499 0.8031906741031161 0.7889474907741533 0.5579085794605227\n",
      "-0.2129708031778602 -0.1801547158440515 -0.028663767361059043\n",
      "E3 =  0.003406366733401786 icount = 8\n",
      "next ws: 1.3203791517248915 0.5067541014521846 0.8087219218970421 0.7906685491718314 0.5592457621510806\n",
      "next bs: -0.20742587235535673 -0.1757800565851211 -0.02622310742828537\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3203791517248915 0.5067541014521846 0.8087219218970421 0.7906685491718314 0.5592457621510806\n",
      "-0.20742587235535673 -0.1757800565851211 -0.02622310742828537\n",
      "E3 =  0.0016062089439066267 icount = 8\n",
      "next ws: 1.3240165556907837 0.5109114828591214 0.8127223658374482 0.7919130120948408 0.5602100864394176\n",
      "next bs: -0.20341391051306018 -0.17260792453593976 -0.02444910602279707\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3240165556907837 0.5109114828591214 0.8127223658374482 0.7919130120948408 0.5602100864394176\n",
      "-0.20341391051306018 -0.17260792453593976 -0.02444910602279707\n",
      "E3 =  0.0007810941805054494 icount = 8\n",
      "next ws: 1.32697893002358 0.5142637015636203 0.8159222210530802 0.7929154313085943 0.5609858592011434\n",
      "next bs: -0.20020243629675977 -0.1700647163160444 -0.023024375126096043\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.32697893002358 0.5142637015636203 0.8159222210530802 0.7929154313085943 0.5609858592011434\n",
      "-0.20020243629675977 -0.1700647163160444 -0.023024375126096043\n",
      "E3 =  0.00041404542953884117 icount = 8\n",
      "next ws: 1.3304545058347463 0.518082059970551 0.8194844853763141 0.7940651685032052 0.5618766178101403\n",
      "next bs: -0.19661969807460133 -0.16722390789335587 -0.021430721772268273\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3304545058347463 0.518082059970551 0.8194844853763141 0.7940651685032052 0.5618766178101403\n",
      "-0.19661969807460133 -0.16722390789335587 -0.021430721772268273\n",
      "E3 =  0.0003218066225780641 icount = 8\n",
      "next ws: 1.3235181189016432 0.5086656668235692 0.8088128510655826 0.7914611708851796 0.5599046801609806\n",
      "next bs: -0.20714692762453535 -0.17558321419979614 -0.026127620526969916\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.3304545058347463 0.518082059970551 0.8194844853763141 0.7940651685032052 0.5618766178101403\n",
      "-0.19661969807460133 -0.16722390789335587 -0.021430721772268273\n",
      "Tdbin, Twbin, qdot, Tdbout, ypredicted:\n",
      "20.0 13.0 310.8 30.97 31.129964743764013\n",
      "20.0 14.5 308.0 32.3 31.797025253913326\n",
      "20.0 15.3 306.0 31.5 32.133303433798375\n",
      "20.2 13.0 310.8 30.91 31.320388343553155\n",
      "20.0 14.5 308.0 32.5 31.797025253913326\n",
      "20.0 15.3 306.0 31.4 32.133303433798375\n",
      "24.0 13.0 310.8 35.59 34.9384367395469\n",
      "36.0 14.5 308.0 46.4 47.03091323704486\n",
      "Stored 'Y3_FP' (list)\n"
     ]
    }
   ],
   "source": [
    "'''#Intro to Neural Network Modeling \n",
    "# Python Neural Network Model of Spray Cooling Test System\n",
    "\n",
    ">>>>> start CodeP2.1F22\n",
    "    V.P. Carey, ME249, Fall 2022'''\n",
    "\n",
    "# version 3 print function\n",
    "from __future__ import print_function\n",
    "\n",
    "# import math, numpy and other usefuk packages\n",
    "import math\n",
    "import numpy \n",
    "\n",
    "%matplotlib inline\n",
    "# importing the required module \n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.figsize'] = [10, 8] # for square canvas\n",
    "\n",
    "\n",
    "#assembling data array\n",
    "#store array where rows are data vectors [x01, x02, x03, y3]\n",
    "xydata = []\n",
    "\n",
    "xydata = [[20./20.2, 13.0/14.5, 310.8/308.0, 30.97/32.4], [20./20.2, 14.5/14.5, 308.0/308.0, 32.3/32.4]]\n",
    "xydata.append([20./20.2, 15.3/14.5, 306.0/308.0, 31.5/32.4])\n",
    "xydata.append([20.2/20.2, 13.0/14.5, 310.8/308.0, 30.91/32.4]) \n",
    "xydata.append([20./20.2, 14.5/14.5, 308.0/308.0, 32.5/32.4]) \n",
    "xydata.append([20./20.2, 15.3/14.5, 306.0/308.0, 31.4/32.4]) \n",
    "xydata.append([24./20.2, 13.0/14.5, 310.8/308.0, 35.59/32.4]) \n",
    "xydata.append([36./20.2, 14.5/14.5, 308.0/308.0, 46.4/32.4]) \n",
    "print (xydata)\n",
    "\n",
    "#set starting values \n",
    "w01n =  1.23*1.2 \n",
    "w02n =  0.40 *1.2\n",
    "w03n =  0.70*1.2\n",
    "b1n =  -0.15*1.2\n",
    "w12n =  0.72*1.2\n",
    "b2n =  -0.12*1.2\n",
    "w23n =  0.7*1.2\n",
    "b3n =  0.01*1.2\n",
    "\n",
    "#start of batch loop  \n",
    "\n",
    "for k in range (0,200):\n",
    "    icount = 0\n",
    "    #initialize error and derivative parameters\n",
    "    E3ti = 0.\n",
    "    dE3da3 = 0.\n",
    "    dE3dw01ti = 0.\n",
    "    dE3dw02ti = 0.\n",
    "    dE3dw03ti = 0.\n",
    "    dE3db1ti = 0.\n",
    "    dE3dw12ti = 0.\n",
    "    dE3db2ti = 0.\n",
    "    dE3dw23ti = 0.\n",
    "    dE3db3ti = 0.\n",
    " \n",
    "    w01 = w01n \n",
    "    w02 = w02n\n",
    "    w03 = w03n\n",
    "    b1 = b1n \n",
    "    w12 = w12n\n",
    "    b2 = b2n \n",
    "    w23 = w23n \n",
    "    b3 = b3n \n",
    "    \n",
    "    #doing calcuations for each data point \n",
    "    for i in range(0,8):\n",
    "        #compute activation functions and their derivatives\n",
    "        z1 = w01*xydata[i][0]+w02*xydata[i][1]+w03*xydata[i][2]+b1 \n",
    "        sig1 = z1\n",
    "        sigp1 = 1.0\n",
    "        if z1 < 0.0:\n",
    "            sig1 = math.exp(z1) - 1.0\n",
    "            sigp1 = math.exp(z1)\n",
    "        a1 = sig1\n",
    "\n",
    "        z2 = w12*a1+b2 \n",
    "        sig2 = z2\n",
    "        sigp2 = 1.0\n",
    "        if z2 < 0.0:\n",
    "            sig2 = math.exp(z2) - 1.0\n",
    "            sigp2 = math.exp(z2)\n",
    "        a2 = sig2\n",
    "\n",
    "        z3 = w23*a2+b3 \n",
    "        sig3 = z3\n",
    "        sigp3 = 1.0\n",
    "        if z3 < 0.0:\n",
    "            sig3 = math.exp(z3) - 1.0\n",
    "            sigp3 = math.exp(z3)\n",
    "        a3 = sig3\n",
    "        \n",
    "        \n",
    "        #compute derivatives for backpropagation\n",
    "        #add to sum for batch average calculation\n",
    "        E3ti = E3ti +(a3 - xydata[i][3])*(a3 - xydata[i][3])\n",
    "        dE3da3 = 2.*(a3 - xydata[i][3])\n",
    "        \n",
    "        dE3dw01ti = dE3dw01ti + dE3da3*sigp3*w23*sigp2*w12*sigp1*xydata[i][0]\n",
    "        dE3dw02ti = dE3dw02ti + dE3da3*sigp3*w23*sigp2*w12*sigp1*xydata[i][1]\n",
    "        dE3dw03ti = dE3dw03ti + dE3da3*sigp3*w23*sigp2*w12*sigp1*xydata[i][2]\n",
    "        dE3db1ti = dE3db1ti + dE3da3*sigp3*w23*sigp2*w12*sigp1\n",
    "        \n",
    "        dE3dw12ti = dE3dw12ti + dE3da3*sigp3*w23*sigp2*a1\n",
    "        dE3db2ti = dE3db2ti + dE3da3*sigp3*w23*sigp2\n",
    "        \n",
    "        dE3dw23ti = dE3dw23ti + dE3da3*sigp3*a2\n",
    "        dE3db3ti = dE3db3ti + dE3da3*sigp3\n",
    "        \n",
    "        icount = i + 1\n",
    "        # end  calculations for each data point in batch\n",
    "        \n",
    "    #compute batch averaged values\n",
    "    E3 = E3ti/icount\n",
    "    dE3dw01 = dE3dw01ti/icount\n",
    "    dE3dw02 = dE3dw02ti/icount\n",
    "    dE3dw03 = dE3dw03ti/icount\n",
    "    dE3db1 = dE3db1ti/icount\n",
    "    dE3dw12 = dE3dw12ti/icount\n",
    "    dE3db2 = dE3db2ti/icount\n",
    "    dE3dw23 = dE3dw23ti/icount\n",
    "    dE3db3 = dE3db3ti/icount\n",
    "    \n",
    "    #set gam = learning rate\n",
    "    gam = 0.165\n",
    "    if E3 < 0.07: \n",
    "        gam = 0.08\n",
    "\n",
    "    w01n = w01 + gam*(-E3)/dE3dw01\n",
    "    w02n = w02 + gam*(-E3)/dE3dw02\n",
    "    w03n = w03 + gam*(-E3)/dE3dw03\n",
    "    b1n = b1 + gam*(-E3)/dE3db1\n",
    "    w12n = w12 + gam*(-E3)/dE3dw12\n",
    "    b2n = b2 + gam*(-E3)/dE3db2\n",
    "    \n",
    "    w23n = w23 + gam*(-E3)/dE3dw23\n",
    "    b3n = b3 + gam*(-E3)/dE3db3\n",
    "    \n",
    "    #printing for each iteration\n",
    "    print ('last w01, w02, w03, w12, w23:')\n",
    "    print ('last b1, b2, b3:')\n",
    "    print (w01, w02, w03, w12, w23)\n",
    "    print (b1, b2, b3)\n",
    "    print ('E3 = ', E3, 'icount =', icount)\n",
    "    print ('next ws:', w01n, w02n, w03n, w12n, w23n)\n",
    "    print ('next bs:', b1n, b2n, b3n)\n",
    "    \n",
    "    #quit if squared error is below target\n",
    "    if E3 < 0.00035:\n",
    "        break\n",
    "    \n",
    "\n",
    "print ('last w01, w02, w03, w12, w23:')\n",
    "print ('last b1, b2, b3:')\n",
    "print (w01, w02, w03, w12, w23)\n",
    "print (b1, b2, b3)\n",
    "#decomment print statements below if you want to print neuron outputs\n",
    "#print ('z1 =', z1)\n",
    "#print ('a1 =', a1)\n",
    "#print ('z2 =', z2)\n",
    "#print ('a2 =', a2)\n",
    "#print ('z3 =', z3)\n",
    "#print ('a3 =', a3)\n",
    "\n",
    "#print comparison of data and trained network predictions\n",
    "# restore raw data values  \n",
    "xydatar = [[20., 13.0, 310.8, 30.97], [20., 14.5, 308.0, 32.3]]\n",
    "xydatar.append([20., 15.3, 306.0, 31.5])\n",
    "xydatar.append([20.2, 13.0, 310.8, 30.91]) \n",
    "xydatar.append([20., 14.5, 308.0, 32.5]) \n",
    "xydatar.append([20., 15.3, 306.0, 31.4]) \n",
    "xydatar.append([24., 13.0, 310.8, 35.59]) \n",
    "xydatar.append([36., 14.5, 308.0, 46.4])\n",
    "print ('Tdbin, Twbin, qdot, Tdbout, ypredicted:')\n",
    "Y3_FP = []\n",
    "for i in range(0,8): \n",
    "    z1 = w01*xydata[i][0]+w02*xydata[i][1]+w03*xydata[i][2]+b1 \n",
    "    sig1 = z1\n",
    "    sigp1 = 1.0\n",
    "    if z1 < 0.0:\n",
    "        sig1 = math.exp(z1) - 1.0\n",
    "        sigp1 = math.exp(z1)\n",
    "    a1 = sig1\n",
    "\n",
    "    z2 = w12*a1+b2 \n",
    "    sig2 = z2\n",
    "    sigp2 = 1.0\n",
    "    if z2 < 0.0:\n",
    "        sig2 = math.exp(z2) - 1.0\n",
    "        sigp2 = math.exp(z2)\n",
    "    a2 = sig2\n",
    "\n",
    "    z3 = w23*a2+b3 \n",
    "    sig3 = z3\n",
    "    sigp3 = 1.0\n",
    "    if z3 < 0.0:\n",
    "        sig3 = math.exp(z3) - 1.0\n",
    "        sigp3 = math.exp(z3)\n",
    "    a3 = sig3\n",
    "\n",
    "    print (xydatar[i][0], xydatar[i][1], xydatar[i][2], xydatar[i][3], a3*32.4)\n",
    "    Y3_FP.append(a3*32.4)\n",
    "%store Y3_FP\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "deeaf4dc-c3bf-49e1-9af7-27b4defb55da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.990099\n",
      "1    0.990099\n",
      "2    0.990099\n",
      "3    1.000000\n",
      "4    0.990099\n",
      "5    1.000000\n",
      "6    1.188119\n",
      "7    1.782178\n",
      "Name: x01, dtype: float64 0    0.896552\n",
      "1    1.000000\n",
      "2    1.055172\n",
      "3    0.896552\n",
      "4    1.000000\n",
      "5    1.055172\n",
      "6    0.896552\n",
      "7    1.000000\n",
      "Name: x02, dtype: float64 0    1.009091\n",
      "1    1.000000\n",
      "2    0.993506\n",
      "3    1.009091\n",
      "4    1.000000\n",
      "5    0.993506\n",
      "6    1.009091\n",
      "7    1.000000\n",
      "Name: x03, dtype: float64 0    0.955835\n",
      "1    0.996883\n",
      "2    0.972192\n",
      "3    0.953983\n",
      "4    1.003055\n",
      "5    0.969106\n",
      "6    1.098423\n",
      "7    1.432055\n",
      "Name: y3, dtype: float64\n",
      "[[0.9900990099009901, 0.896551724137931, 1.009090909090909], [0.9900990099009901, 1.0, 1.0], [0.9900990099009901, 1.0551724137931036, 0.9935064935064936], [1.0, 0.896551724137931, 1.009090909090909], [0.9900990099009901, 1.0, 1.0], [1.0, 1.0551724137931036, 0.9935064935064936], [1.188118811881188, 0.896551724137931, 1.009090909090909], [1.7821782178217822, 1.0, 1.0]]\n",
      "[[0.99009901 0.89655172 1.00909091]\n",
      " [0.99009901 1.         1.        ]\n",
      " [0.99009901 1.05517241 0.99350649]\n",
      " [1.         0.89655172 1.00909091]\n",
      " [0.99009901 1.         1.        ]\n",
      " [1.         1.05517241 0.99350649]\n",
      " [1.18811881 0.89655172 1.00909091]\n",
      " [1.78217822 1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "'''>>>>> start CodeP2.2F22\n",
    "    V.P. Carey ME249, Fall 2022\n",
    "\n",
    "Intro to Neural Network Modeling \n",
    "Keras model for comparison with first principles model'''\n",
    "\n",
    "#import useful packages\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#raw data in dictionary form x01, x02, x03, y3\n",
    "my_dict = { \n",
    "    'x01' : [20., 20., 20., 20.2, 20., 20.2, 24.0, 36.],\n",
    "    'x02' : [13., 14.5, 15.3, 13., 14.5, 15.3, 13., 14.5],\n",
    "    'x03' : [310.8, 308.0, 306.0, 310.8, 308.0, 306.0, 310.8, 308.0],\n",
    "    'y3' : [30.97, 32.3, 31.5, 30.91, 32.5, 31.4, 35.59, 46.4]\n",
    "}\n",
    "#normalized inputs in array\n",
    "xdata = []\n",
    "xdata = [[20./20.2, 13.0/14.5, 310.8/308.0], [20./20.2, 14.5/14.5, 308.0/308.0]] \n",
    "xdata.append([20./20.2, 15.3/14.5, 306.0/308.0])\n",
    "xdata.append([20.2/20.2, 13.0/14.5, 310.8/308.0]) \n",
    "xdata.append([20./20.2, 14.5/14.5, 308.0/308.0]) \n",
    "xdata.append([20.2/20.2, 15.3/14.5, 306.0/308.0]) \n",
    "xdata.append([24./20.2, 13.0/14.5, 310.8/308.0]) \n",
    "xdata.append([36./20.2, 14.5/14.5, 308.0/308.0]) \n",
    "\n",
    "#data frame\n",
    "df = pd.DataFrame(my_dict)\n",
    "#devide by the median to normalize \n",
    "df.x01= df.x01/20.2\n",
    "df.x02= df.x02/14.5\n",
    "df.x03= df.x03/308.0\n",
    "#normalize output array\n",
    "df.y3= df.y3/32.401\n",
    "df.head\n",
    "print (df.x01, df.x02, df.x03, df.y3)\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "print (xdata)\n",
    "print (xarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ec27b32-2308-4608-93b3-a87a141b0344",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "Weights and biases of the layers before training the model: \n",
      "\n",
      "dense_one\n",
      "Weights\n",
      "Shape:  (3, 1) \n",
      " [[1.23]\n",
      " [0.4 ]\n",
      " [0.7 ]]\n",
      "Bias\n",
      "Shape:  (1,) \n",
      " [-0.15] \n",
      "\n",
      "dense_two\n",
      "Weights\n",
      "Shape:  (1, 1) \n",
      " [[0.72]]\n",
      "Bias\n",
      "Shape:  (1,) \n",
      " [-0.12] \n",
      "\n",
      "dense_three\n",
      "Weights\n",
      "Shape:  (1, 1) \n",
      " [[0.7]]\n",
      "Bias\n",
      "Shape:  (1,) \n",
      " [0.01] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x7f8139fd0050>,\n",
       " <keras.layers.core.Dense at 0x7f8128093c50>,\n",
       " <keras.layers.core.Dense at 0x7f81280935d0>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "#As seen below, we have created three dense layers each with just one neuron. \n",
    "#A dense layer is a layer in neural network that’s fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 3 in this case. \n",
    "#The activation function we have chosen is ReLU, which stands for rectified linear unit.\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 1.2\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=1.2)\n",
    "\n",
    "# define three layer model with one neuron in each layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, activation=K.elu, input_shape=[3],  kernel_initializer=initializer, name=\"dense_one\"),\n",
    "    keras.layers.Dense(1, activation=K.elu,  kernel_initializer=initializer, name=\"dense_two\"),\n",
    "    keras.layers.Dense(1, activation=K.elu,  kernel_initializer=initializer, name=\"dense_three\")\n",
    "  ])\n",
    "\n",
    "\n",
    "#set starting values to those used in first principles model\n",
    "w01n =  1.23 \n",
    "w02n =  0.40 \n",
    "w03n =  0.70\n",
    "b1n =  -0.15\n",
    "w12n =  0.72\n",
    "b2n =  -0.12\n",
    "w23n =  0.7\n",
    "b3n =  0.01\n",
    "\n",
    "weights0 =  [[ w01n], [w02n], [ w03n]]\n",
    "w0array= np.array(weights0)\n",
    "print(np.shape(w0array))\n",
    "bias0 = [b1n]\n",
    "bias0array= np.array(bias0)\n",
    "L0=[]\n",
    "L0.append(w0array)\n",
    "L0.append(bias0array)\n",
    "model.layers[0].set_weights(L0) \n",
    "\n",
    "weights1 =  [[ w12n]]\n",
    "w1array= np.array(weights1)\n",
    "print(np.shape(w1array))\n",
    "bias1 = [b2n]\n",
    "bias1array= np.array(bias1)\n",
    "L1=[]\n",
    "L1.append(w1array)\n",
    "L1.append(bias1array)\n",
    "model.layers[1].set_weights(L1)\n",
    "\n",
    "weights2 =  [[ w23n]]\n",
    "w2array= np.array(weights2)\n",
    "print(np.shape(w2array))\n",
    "bias2 = [b3n]\n",
    "bias2array= np.array(bias2)\n",
    "L2=[]\n",
    "L2.append(w2array)\n",
    "L2.append(bias2array)\n",
    "model.layers[2].set_weights(L2)\n",
    "\n",
    "\n",
    "print(\"Weights and biases of the layers before training the model: \\n\")\n",
    "for layer in model.layers:\n",
    "  print(layer.name)\n",
    "  print(\"Weights\")\n",
    "  print(\"Shape: \",layer.get_weights()[0].shape,'\\n',layer.get_weights()[0])\n",
    "  print(\"Bias\")\n",
    "  print(\"Shape: \",layer.get_weights()[1].shape,'\\n',layer.get_weights()[1],'\\n')\n",
    "model.layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17bb19a1-da63-4ac0-b77a-5920f365c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean absolute error. After the compilation of the model, we’ll use the fit method with 100 epochs.\n",
    "\n",
    "#Running model.fit successive times extends the calculation to addtional epochs.\n",
    "\n",
    "rms = keras.optimizers.RMSprop(0.00035)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27c32482-afe6-40f0-9f94-cfa5a76a0497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "8/8 [==============================] - 0s 685us/step - loss: 0.0148\n",
      "Epoch 2/400\n",
      "8/8 [==============================] - 0s 180us/step - loss: 0.0147\n",
      "Epoch 3/400\n",
      "8/8 [==============================] - 0s 156us/step - loss: 0.0147\n",
      "Epoch 4/400\n",
      "8/8 [==============================] - 0s 193us/step - loss: 0.0148\n",
      "Epoch 5/400\n",
      "8/8 [==============================] - 0s 194us/step - loss: 0.0147\n",
      "Epoch 6/400\n",
      "8/8 [==============================] - 0s 188us/step - loss: 0.0148\n",
      "Epoch 7/400\n",
      "8/8 [==============================] - 0s 204us/step - loss: 0.0147\n",
      "Epoch 8/400\n",
      "8/8 [==============================] - 0s 158us/step - loss: 0.0147\n",
      "Epoch 9/400\n",
      "8/8 [==============================] - 0s 197us/step - loss: 0.0148\n",
      "Epoch 10/400\n",
      "8/8 [==============================] - 0s 185us/step - loss: 0.0147\n",
      "Epoch 11/400\n",
      "8/8 [==============================] - 0s 196us/step - loss: 0.0148\n",
      "Epoch 12/400\n",
      "8/8 [==============================] - 0s 167us/step - loss: 0.0147\n",
      "Epoch 13/400\n",
      "8/8 [==============================] - 0s 180us/step - loss: 0.0148\n",
      "Epoch 14/400\n",
      "8/8 [==============================] - 0s 170us/step - loss: 0.0147\n",
      "Epoch 15/400\n",
      "8/8 [==============================] - 0s 179us/step - loss: 0.0147\n",
      "Epoch 16/400\n",
      "8/8 [==============================] - 0s 158us/step - loss: 0.0147\n",
      "Epoch 17/400\n",
      "8/8 [==============================] - 0s 162us/step - loss: 0.0147\n",
      "Epoch 18/400\n",
      "8/8 [==============================] - 0s 175us/step - loss: 0.0147\n",
      "Epoch 19/400\n",
      "8/8 [==============================] - 0s 205us/step - loss: 0.0147\n",
      "Epoch 20/400\n",
      "8/8 [==============================] - 0s 154us/step - loss: 0.0147\n",
      "Epoch 21/400\n",
      "8/8 [==============================] - 0s 163us/step - loss: 0.0147\n",
      "Epoch 22/400\n",
      "8/8 [==============================] - 0s 175us/step - loss: 0.0151\n",
      "Epoch 23/400\n",
      "8/8 [==============================] - 0s 154us/step - loss: 0.0147\n",
      "Epoch 24/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0147\n",
      "Epoch 25/400\n",
      "8/8 [==============================] - 0s 179us/step - loss: 0.0150\n",
      "Epoch 26/400\n",
      "8/8 [==============================] - 0s 166us/step - loss: 0.0146\n",
      "Epoch 27/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0147\n",
      "Epoch 28/400\n",
      "8/8 [==============================] - 0s 176us/step - loss: 0.0149\n",
      "Epoch 29/400\n",
      "8/8 [==============================] - 0s 160us/step - loss: 0.0146\n",
      "Epoch 30/400\n",
      "8/8 [==============================] - 0s 186us/step - loss: 0.0149\n",
      "Epoch 31/400\n",
      "8/8 [==============================] - 0s 181us/step - loss: 0.0146\n",
      "Epoch 32/400\n",
      "8/8 [==============================] - 0s 164us/step - loss: 0.0147\n",
      "Epoch 33/400\n",
      "8/8 [==============================] - 0s 183us/step - loss: 0.0149\n",
      "Epoch 34/400\n",
      "8/8 [==============================] - 0s 151us/step - loss: 0.0146\n",
      "Epoch 35/400\n",
      "8/8 [==============================] - 0s 183us/step - loss: 0.0147\n",
      "Epoch 36/400\n",
      "8/8 [==============================] - 0s 152us/step - loss: 0.0149\n",
      "Epoch 37/400\n",
      "8/8 [==============================] - 0s 155us/step - loss: 0.0147\n",
      "Epoch 38/400\n",
      "8/8 [==============================] - 0s 164us/step - loss: 0.0149\n",
      "Epoch 39/400\n",
      "8/8 [==============================] - 0s 166us/step - loss: 0.0146\n",
      "Epoch 40/400\n",
      "8/8 [==============================] - 0s 160us/step - loss: 0.0147\n",
      "Epoch 41/400\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0148\n",
      "Epoch 42/400\n",
      "8/8 [==============================] - 0s 164us/step - loss: 0.0147\n",
      "Epoch 43/400\n",
      "8/8 [==============================] - 0s 160us/step - loss: 0.0149\n",
      "Epoch 44/400\n",
      "8/8 [==============================] - 0s 158us/step - loss: 0.0146\n",
      "Epoch 45/400\n",
      "8/8 [==============================] - 0s 178us/step - loss: 0.0147\n",
      "Epoch 46/400\n",
      "8/8 [==============================] - 0s 164us/step - loss: 0.0148\n",
      "Epoch 47/400\n",
      "8/8 [==============================] - 0s 174us/step - loss: 0.0147\n",
      "Epoch 48/400\n",
      "8/8 [==============================] - 0s 178us/step - loss: 0.0148\n",
      "Epoch 49/400\n",
      "8/8 [==============================] - 0s 174us/step - loss: 0.0146\n",
      "Epoch 50/400\n",
      "8/8 [==============================] - 0s 176us/step - loss: 0.0147\n",
      "Epoch 51/400\n",
      "8/8 [==============================] - 0s 163us/step - loss: 0.0148\n",
      "Epoch 52/400\n",
      "8/8 [==============================] - 0s 163us/step - loss: 0.0147\n",
      "Epoch 53/400\n",
      "8/8 [==============================] - 0s 180us/step - loss: 0.0148\n",
      "Epoch 54/400\n",
      "8/8 [==============================] - 0s 169us/step - loss: 0.0146\n",
      "Epoch 55/400\n",
      "8/8 [==============================] - 0s 190us/step - loss: 0.0147\n",
      "Epoch 56/400\n",
      "8/8 [==============================] - 0s 177us/step - loss: 0.0148\n",
      "Epoch 57/400\n",
      "8/8 [==============================] - 0s 152us/step - loss: 0.0147\n",
      "Epoch 58/400\n",
      "8/8 [==============================] - 0s 188us/step - loss: 0.0148\n",
      "Epoch 59/400\n",
      "8/8 [==============================] - 0s 170us/step - loss: 0.0146\n",
      "Epoch 60/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0148\n",
      "Epoch 61/400\n",
      "8/8 [==============================] - 0s 183us/step - loss: 0.0146\n",
      "Epoch 62/400\n",
      "8/8 [==============================] - 0s 215us/step - loss: 0.0147\n",
      "Epoch 63/400\n",
      "8/8 [==============================] - 0s 195us/step - loss: 0.0148\n",
      "Epoch 64/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0146\n",
      "Epoch 65/400\n",
      "8/8 [==============================] - 0s 201us/step - loss: 0.0148\n",
      "Epoch 66/400\n",
      "8/8 [==============================] - 0s 167us/step - loss: 0.0146\n",
      "Epoch 67/400\n",
      "8/8 [==============================] - 0s 225us/step - loss: 0.0147\n",
      "Epoch 68/400\n",
      "8/8 [==============================] - 0s 193us/step - loss: 0.0148\n",
      "Epoch 69/400\n",
      "8/8 [==============================] - 0s 180us/step - loss: 0.0147\n",
      "Epoch 70/400\n",
      "8/8 [==============================] - 0s 194us/step - loss: 0.0148\n",
      "Epoch 71/400\n",
      "8/8 [==============================] - 0s 224us/step - loss: 0.0146\n",
      "Epoch 72/400\n",
      "8/8 [==============================] - 0s 183us/step - loss: 0.0147\n",
      "Epoch 73/400\n",
      "8/8 [==============================] - 0s 193us/step - loss: 0.0148\n",
      "Epoch 74/400\n",
      "8/8 [==============================] - 0s 189us/step - loss: 0.0147\n",
      "Epoch 75/400\n",
      "8/8 [==============================] - 0s 170us/step - loss: 0.0148\n",
      "Epoch 76/400\n",
      "8/8 [==============================] - 0s 155us/step - loss: 0.0146\n",
      "Epoch 77/400\n",
      "8/8 [==============================] - 0s 176us/step - loss: 0.0147\n",
      "Epoch 78/400\n",
      "8/8 [==============================] - 0s 204us/step - loss: 0.0148\n",
      "Epoch 79/400\n",
      "8/8 [==============================] - 0s 202us/step - loss: 0.0147\n",
      "Epoch 80/400\n",
      "8/8 [==============================] - 0s 182us/step - loss: 0.0148\n",
      "Epoch 81/400\n",
      "8/8 [==============================] - 0s 189us/step - loss: 0.0146\n",
      "Epoch 82/400\n",
      "8/8 [==============================] - 0s 203us/step - loss: 0.0148\n",
      "Epoch 83/400\n",
      "8/8 [==============================] - 0s 194us/step - loss: 0.0146\n",
      "Epoch 84/400\n",
      "8/8 [==============================] - 0s 192us/step - loss: 0.0147\n",
      "Epoch 85/400\n",
      "8/8 [==============================] - 0s 208us/step - loss: 0.0148\n",
      "Epoch 86/400\n",
      "8/8 [==============================] - 0s 210us/step - loss: 0.0146\n",
      "Epoch 87/400\n",
      "8/8 [==============================] - 0s 197us/step - loss: 0.0148\n",
      "Epoch 88/400\n",
      "8/8 [==============================] - 0s 159us/step - loss: 0.0146\n",
      "Epoch 89/400\n",
      "8/8 [==============================] - 0s 175us/step - loss: 0.0147\n",
      "Epoch 90/400\n",
      "8/8 [==============================] - 0s 160us/step - loss: 0.0148\n",
      "Epoch 91/400\n",
      "8/8 [==============================] - 0s 162us/step - loss: 0.0146\n",
      "Epoch 92/400\n",
      "8/8 [==============================] - 0s 192us/step - loss: 0.0148\n",
      "Epoch 93/400\n",
      "8/8 [==============================] - 0s 176us/step - loss: 0.0146\n",
      "Epoch 94/400\n",
      "8/8 [==============================] - 0s 207us/step - loss: 0.0147\n",
      "Epoch 95/400\n",
      "8/8 [==============================] - 0s 195us/step - loss: 0.0148\n",
      "Epoch 96/400\n",
      "8/8 [==============================] - 0s 214us/step - loss: 0.0147\n",
      "Epoch 97/400\n",
      "8/8 [==============================] - 0s 219us/step - loss: 0.0148\n",
      "Epoch 98/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0146\n",
      "Epoch 99/400\n",
      "8/8 [==============================] - 0s 296us/step - loss: 0.0147\n",
      "Epoch 100/400\n",
      "8/8 [==============================] - 0s 235us/step - loss: 0.0148\n",
      "Epoch 101/400\n",
      "8/8 [==============================] - 0s 205us/step - loss: 0.0147\n",
      "Epoch 102/400\n",
      "8/8 [==============================] - 0s 304us/step - loss: 0.0148\n",
      "Epoch 103/400\n",
      "8/8 [==============================] - 0s 195us/step - loss: 0.0146\n",
      "Epoch 104/400\n",
      "8/8 [==============================] - 0s 335us/step - loss: 0.0148\n",
      "Epoch 105/400\n",
      "8/8 [==============================] - 0s 205us/step - loss: 0.0146\n",
      "Epoch 106/400\n",
      "8/8 [==============================] - 0s 216us/step - loss: 0.0147\n",
      "Epoch 107/400\n",
      "8/8 [==============================] - 0s 314us/step - loss: 0.0148\n",
      "Epoch 108/400\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0146\n",
      "Epoch 109/400\n",
      "8/8 [==============================] - 0s 184us/step - loss: 0.0148\n",
      "Epoch 110/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0146\n",
      "Epoch 111/400\n",
      "8/8 [==============================] - 0s 202us/step - loss: 0.0147\n",
      "Epoch 112/400\n",
      "8/8 [==============================] - 0s 185us/step - loss: 0.0148\n",
      "Epoch 113/400\n",
      "8/8 [==============================] - 0s 186us/step - loss: 0.0146\n",
      "Epoch 114/400\n",
      "8/8 [==============================] - 0s 192us/step - loss: 0.0148\n",
      "Epoch 115/400\n",
      "8/8 [==============================] - 0s 255us/step - loss: 0.0146\n",
      "Epoch 116/400\n",
      "8/8 [==============================] - 0s 177us/step - loss: 0.0147\n",
      "Epoch 117/400\n",
      "8/8 [==============================] - 0s 197us/step - loss: 0.0148\n",
      "Epoch 118/400\n",
      "8/8 [==============================] - 0s 167us/step - loss: 0.0147\n",
      "Epoch 119/400\n",
      "8/8 [==============================] - 0s 234us/step - loss: 0.0148\n",
      "Epoch 120/400\n",
      "8/8 [==============================] - 0s 209us/step - loss: 0.0146\n",
      "Epoch 121/400\n",
      "8/8 [==============================] - 0s 161us/step - loss: 0.0147\n",
      "Epoch 122/400\n",
      "8/8 [==============================] - 0s 201us/step - loss: 0.0148\n",
      "Epoch 123/400\n",
      "8/8 [==============================] - 0s 159us/step - loss: 0.0147\n",
      "Epoch 124/400\n",
      "8/8 [==============================] - 0s 231us/step - loss: 0.0148\n",
      "Epoch 125/400\n",
      "8/8 [==============================] - 0s 238us/step - loss: 0.0146\n",
      "Epoch 126/400\n",
      "8/8 [==============================] - 0s 185us/step - loss: 0.0148\n",
      "Epoch 127/400\n",
      "8/8 [==============================] - 0s 214us/step - loss: 0.0146\n",
      "Epoch 128/400\n",
      "8/8 [==============================] - 0s 279us/step - loss: 0.0147\n",
      "Epoch 129/400\n",
      "8/8 [==============================] - 0s 165us/step - loss: 0.0148\n",
      "Epoch 130/400\n",
      "8/8 [==============================] - 0s 180us/step - loss: 0.0146\n",
      "Epoch 131/400\n",
      "8/8 [==============================] - 0s 193us/step - loss: 0.0148\n",
      "Epoch 132/400\n",
      "8/8 [==============================] - 0s 180us/step - loss: 0.0146\n",
      "Epoch 133/400\n",
      "8/8 [==============================] - 0s 246us/step - loss: 0.0147\n",
      "Epoch 134/400\n",
      "8/8 [==============================] - 0s 239us/step - loss: 0.0148\n",
      "Epoch 135/400\n",
      "8/8 [==============================] - 0s 183us/step - loss: 0.0146\n",
      "Epoch 136/400\n",
      "8/8 [==============================] - 0s 183us/step - loss: 0.0148\n",
      "Epoch 137/400\n",
      "8/8 [==============================] - 0s 199us/step - loss: 0.0146\n",
      "Epoch 138/400\n",
      "8/8 [==============================] - 0s 196us/step - loss: 0.0147\n",
      "Epoch 139/400\n",
      "8/8 [==============================] - 0s 175us/step - loss: 0.0148\n",
      "Epoch 140/400\n",
      "8/8 [==============================] - 0s 199us/step - loss: 0.0147\n",
      "Epoch 141/400\n",
      "8/8 [==============================] - 0s 227us/step - loss: 0.0148\n",
      "Epoch 142/400\n",
      "8/8 [==============================] - 0s 167us/step - loss: 0.0146\n",
      "Epoch 143/400\n",
      "8/8 [==============================] - 0s 161us/step - loss: 0.0147\n",
      "Epoch 144/400\n",
      "8/8 [==============================] - 0s 217us/step - loss: 0.0148\n",
      "Epoch 145/400\n",
      "8/8 [==============================] - 0s 169us/step - loss: 0.0147\n",
      "Epoch 146/400\n",
      "8/8 [==============================] - 0s 191us/step - loss: 0.0148\n",
      "Epoch 147/400\n",
      "8/8 [==============================] - 0s 153us/step - loss: 0.0146\n",
      "Epoch 148/400\n",
      "8/8 [==============================] - 0s 242us/step - loss: 0.0148\n",
      "Epoch 149/400\n",
      "8/8 [==============================] - 0s 177us/step - loss: 0.0146\n",
      "Epoch 150/400\n",
      "8/8 [==============================] - 0s 230us/step - loss: 0.0147\n",
      "Epoch 151/400\n",
      "8/8 [==============================] - 0s 199us/step - loss: 0.0148\n",
      "Epoch 152/400\n",
      "8/8 [==============================] - 0s 194us/step - loss: 0.0146\n",
      "Epoch 153/400\n",
      "8/8 [==============================] - 0s 177us/step - loss: 0.0148\n",
      "Epoch 154/400\n",
      "8/8 [==============================] - 0s 186us/step - loss: 0.0146\n",
      "Epoch 155/400\n",
      "8/8 [==============================] - 0s 169us/step - loss: 0.0147\n",
      "Epoch 156/400\n",
      "8/8 [==============================] - 0s 182us/step - loss: 0.0148\n",
      "Epoch 157/400\n",
      "8/8 [==============================] - 0s 215us/step - loss: 0.0146\n",
      "Epoch 158/400\n",
      "8/8 [==============================] - 0s 225us/step - loss: 0.0148\n",
      "Epoch 159/400\n",
      "8/8 [==============================] - 0s 202us/step - loss: 0.0146\n",
      "Epoch 160/400\n",
      "8/8 [==============================] - 0s 212us/step - loss: 0.0147\n",
      "Epoch 161/400\n",
      "8/8 [==============================] - 0s 175us/step - loss: 0.0148\n",
      "Epoch 162/400\n",
      "8/8 [==============================] - 0s 189us/step - loss: 0.0147\n",
      "Epoch 163/400\n",
      "8/8 [==============================] - 0s 235us/step - loss: 0.0148\n",
      "Epoch 164/400\n",
      "8/8 [==============================] - 0s 215us/step - loss: 0.0146\n",
      "Epoch 165/400\n",
      "8/8 [==============================] - 0s 186us/step - loss: 0.0147\n",
      "Epoch 166/400\n",
      "8/8 [==============================] - 0s 164us/step - loss: 0.0148\n",
      "Epoch 167/400\n",
      "8/8 [==============================] - 0s 230us/step - loss: 0.0147\n",
      "Epoch 168/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0148\n",
      "Epoch 169/400\n",
      "8/8 [==============================] - 0s 174us/step - loss: 0.0146\n",
      "Epoch 170/400\n",
      "8/8 [==============================] - 0s 230us/step - loss: 0.0148\n",
      "Epoch 171/400\n",
      "8/8 [==============================] - 0s 161us/step - loss: 0.0146\n",
      "Epoch 172/400\n",
      "8/8 [==============================] - 0s 250us/step - loss: 0.0147\n",
      "Epoch 173/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0148\n",
      "Epoch 174/400\n",
      "8/8 [==============================] - 0s 216us/step - loss: 0.0146\n",
      "Epoch 175/400\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0148\n",
      "Epoch 176/400\n",
      "8/8 [==============================] - 0s 165us/step - loss: 0.0146\n",
      "Epoch 177/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0147\n",
      "Epoch 178/400\n",
      "8/8 [==============================] - 0s 176us/step - loss: 0.0148\n",
      "Epoch 179/400\n",
      "8/8 [==============================] - 0s 162us/step - loss: 0.0146\n",
      "Epoch 180/400\n",
      "8/8 [==============================] - 0s 209us/step - loss: 0.0148\n",
      "Epoch 181/400\n",
      "8/8 [==============================] - 0s 209us/step - loss: 0.0146\n",
      "Epoch 182/400\n",
      "8/8 [==============================] - 0s 246us/step - loss: 0.0147\n",
      "Epoch 183/400\n",
      "8/8 [==============================] - 0s 220us/step - loss: 0.0148\n",
      "Epoch 184/400\n",
      "8/8 [==============================] - 0s 220us/step - loss: 0.0146\n",
      "Epoch 185/400\n",
      "8/8 [==============================] - 0s 206us/step - loss: 0.0148\n",
      "Epoch 186/400\n",
      "8/8 [==============================] - 0s 177us/step - loss: 0.0146\n",
      "Epoch 187/400\n",
      "8/8 [==============================] - 0s 191us/step - loss: 0.0147\n",
      "Epoch 188/400\n",
      "8/8 [==============================] - 0s 175us/step - loss: 0.0148\n",
      "Epoch 189/400\n",
      "8/8 [==============================] - 0s 157us/step - loss: 0.0147\n",
      "Epoch 190/400\n",
      "8/8 [==============================] - 0s 169us/step - loss: 0.0148\n",
      "Epoch 191/400\n",
      "8/8 [==============================] - 0s 202us/step - loss: 0.0146\n",
      "Epoch 192/400\n",
      "8/8 [==============================] - 0s 208us/step - loss: 0.0148\n",
      "Epoch 193/400\n",
      "8/8 [==============================] - 0s 215us/step - loss: 0.0146\n",
      "Epoch 194/400\n",
      "8/8 [==============================] - 0s 215us/step - loss: 0.0147\n",
      "Epoch 195/400\n",
      "8/8 [==============================] - 0s 193us/step - loss: 0.0148\n",
      "Epoch 196/400\n",
      "8/8 [==============================] - 0s 169us/step - loss: 0.0146\n",
      "Epoch 197/400\n",
      "8/8 [==============================] - 0s 184us/step - loss: 0.0148\n",
      "Epoch 198/400\n",
      "8/8 [==============================] - 0s 156us/step - loss: 0.0146\n",
      "Epoch 199/400\n",
      "8/8 [==============================] - 0s 238us/step - loss: 0.0147\n",
      "Epoch 200/400\n",
      "8/8 [==============================] - 0s 179us/step - loss: 0.0148\n",
      "Epoch 201/400\n",
      "8/8 [==============================] - 0s 160us/step - loss: 0.0146\n",
      "Epoch 202/400\n",
      "8/8 [==============================] - 0s 187us/step - loss: 0.0148\n",
      "Epoch 203/400\n",
      "8/8 [==============================] - 0s 179us/step - loss: 0.0146\n",
      "Epoch 204/400\n",
      "8/8 [==============================] - 0s 186us/step - loss: 0.0147\n",
      "Epoch 205/400\n",
      "8/8 [==============================] - 0s 209us/step - loss: 0.0148\n",
      "Epoch 206/400\n",
      "8/8 [==============================] - 0s 164us/step - loss: 0.0146\n",
      "Epoch 207/400\n",
      "8/8 [==============================] - 0s 240us/step - loss: 0.0148\n",
      "Epoch 208/400\n",
      "8/8 [==============================] - 0s 194us/step - loss: 0.0146\n",
      "Epoch 209/400\n",
      "8/8 [==============================] - 0s 206us/step - loss: 0.0147\n",
      "Epoch 210/400\n",
      "8/8 [==============================] - 0s 214us/step - loss: 0.0148\n",
      "Epoch 211/400\n",
      "8/8 [==============================] - 0s 184us/step - loss: 0.0147\n",
      "Epoch 212/400\n",
      "8/8 [==============================] - 0s 178us/step - loss: 0.0148\n",
      "Epoch 213/400\n",
      "8/8 [==============================] - 0s 177us/step - loss: 0.0146\n",
      "Epoch 214/400\n",
      "8/8 [==============================] - 0s 205us/step - loss: 0.0148\n",
      "Epoch 215/400\n",
      "8/8 [==============================] - 0s 200us/step - loss: 0.0146\n",
      "Epoch 216/400\n",
      "8/8 [==============================] - 0s 197us/step - loss: 0.0147\n",
      "Epoch 217/400\n",
      "8/8 [==============================] - 0s 222us/step - loss: 0.0148\n",
      "Epoch 218/400\n",
      "8/8 [==============================] - 0s 388us/step - loss: 0.0146\n",
      "Epoch 219/400\n",
      "8/8 [==============================] - 0s 234us/step - loss: 0.0148\n",
      "Epoch 220/400\n",
      "8/8 [==============================] - 0s 189us/step - loss: 0.0146\n",
      "Epoch 221/400\n",
      "8/8 [==============================] - 0s 194us/step - loss: 0.0147\n",
      "Epoch 222/400\n",
      "8/8 [==============================] - 0s 182us/step - loss: 0.0148\n",
      "Epoch 223/400\n",
      "8/8 [==============================] - 0s 193us/step - loss: 0.0146\n",
      "Epoch 224/400\n",
      "8/8 [==============================] - 0s 182us/step - loss: 0.0148\n",
      "Epoch 225/400\n",
      "8/8 [==============================] - 0s 164us/step - loss: 0.0146\n",
      "Epoch 226/400\n",
      "8/8 [==============================] - 0s 229us/step - loss: 0.0147\n",
      "Epoch 227/400\n",
      "8/8 [==============================] - 0s 208us/step - loss: 0.0148\n",
      "Epoch 228/400\n",
      "8/8 [==============================] - 0s 165us/step - loss: 0.0146\n",
      "Epoch 229/400\n",
      "8/8 [==============================] - 0s 162us/step - loss: 0.0148\n",
      "Epoch 230/400\n",
      "8/8 [==============================] - 0s 224us/step - loss: 0.0146\n",
      "Epoch 231/400\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0147\n",
      "Epoch 232/400\n",
      "8/8 [==============================] - 0s 173us/step - loss: 0.0147\n",
      "Epoch 233/400\n",
      "8/8 [==============================] - 0s 163us/step - loss: 0.0147\n",
      "Epoch 234/400\n",
      "8/8 [==============================] - 0s 178us/step - loss: 0.0148\n",
      "Epoch 235/400\n",
      "8/8 [==============================] - 0s 174us/step - loss: 0.0146\n",
      "Epoch 236/400\n",
      "8/8 [==============================] - 0s 198us/step - loss: 0.0148\n",
      "Epoch 237/400\n",
      "8/8 [==============================] - 0s 169us/step - loss: 0.0146\n",
      "Epoch 238/400\n",
      "8/8 [==============================] - 0s 262us/step - loss: 0.0147\n",
      "Epoch 239/400\n",
      "8/8 [==============================] - 0s 209us/step - loss: 0.0148\n",
      "Epoch 240/400\n",
      "8/8 [==============================] - 0s 185us/step - loss: 0.0146\n",
      "Epoch 241/400\n",
      "8/8 [==============================] - 0s 233us/step - loss: 0.0148\n",
      "Epoch 242/400\n",
      "8/8 [==============================] - 0s 191us/step - loss: 0.0146\n",
      "Epoch 243/400\n",
      "8/8 [==============================] - 0s 219us/step - loss: 0.0147\n",
      "Epoch 244/400\n",
      "8/8 [==============================] - 0s 284us/step - loss: 0.0147\n",
      "Epoch 245/400\n",
      "8/8 [==============================] - 0s 285us/step - loss: 0.0146\n",
      "Epoch 246/400\n",
      "8/8 [==============================] - 0s 203us/step - loss: 0.0148\n",
      "Epoch 247/400\n",
      "8/8 [==============================] - 0s 181us/step - loss: 0.0146\n",
      "Epoch 248/400\n",
      "8/8 [==============================] - 0s 197us/step - loss: 0.0147\n",
      "Epoch 249/400\n",
      "8/8 [==============================] - 0s 166us/step - loss: 0.0147\n",
      "Epoch 250/400\n",
      "8/8 [==============================] - 0s 161us/step - loss: 0.0146\n",
      "Epoch 251/400\n",
      "8/8 [==============================] - 0s 174us/step - loss: 0.0148\n",
      "Epoch 252/400\n",
      "8/8 [==============================] - 0s 238us/step - loss: 0.0146\n",
      "Epoch 253/400\n",
      "8/8 [==============================] - 0s 185us/step - loss: 0.0147\n",
      "Epoch 254/400\n",
      "8/8 [==============================] - 0s 162us/step - loss: 0.0147\n",
      "Epoch 255/400\n",
      "8/8 [==============================] - 0s 157us/step - loss: 0.0146\n",
      "Epoch 256/400\n",
      "8/8 [==============================] - 0s 170us/step - loss: 0.0148\n",
      "Epoch 257/400\n",
      "8/8 [==============================] - 0s 151us/step - loss: 0.0146\n",
      "Epoch 258/400\n",
      "8/8 [==============================] - 0s 191us/step - loss: 0.0147\n",
      "Epoch 259/400\n",
      "8/8 [==============================] - 0s 212us/step - loss: 0.0147\n",
      "Epoch 260/400\n",
      "8/8 [==============================] - 0s 195us/step - loss: 0.0147\n",
      "Epoch 261/400\n",
      "8/8 [==============================] - 0s 215us/step - loss: 0.0147\n",
      "Epoch 262/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0146\n",
      "Epoch 263/400\n",
      "8/8 [==============================] - 0s 184us/step - loss: 0.0148\n",
      "Epoch 264/400\n",
      "8/8 [==============================] - 0s 226us/step - loss: 0.0146\n",
      "Epoch 265/400\n",
      "8/8 [==============================] - 0s 231us/step - loss: 0.0147\n",
      "Epoch 266/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0147\n",
      "Epoch 267/400\n",
      "8/8 [==============================] - 0s 201us/step - loss: 0.0146\n",
      "Epoch 268/400\n",
      "8/8 [==============================] - 0s 201us/step - loss: 0.0148\n",
      "Epoch 269/400\n",
      "8/8 [==============================] - 0s 186us/step - loss: 0.0146\n",
      "Epoch 270/400\n",
      "8/8 [==============================] - 0s 255us/step - loss: 0.0147\n",
      "Epoch 271/400\n",
      "8/8 [==============================] - 0s 185us/step - loss: 0.0147\n",
      "Epoch 272/400\n",
      "8/8 [==============================] - 0s 167us/step - loss: 0.0146\n",
      "Epoch 273/400\n",
      "8/8 [==============================] - 0s 157us/step - loss: 0.0148\n",
      "Epoch 274/400\n",
      "8/8 [==============================] - 0s 151us/step - loss: 0.0146\n",
      "Epoch 275/400\n",
      "8/8 [==============================] - 0s 174us/step - loss: 0.0147\n",
      "Epoch 276/400\n",
      "8/8 [==============================] - 0s 145us/step - loss: 0.0147\n",
      "Epoch 277/400\n",
      "8/8 [==============================] - 0s 214us/step - loss: 0.0146\n",
      "Epoch 278/400\n",
      "8/8 [==============================] - 0s 180us/step - loss: 0.0147\n",
      "Epoch 279/400\n",
      "8/8 [==============================] - 0s 216us/step - loss: 0.0146\n",
      "Epoch 280/400\n",
      "8/8 [==============================] - 0s 224us/step - loss: 0.0147\n",
      "Epoch 281/400\n",
      "8/8 [==============================] - 0s 188us/step - loss: 0.0147\n",
      "Epoch 282/400\n",
      "8/8 [==============================] - 0s 182us/step - loss: 0.0147\n",
      "Epoch 283/400\n",
      "8/8 [==============================] - 0s 222us/step - loss: 0.0147\n",
      "Epoch 284/400\n",
      "8/8 [==============================] - 0s 255us/step - loss: 0.0146\n",
      "Epoch 285/400\n",
      "8/8 [==============================] - 0s 265us/step - loss: 0.0148\n",
      "Epoch 286/400\n",
      "8/8 [==============================] - 0s 273us/step - loss: 0.0146\n",
      "Epoch 287/400\n",
      "8/8 [==============================] - 0s 269us/step - loss: 0.0147\n",
      "Epoch 288/400\n",
      "8/8 [==============================] - 0s 196us/step - loss: 0.0147\n",
      "Epoch 289/400\n",
      "8/8 [==============================] - 0s 179us/step - loss: 0.0146\n",
      "Epoch 290/400\n",
      "8/8 [==============================] - 0s 181us/step - loss: 0.0147\n",
      "Epoch 291/400\n",
      "8/8 [==============================] - 0s 184us/step - loss: 0.0146\n",
      "Epoch 292/400\n",
      "8/8 [==============================] - 0s 253us/step - loss: 0.0147\n",
      "Epoch 293/400\n",
      "8/8 [==============================] - 0s 194us/step - loss: 0.0147\n",
      "Epoch 294/400\n",
      "8/8 [==============================] - 0s 204us/step - loss: 0.0146\n",
      "Epoch 295/400\n",
      "8/8 [==============================] - 0s 238us/step - loss: 0.0147\n",
      "Epoch 296/400\n",
      "8/8 [==============================] - 0s 202us/step - loss: 0.0146\n",
      "Epoch 297/400\n",
      "8/8 [==============================] - 0s 200us/step - loss: 0.0147\n",
      "Epoch 298/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0147\n",
      "Epoch 299/400\n",
      "8/8 [==============================] - 0s 158us/step - loss: 0.0146\n",
      "Epoch 300/400\n",
      "8/8 [==============================] - 0s 157us/step - loss: 0.0147\n",
      "Epoch 301/400\n",
      "8/8 [==============================] - 0s 169us/step - loss: 0.0146\n",
      "Epoch 302/400\n",
      "8/8 [==============================] - 0s 169us/step - loss: 0.0147\n",
      "Epoch 303/400\n",
      "8/8 [==============================] - 0s 196us/step - loss: 0.0147\n",
      "Epoch 304/400\n",
      "8/8 [==============================] - 0s 187us/step - loss: 0.0146\n",
      "Epoch 305/400\n",
      "8/8 [==============================] - 0s 215us/step - loss: 0.0147\n",
      "Epoch 306/400\n",
      "8/8 [==============================] - 0s 225us/step - loss: 0.0146\n",
      "Epoch 307/400\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0147\n",
      "Epoch 308/400\n",
      "8/8 [==============================] - 0s 219us/step - loss: 0.0146\n",
      "Epoch 309/400\n",
      "8/8 [==============================] - 0s 226us/step - loss: 0.0147\n",
      "Epoch 310/400\n",
      "8/8 [==============================] - 0s 227us/step - loss: 0.0147\n",
      "Epoch 311/400\n",
      "8/8 [==============================] - 0s 244us/step - loss: 0.0146\n",
      "Epoch 312/400\n",
      "8/8 [==============================] - 0s 251us/step - loss: 0.0147\n",
      "Epoch 313/400\n",
      "8/8 [==============================] - 0s 166us/step - loss: 0.0146\n",
      "Epoch 314/400\n",
      "8/8 [==============================] - 0s 192us/step - loss: 0.0147\n",
      "Epoch 315/400\n",
      "8/8 [==============================] - 0s 262us/step - loss: 0.0147\n",
      "Epoch 316/400\n",
      "8/8 [==============================] - 0s 185us/step - loss: 0.0146\n",
      "Epoch 317/400\n",
      "8/8 [==============================] - 0s 205us/step - loss: 0.0147\n",
      "Epoch 318/400\n",
      "8/8 [==============================] - 0s 207us/step - loss: 0.0146\n",
      "Epoch 319/400\n",
      "8/8 [==============================] - 0s 189us/step - loss: 0.0147\n",
      "Epoch 320/400\n",
      "8/8 [==============================] - 0s 222us/step - loss: 0.0147\n",
      "Epoch 321/400\n",
      "8/8 [==============================] - 0s 218us/step - loss: 0.0146\n",
      "Epoch 322/400\n",
      "8/8 [==============================] - 0s 262us/step - loss: 0.0147\n",
      "Epoch 323/400\n",
      "8/8 [==============================] - 0s 200us/step - loss: 0.0146\n",
      "Epoch 324/400\n",
      "8/8 [==============================] - 0s 266us/step - loss: 0.0147\n",
      "Epoch 325/400\n",
      "8/8 [==============================] - 0s 201us/step - loss: 0.0147\n",
      "Epoch 326/400\n",
      "8/8 [==============================] - 0s 185us/step - loss: 0.0146\n",
      "Epoch 327/400\n",
      "8/8 [==============================] - 0s 195us/step - loss: 0.0147\n",
      "Epoch 328/400\n",
      "8/8 [==============================] - 0s 178us/step - loss: 0.0146\n",
      "Epoch 329/400\n",
      "8/8 [==============================] - 0s 232us/step - loss: 0.0147\n",
      "Epoch 330/400\n",
      "8/8 [==============================] - 0s 204us/step - loss: 0.0146\n",
      "Epoch 331/400\n",
      "8/8 [==============================] - 0s 270us/step - loss: 0.0147\n",
      "Epoch 332/400\n",
      "8/8 [==============================] - 0s 222us/step - loss: 0.0147\n",
      "Epoch 333/400\n",
      "8/8 [==============================] - 0s 165us/step - loss: 0.0146\n",
      "Epoch 334/400\n",
      "8/8 [==============================] - 0s 192us/step - loss: 0.0147\n",
      "Epoch 335/400\n",
      "8/8 [==============================] - 0s 179us/step - loss: 0.0146\n",
      "Epoch 336/400\n",
      "8/8 [==============================] - 0s 189us/step - loss: 0.0147\n",
      "Epoch 337/400\n",
      "8/8 [==============================] - 0s 187us/step - loss: 0.0147\n",
      "Epoch 338/400\n",
      "8/8 [==============================] - 0s 193us/step - loss: 0.0146\n",
      "Epoch 339/400\n",
      "8/8 [==============================] - 0s 251us/step - loss: 0.0147\n",
      "Epoch 340/400\n",
      "8/8 [==============================] - 0s 200us/step - loss: 0.0146\n",
      "Epoch 341/400\n",
      "8/8 [==============================] - 0s 197us/step - loss: 0.0147\n",
      "Epoch 342/400\n",
      "8/8 [==============================] - 0s 200us/step - loss: 0.0147\n",
      "Epoch 343/400\n",
      "8/8 [==============================] - 0s 160us/step - loss: 0.0146\n",
      "Epoch 344/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0147\n",
      "Epoch 345/400\n",
      "8/8 [==============================] - 0s 244us/step - loss: 0.0146\n",
      "Epoch 346/400\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0147\n",
      "Epoch 347/400\n",
      "8/8 [==============================] - 0s 210us/step - loss: 0.0147\n",
      "Epoch 348/400\n",
      "8/8 [==============================] - 0s 167us/step - loss: 0.0146\n",
      "Epoch 349/400\n",
      "8/8 [==============================] - 0s 201us/step - loss: 0.0147\n",
      "Epoch 350/400\n",
      "8/8 [==============================] - 0s 242us/step - loss: 0.0146\n",
      "Epoch 351/400\n",
      "8/8 [==============================] - 0s 148us/step - loss: 0.0147\n",
      "Epoch 352/400\n",
      "8/8 [==============================] - 0s 169us/step - loss: 0.0146\n",
      "Epoch 353/400\n",
      "8/8 [==============================] - 0s 154us/step - loss: 0.0147\n",
      "Epoch 354/400\n",
      "8/8 [==============================] - 0s 170us/step - loss: 0.0147\n",
      "Epoch 355/400\n",
      "8/8 [==============================] - 0s 175us/step - loss: 0.0146\n",
      "Epoch 356/400\n",
      "8/8 [==============================] - 0s 175us/step - loss: 0.0147\n",
      "Epoch 357/400\n",
      "8/8 [==============================] - 0s 188us/step - loss: 0.0146\n",
      "Epoch 358/400\n",
      "8/8 [==============================] - 0s 200us/step - loss: 0.0147\n",
      "Epoch 359/400\n",
      "8/8 [==============================] - 0s 209us/step - loss: 0.0147\n",
      "Epoch 360/400\n",
      "8/8 [==============================] - 0s 225us/step - loss: 0.0146\n",
      "Epoch 361/400\n",
      "8/8 [==============================] - 0s 252us/step - loss: 0.0147\n",
      "Epoch 362/400\n",
      "8/8 [==============================] - 0s 274us/step - loss: 0.0146\n",
      "Epoch 363/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0147\n",
      "Epoch 364/400\n",
      "8/8 [==============================] - 0s 181us/step - loss: 0.0147\n",
      "Epoch 365/400\n",
      "8/8 [==============================] - 0s 196us/step - loss: 0.0146\n",
      "Epoch 366/400\n",
      "8/8 [==============================] - 0s 208us/step - loss: 0.0147\n",
      "Epoch 367/400\n",
      "8/8 [==============================] - 0s 217us/step - loss: 0.0146\n",
      "Epoch 368/400\n",
      "8/8 [==============================] - 0s 192us/step - loss: 0.0147\n",
      "Epoch 369/400\n",
      "8/8 [==============================] - 0s 187us/step - loss: 0.0147\n",
      "Epoch 370/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0146\n",
      "Epoch 371/400\n",
      "8/8 [==============================] - 0s 229us/step - loss: 0.0147\n",
      "Epoch 372/400\n",
      "8/8 [==============================] - 0s 167us/step - loss: 0.0146\n",
      "Epoch 373/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0147\n",
      "Epoch 374/400\n",
      "8/8 [==============================] - 0s 182us/step - loss: 0.0147\n",
      "Epoch 375/400\n",
      "8/8 [==============================] - 0s 167us/step - loss: 0.0146\n",
      "Epoch 376/400\n",
      "8/8 [==============================] - 0s 177us/step - loss: 0.0147\n",
      "Epoch 377/400\n",
      "8/8 [==============================] - 0s 181us/step - loss: 0.0146\n",
      "Epoch 378/400\n",
      "8/8 [==============================] - 0s 264us/step - loss: 0.0147\n",
      "Epoch 379/400\n",
      "8/8 [==============================] - 0s 274us/step - loss: 0.0146\n",
      "Epoch 380/400\n",
      "8/8 [==============================] - 0s 206us/step - loss: 0.0147\n",
      "Epoch 381/400\n",
      "8/8 [==============================] - 0s 205us/step - loss: 0.0147\n",
      "Epoch 382/400\n",
      "8/8 [==============================] - 0s 155us/step - loss: 0.0146\n",
      "Epoch 383/400\n",
      "8/8 [==============================] - 0s 185us/step - loss: 0.0147\n",
      "Epoch 384/400\n",
      "8/8 [==============================] - 0s 204us/step - loss: 0.0146\n",
      "Epoch 385/400\n",
      "8/8 [==============================] - 0s 172us/step - loss: 0.0147\n",
      "Epoch 386/400\n",
      "8/8 [==============================] - 0s 192us/step - loss: 0.0147\n",
      "Epoch 387/400\n",
      "8/8 [==============================] - 0s 190us/step - loss: 0.0146\n",
      "Epoch 388/400\n",
      "8/8 [==============================] - 0s 229us/step - loss: 0.0147\n",
      "Epoch 389/400\n",
      "8/8 [==============================] - 0s 245us/step - loss: 0.0146\n",
      "Epoch 390/400\n",
      "8/8 [==============================] - 0s 201us/step - loss: 0.0147\n",
      "Epoch 391/400\n",
      "8/8 [==============================] - 0s 170us/step - loss: 0.0147\n",
      "Epoch 392/400\n",
      "8/8 [==============================] - 0s 213us/step - loss: 0.0146\n",
      "Epoch 393/400\n",
      "8/8 [==============================] - 0s 187us/step - loss: 0.0147\n",
      "Epoch 394/400\n",
      "8/8 [==============================] - 0s 184us/step - loss: 0.0146\n",
      "Epoch 395/400\n",
      "8/8 [==============================] - 0s 168us/step - loss: 0.0147\n",
      "Epoch 396/400\n",
      "8/8 [==============================] - 0s 171us/step - loss: 0.0147\n",
      "Epoch 397/400\n",
      "8/8 [==============================] - 0s 181us/step - loss: 0.0146\n",
      "Epoch 398/400\n",
      "8/8 [==============================] - 0s 179us/step - loss: 0.0147\n",
      "Epoch 399/400\n",
      "8/8 [==============================] - 0s 201us/step - loss: 0.0146\n",
      "Epoch 400/400\n",
      "8/8 [==============================] - 0s 203us/step - loss: 0.0147\n",
      "best epoch =  394\n",
      "smallest loss = 0.01460283249616623\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 80, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = tf.keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(xarray,df.y3,epochs=400,callbacks=[es])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93fd795b-c93d-4717-bf5b-9fa353c85257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2100601 ]\n",
      " [0.37602067]\n",
      " [0.7082452 ]]\n",
      "w01 =  1.2100601 w02 =  0.37602067 w03 =  0.7082452\n",
      "[-0.14468023]\n",
      "b1 =  [-0.14468023]\n",
      "[[0.7057381]]\n",
      "w12 =  0.7057381\n",
      "[-0.11462832]\n",
      "b2 =  [-0.11462832]\n",
      "[[0.6842814]]\n",
      "w23 =  0.6842814\n",
      "[0.01542608]\n",
      "b3 =  [0.01542608]\n",
      "x01/20.2,  x02/14.5,   x03/308.0,  y3/32.4,  a3:\n",
      "0.9900990099009901 0.896551724137931 1.009090909090909 0.9558346964599856 [[0.9536409]]\n",
      "0.9900990099009901 1.0 1.0 0.9968828122588808 [[0.9693167]]\n",
      "0.9900990099009901 1.0551724137931036 0.9935064935064936 0.9721922162896206 [[0.9771144]]\n",
      "1.0 0.896551724137931 1.009090909090909 0.9539829017622912 [[0.95942676]]\n",
      "0.9900990099009901 1.0 1.0 1.003055461251196 [[0.9693167]]\n",
      "1.0 1.0551724137931036 0.9935064935064936 0.9691058917934631 [[0.9829002]]\n",
      "1.188118811881188 0.896551724137931 1.009090909090909 1.0984228881824636 [[1.069357]]\n",
      "1.7821782178217822 1.0 1.0 1.4320545662170918 [[1.4321812]]\n",
      "  \n",
      "x01,  x02,   x03,  y3,  a3*32.4:\n",
      "20.0 13.0 310.8 30.969044165303533 [[30.897966]]\n",
      "20.0 14.5 308.0 32.29900311718774 [[31.405863]]\n",
      "20.0 15.3 306.0 31.499027807783705 [[31.658508]]\n",
      "20.2 13.0 310.8 30.909046017098234 [[31.085428]]\n",
      "20.0 14.5 308.0 32.498996944538746 [[31.405863]]\n",
      "20.2 15.3 306.0 31.3990308941082 [[31.845968]]\n",
      "23.999999999999996 13.0 310.8 35.58890157711182 [[34.64717]]\n",
      "36.0 14.5 308.0 46.398567945433776 [[46.402676]]\n",
      "Stored 'Y3_keras' (list)\n",
      "Stored 'Y3_data' (list)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#For results of training network:\n",
    "#keras.layer.get_weights() function retrieves weight values\n",
    "first_layer_weights = model.layers[0].get_weights()[0]\n",
    "w01 = first_layer_weights[0][0]\n",
    "w02 = first_layer_weights[1][0]\n",
    "w03 = first_layer_weights[2][0]\n",
    "first_layer_bias  = model.layers[0].get_weights()[1]\n",
    "b1 = first_layer_bias\n",
    "second_layer_weights = model.layers[1].get_weights()[0]\n",
    "w12 = second_layer_weights[0][0]\n",
    "second_layer_bias  = model.layers[1].get_weights()[1]\n",
    "b2 = second_layer_bias\n",
    "third_layer_weights = model.layers[2].get_weights()[0]\n",
    "w23 = third_layer_weights[0][0]\n",
    "third_layer_bias  = model.layers[2].get_weights()[1]\n",
    "b3 = third_layer_bias\n",
    "\n",
    "#print weights and biases\n",
    "print (first_layer_weights)\n",
    "print ('w01 = ', w01, 'w02 = ', w02, 'w03 = ', w03)\n",
    "print (first_layer_bias)\n",
    "print ('b1 = ', b1)\n",
    "print (second_layer_weights)\n",
    "print ('w12 = ', w12)\n",
    "print (second_layer_bias)\n",
    "print ('b2 = ', b2)\n",
    "print (third_layer_weights)\n",
    "print ('w23 = ', w23)\n",
    "print (third_layer_bias)\n",
    "print ('b3 = ', b3)\n",
    "\n",
    "#use model.predict() function to print model predictions for data conditions\n",
    "xarray= np.array(xdata)\n",
    "print ('x01/20.2,  x02/14.5,   x03/308.0,  y3/32.4,  a3:')\n",
    "test = []\n",
    "for i in range(0,8): \n",
    "    test = [[xarray[i][0], xarray[i][1], xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    print (xarray[i][0], xarray[i][1], xarray[i][2], df.y3[i], a3)\n",
    "print('  ')\n",
    "print ('x01,  x02,   x03,  y3,  a3*32.4:')\n",
    "Y3_keras = []\n",
    "Y3_data = []\n",
    "for i in range(0,8): \n",
    "    test = [[xarray[i][0], xarray[i][1], xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    Y3_keras.append(a3*32.4)\n",
    "    Y3_data.append(df.y3[i]*32.4)\n",
    "    print (xarray[i][0]*20.2, xarray[i][1]*14.5, xarray[i][2]*308.0, df.y3[i]*32.4, a3*32.4)\n",
    "%store Y3_keras\n",
    "%store Y3_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15aec0f-1eae-4bf2-a1a5-4018d969e427",
   "metadata": {},
   "source": [
    "## Task 2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f099d2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nydata =  [[ 35.1316 , 0.3808 ],[ 40.3764 , 0.38686 ]]\\nydata.append([ 47.4620 , 0.3930 ])\\nydata.append([ 57.5639 , 0.39949 ])\\nydata.append([ 73.1286 , 0.40612 ])\\nydata.append([ 49.1110 , 0.4023 ])\\nydata.append([ 56.4428 , 0.40605 ])\\nydata.append([ 66.3479 , 0.4098 ])\\nydata.append([ 80.4695 , 0.413 ])\\nydata.append([ 102.2276 , 0.4175 ])\\nydata.append([ 63.0904 , 0.41540 ])\\nydata.append([ 72.5092 , 0.4175 ])\\nydata.append([ 85.2338, 0.4197 ])\\nydata.append([ 103.3750 , 0.42192 ])\\nydata.append([ 131.3266 , 0.4242 ])\\n  \\nydata.append([ 34.273 , 0.3952 ])\\nydata.append([ 38.99026 , 0.4012 ])\\nydata.append([ 45.2133, 0.4073 ])\\nydata.append([ 53.8000 , 0.4136 ])\\nydata.append([ 66.4130 , 0.4201 ])\\nydata.append([ 47.922 , 0.4178 ])\\nydata.append([ 54.518 , 0.4215 ])\\nydata.append([ 63.220 , 0.4252 ])\\nydata.append([ 75.226 , 0.4290 ])\\nydata.append([ 92.862 , 0.4329 ])\\nydata.append([ 61.572 , 0.4315 ])\\nydata.append([ 70.0468 , 0.43373 ])\\nydata.append([ 81.226 , 0.43597 ])\\nydata.append([ 96.653 , 0.4382 ])\\nydata.append([ 119.3124 , 0.44045 ])\\n  \\nydata.append([ 33.4521 , 0.40913 ])\\nydata.append([ 37.6911, 0.4150 ])\\nydata.append([ 43.1602 , 0.4209 ])\\nydata.append([ 50.4858 , 0.4271 ])\\nydata.append([ 60.8067 , 0.4334 ])\\nydata.append([ 46.7865 , 0.4328 ])\\nydata.append([ 52.7151 , 0.43646 ])\\nydata.append([ 60.36425 , 0.44016 ])\\nydata.append([ 70.6099 , 0.443926 ])\\nydata.append([ 85.0447 , 0.4477 ])\\nydata.append([ 60.1208 , 0.44721 ])\\nydata.append([ 67.7391 , 0.44940 ])\\nydata.append([ 77.56830 , 0.4516 ])\\nydata.append([ 90.73410 , 0.4538 ])\\nydata.append([ 109.2828 , 0.4560 ])\\n  \\nydata.append([ 32.4123 , 0.42694 ])\\nydata.append([ 36.0807 , 0.4325 ])\\nydata.append([ 40.6854 , 0.4383 ])\\nydata.append([ 46.6374 , 0.4442 ])\\nydata.append([ 54.6293 , 0.4503 ])\\nydata.append([ 45.3472 , 0.4519 ])\\nydata.append([ 50.4796 , 0.4555 ])\\nydata.append([ 56.9219 , 0.4591 ])\\nydata.append([ 65.2492 , 0.4628 ])\\nydata.append([ 76.4304 , 0.4665 ])\\nydata.append([ 58.2822 , 0.4672 ])\\nydata.append([ 64.8785 , 0.4693 ])\\nydata.append([ 73.1584 , 0.4715 ])\\nydata.append([ 83.8610 , 0.4738 ])\\nydata.append([ 98.2316 , 0.4760 ])\\n  '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''>>>>> start CodeP2.3F22\n",
    "    V.P. Carey ME249, Fall 2022\n",
    "\n",
    "Intro to Neural Network Modeling \n",
    "Data arrays for hybrid solar/fossil-fuel gas turbine power system'''\n",
    "\n",
    "'''\n",
    "#create input data array, normalizing input temp\n",
    "#T1(K), gamma, , qsol(kW):\n",
    "xdata = []\n",
    "xdata =  [[ 318.0 , 0.0 , 500.0 ], [ 318.0 , 0.0 , 1000.0 ]]\n",
    "xdata.append([ 318.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 318.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 318.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 2500.0 ])\n",
    "  \n",
    "xdata.append([ 303.0 , 0.0 , 500.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 1000.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 2500.0 ])\n",
    "  \n",
    "xdata.append([ 288.0 , 0.0 , 500.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 1000.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 2500.0 ])\n",
    "  \n",
    "xdata.append([ 268.0 , 0.0 , 500.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 1000.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 2500.0 ])\n",
    "  '''\n",
    "\n",
    "'''\n",
    "ydata =  [[ 35.1316 , 0.3808 ],[ 40.3764 , 0.38686 ]]\n",
    "ydata.append([ 47.4620 , 0.3930 ])\n",
    "ydata.append([ 57.5639 , 0.39949 ])\n",
    "ydata.append([ 73.1286 , 0.40612 ])\n",
    "ydata.append([ 49.1110 , 0.4023 ])\n",
    "ydata.append([ 56.4428 , 0.40605 ])\n",
    "ydata.append([ 66.3479 , 0.4098 ])\n",
    "ydata.append([ 80.4695 , 0.413 ])\n",
    "ydata.append([ 102.2276 , 0.4175 ])\n",
    "ydata.append([ 63.0904 , 0.41540 ])\n",
    "ydata.append([ 72.5092 , 0.4175 ])\n",
    "ydata.append([ 85.2338, 0.4197 ])\n",
    "ydata.append([ 103.3750 , 0.42192 ])\n",
    "ydata.append([ 131.3266 , 0.4242 ])\n",
    "  \n",
    "ydata.append([ 34.273 , 0.3952 ])\n",
    "ydata.append([ 38.99026 , 0.4012 ])\n",
    "ydata.append([ 45.2133, 0.4073 ])\n",
    "ydata.append([ 53.8000 , 0.4136 ])\n",
    "ydata.append([ 66.4130 , 0.4201 ])\n",
    "ydata.append([ 47.922 , 0.4178 ])\n",
    "ydata.append([ 54.518 , 0.4215 ])\n",
    "ydata.append([ 63.220 , 0.4252 ])\n",
    "ydata.append([ 75.226 , 0.4290 ])\n",
    "ydata.append([ 92.862 , 0.4329 ])\n",
    "ydata.append([ 61.572 , 0.4315 ])\n",
    "ydata.append([ 70.0468 , 0.43373 ])\n",
    "ydata.append([ 81.226 , 0.43597 ])\n",
    "ydata.append([ 96.653 , 0.4382 ])\n",
    "ydata.append([ 119.3124 , 0.44045 ])\n",
    "  \n",
    "ydata.append([ 33.4521 , 0.40913 ])\n",
    "ydata.append([ 37.6911, 0.4150 ])\n",
    "ydata.append([ 43.1602 , 0.4209 ])\n",
    "ydata.append([ 50.4858 , 0.4271 ])\n",
    "ydata.append([ 60.8067 , 0.4334 ])\n",
    "ydata.append([ 46.7865 , 0.4328 ])\n",
    "ydata.append([ 52.7151 , 0.43646 ])\n",
    "ydata.append([ 60.36425 , 0.44016 ])\n",
    "ydata.append([ 70.6099 , 0.443926 ])\n",
    "ydata.append([ 85.0447 , 0.4477 ])\n",
    "ydata.append([ 60.1208 , 0.44721 ])\n",
    "ydata.append([ 67.7391 , 0.44940 ])\n",
    "ydata.append([ 77.56830 , 0.4516 ])\n",
    "ydata.append([ 90.73410 , 0.4538 ])\n",
    "ydata.append([ 109.2828 , 0.4560 ])\n",
    "  \n",
    "ydata.append([ 32.4123 , 0.42694 ])\n",
    "ydata.append([ 36.0807 , 0.4325 ])\n",
    "ydata.append([ 40.6854 , 0.4383 ])\n",
    "ydata.append([ 46.6374 , 0.4442 ])\n",
    "ydata.append([ 54.6293 , 0.4503 ])\n",
    "ydata.append([ 45.3472 , 0.4519 ])\n",
    "ydata.append([ 50.4796 , 0.4555 ])\n",
    "ydata.append([ 56.9219 , 0.4591 ])\n",
    "ydata.append([ 65.2492 , 0.4628 ])\n",
    "ydata.append([ 76.4304 , 0.4665 ])\n",
    "ydata.append([ 58.2822 , 0.4672 ])\n",
    "ydata.append([ 64.8785 , 0.4693 ])\n",
    "ydata.append([ 73.1584 , 0.4715 ])\n",
    "ydata.append([ 83.8610 , 0.4738 ])\n",
    "ydata.append([ 98.2316 , 0.4760 ])\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70db33a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.955e+02 2.500e-01 1.500e+03]\n",
      "xdata: [[1.07614213 0.         0.33333333]\n",
      " [1.07614213 0.         0.66666667]\n",
      " [1.07614213 0.         1.        ]\n",
      " [1.07614213 0.         1.33333333]\n",
      " [1.07614213 0.         1.66666667]\n",
      " [1.07614213 1.         0.33333333]\n",
      " [1.07614213 1.         0.66666667]\n",
      " [1.07614213 1.         1.        ]\n",
      " [1.07614213 1.         1.33333333]\n",
      " [1.07614213 1.         1.66666667]\n",
      " [1.07614213 2.         0.33333333]\n",
      " [1.07614213 2.         0.66666667]\n",
      " [1.07614213 2.         1.        ]\n",
      " [1.07614213 2.         1.33333333]\n",
      " [1.07614213 2.         1.66666667]\n",
      " [1.02538071 0.         0.33333333]\n",
      " [1.02538071 0.         0.66666667]\n",
      " [1.02538071 0.         1.        ]\n",
      " [1.02538071 0.         1.33333333]\n",
      " [1.02538071 0.         1.66666667]\n",
      " [1.02538071 1.         0.33333333]\n",
      " [1.02538071 1.         0.66666667]\n",
      " [1.02538071 1.         1.        ]\n",
      " [1.02538071 1.         1.33333333]\n",
      " [1.02538071 1.         1.66666667]\n",
      " [1.02538071 2.         0.33333333]\n",
      " [1.02538071 2.         0.66666667]\n",
      " [1.02538071 2.         1.        ]\n",
      " [1.02538071 2.         1.33333333]\n",
      " [1.02538071 2.         1.66666667]\n",
      " [0.97461929 0.         0.33333333]\n",
      " [0.97461929 0.         0.66666667]\n",
      " [0.97461929 0.         1.        ]\n",
      " [0.97461929 0.         1.33333333]\n",
      " [0.97461929 0.         1.66666667]\n",
      " [0.97461929 1.         0.33333333]\n",
      " [0.97461929 1.         0.66666667]\n",
      " [0.97461929 1.         1.        ]\n",
      " [0.97461929 1.         1.33333333]\n",
      " [0.97461929 1.         1.66666667]\n",
      " [0.97461929 2.         0.33333333]\n",
      " [0.97461929 2.         0.66666667]\n",
      " [0.97461929 2.         1.        ]\n",
      " [0.97461929 2.         1.33333333]\n",
      " [0.97461929 2.         1.66666667]\n",
      " [0.90693739 0.         0.33333333]\n",
      " [0.90693739 0.         0.66666667]\n",
      " [0.90693739 0.         1.        ]\n",
      " [0.90693739 0.         1.33333333]\n",
      " [0.90693739 0.         1.66666667]\n",
      " [0.90693739 1.         0.33333333]\n",
      " [0.90693739 1.         0.66666667]\n",
      " [0.90693739 1.         1.        ]\n",
      " [0.90693739 1.         1.33333333]\n",
      " [0.90693739 1.         1.66666667]\n",
      " [0.90693739 2.         0.33333333]\n",
      " [0.90693739 2.         0.66666667]\n",
      " [0.90693739 2.         1.        ]\n",
      " [0.90693739 2.         1.33333333]\n",
      " [0.90693739 2.         1.66666667]]\n",
      "[61.18935  0.432  ]\n",
      "ydata: [[0.57414566 0.88148148]\n",
      " [0.65985993 0.89550926]\n",
      " [0.77565786 0.90972222]\n",
      " [0.94075031 0.92474537]\n",
      " [1.19511974 0.94009259]\n",
      " [0.80260699 0.93125   ]\n",
      " [0.92242849 0.93993056]\n",
      " [1.0843047  0.94861111]\n",
      " [1.31508996 0.95601852]\n",
      " [1.67067635 0.96643519]\n",
      " [1.03106831 0.96157407]\n",
      " [1.18499706 0.96643519]\n",
      " [1.39295155 0.97152778]\n",
      " [1.68942798 0.97666667]\n",
      " [2.14623296 0.98194444]\n",
      " [0.56011381 0.91481481]\n",
      " [0.63720664 0.9287037 ]\n",
      " [0.738908   0.94282407]\n",
      " [0.87923797 0.95740741]\n",
      " [1.08536861 0.9724537 ]\n",
      " [0.7831755  0.96712963]\n",
      " [0.89097204 0.97569444]\n",
      " [1.03318633 0.98425926]\n",
      " [1.22939695 0.99305556]\n",
      " [1.51761704 1.00208333]\n",
      " [1.00625354 0.99884259]\n",
      " [1.14475477 1.00400463]\n",
      " [1.32745323 1.00918981]\n",
      " [1.57957226 1.01435185]\n",
      " [1.94988834 1.01956019]\n",
      " [0.54669808 0.94706019]\n",
      " [0.61597484 0.96064815]\n",
      " [0.70535477 0.97430556]\n",
      " [0.82507495 0.98865741]\n",
      " [0.99374646 1.00324074]\n",
      " [0.76461835 1.00185185]\n",
      " [0.86150776 1.01032407]\n",
      " [0.98651563 1.01888889]\n",
      " [1.15395735 1.02760648]\n",
      " [1.38986114 1.03634259]\n",
      " [0.98253699 1.03520833]\n",
      " [1.10704069 1.04027778]\n",
      " [1.26767648 1.04537037]\n",
      " [1.48284138 1.05046296]\n",
      " [1.78597746 1.05555556]\n",
      " [0.52970492 0.98828704]\n",
      " [0.58965653 1.00115741]\n",
      " [0.66490982 1.01458333]\n",
      " [0.76218165 1.02824074]\n",
      " [0.89279098 1.04236111]\n",
      " [0.74109629 1.04606481]\n",
      " [0.82497363 1.05439815]\n",
      " [0.93025829 1.06273148]\n",
      " [1.06634896 1.0712963 ]\n",
      " [1.24908011 1.07986111]\n",
      " [0.95248928 1.08148148]\n",
      " [1.06029072 1.08634259]\n",
      " [1.19560675 1.09143519]\n",
      " [1.37051627 1.09675926]\n",
      " [1.60537087 1.10185185]]\n",
      "Stored 'xarray' (ndarray)\n",
      "Stored 'yarray' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "'''>>>>> start CodeP2.4F22\n",
    "    V.P. Carey ME249, Fall 2022\n",
    "\n",
    "Intro to Neural Network Modeling \n",
    "Keras model for hybrid solar/fossil-fuel gas turbine power system'''\n",
    "\n",
    "#import useful packages\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#create input data array\n",
    "# meadian values of input variables\n",
    "Tmed = 293.\n",
    "gamed = 0.25\n",
    "qsmed = 1250.\n",
    "#T1(K), gamma, , qsol(kW):\n",
    "xdata = []\n",
    "xdata =  [[ 318.0, 0.0, 500.0], [ 318.0, 0.0, 1000.0]]\n",
    "xdata.append([ 318.0, 0.0, 1500.0])\n",
    "xdata.append([ 318.0, 0.0, 2000.0])\n",
    "xdata.append([ 318.0, 0.0, 2500.0])\n",
    "xdata.append([ 318.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 2500.0 ])\n",
    "  \n",
    "xdata.append([ 303.0 , 0.0 , 500.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 1000.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 2500.0 ])\n",
    "  \n",
    "xdata.append([ 288.0 , 0.0 , 500.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 1000.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 2500.0 ])\n",
    "  \n",
    "xdata.append([ 268.0 , 0.0 , 500.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 1000.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 2500.0 ])\n",
    "\n",
    "''' #convert to:\n",
    "xdata =  [[ 318.0/Tmed , 0.0/gamed , 500.0/qsmed ], [ 318.0/Tmed , 0.0/gamed , 1000.0/qsmed ]]\n",
    "xdata.append([ 318.0/Tmed  , 0.0/gamed , 1500.0/qsmed ])\n",
    "xdata.append([ 318.0/Tmed  , 0.0/gamed , 2000.0/qsmed ])\n",
    "xdata.append([ 318.0/Tmed  , 0.0/gamed , 2500.0/qsmed ])'''\n",
    "#narmalizing the ydata using the median value.\n",
    "medianx=np.median(xdata,axis=0)\n",
    "print(medianx)\n",
    "Tmed=medianx[0]\n",
    "gamed=medianx[1]\n",
    "qsmed=medianx[2]\n",
    "Nx = []\n",
    "for i in range(len(xdata)):\n",
    "    Nx.append([ xdata[i][0]/Tmed , xdata[i][1]/gamed , xdata[i][2]/qsmed ])\n",
    "xdata = Nx\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "#print (xdata)\n",
    "print ('xdata:', xarray)\n",
    "# meadian values of output variables\n",
    "almed = 60.\n",
    "efmed = 0.4\n",
    "# alpha, effsys\n",
    "ydata = []\n",
    "ydata =  [[ 35.1316, 0.3808], [ 40.3764, 0.38686]]\n",
    "ydata.append([ 47.4620, 0.3930])\n",
    "ydata.append([ 57.5639, 0.39949])\n",
    "ydata.append([ 73.1286, 0.40612])\n",
    "ydata.append([ 49.1110 , 0.4023 ])\n",
    "ydata.append([ 56.4428 , 0.40605 ])\n",
    "ydata.append([ 66.3479 , 0.4098 ])\n",
    "ydata.append([ 80.4695 , 0.413 ])\n",
    "ydata.append([ 102.2276 , 0.4175 ])\n",
    "ydata.append([ 63.0904 , 0.41540 ])\n",
    "ydata.append([ 72.5092 , 0.4175 ])\n",
    "ydata.append([ 85.2338, 0.4197 ])\n",
    "ydata.append([ 103.3750 , 0.42192 ])\n",
    "ydata.append([ 131.3266 , 0.4242 ])\n",
    "  \n",
    "ydata.append([ 34.273 , 0.3952 ])\n",
    "ydata.append([ 38.99026 , 0.4012 ])\n",
    "ydata.append([ 45.2133, 0.4073 ])\n",
    "ydata.append([ 53.8000 , 0.4136 ])\n",
    "ydata.append([ 66.4130 , 0.4201 ])\n",
    "ydata.append([ 47.922 , 0.4178 ])\n",
    "ydata.append([ 54.518 , 0.4215 ])\n",
    "ydata.append([ 63.220 , 0.4252 ])\n",
    "ydata.append([ 75.226 , 0.4290 ])\n",
    "ydata.append([ 92.862 , 0.4329 ])\n",
    "ydata.append([ 61.572 , 0.4315 ])\n",
    "ydata.append([ 70.0468 , 0.43373 ])\n",
    "ydata.append([ 81.226 , 0.43597 ])\n",
    "ydata.append([ 96.653 , 0.4382 ])\n",
    "ydata.append([ 119.3124 , 0.44045 ])\n",
    "  \n",
    "ydata.append([ 33.4521 , 0.40913 ])\n",
    "ydata.append([ 37.6911, 0.4150 ])\n",
    "ydata.append([ 43.1602 , 0.4209 ])\n",
    "ydata.append([ 50.4858 , 0.4271 ])\n",
    "ydata.append([ 60.8067 , 0.4334 ])\n",
    "ydata.append([ 46.7865 , 0.4328 ])\n",
    "ydata.append([ 52.7151 , 0.43646 ])\n",
    "ydata.append([ 60.36425 , 0.44016 ])\n",
    "ydata.append([ 70.6099 , 0.443926 ])\n",
    "ydata.append([ 85.0447 , 0.4477 ])\n",
    "ydata.append([ 60.1208 , 0.44721 ])\n",
    "ydata.append([ 67.7391 , 0.44940 ])\n",
    "ydata.append([ 77.56830 , 0.4516 ])\n",
    "ydata.append([ 90.73410 , 0.4538 ])\n",
    "ydata.append([ 109.2828 , 0.4560 ])\n",
    "  \n",
    "ydata.append([ 32.4123 , 0.42694 ])\n",
    "ydata.append([ 36.0807 , 0.4325 ])\n",
    "ydata.append([ 40.6854 , 0.4383 ])\n",
    "ydata.append([ 46.6374 , 0.4442 ])\n",
    "ydata.append([ 54.6293 , 0.4503 ])\n",
    "ydata.append([ 45.3472 , 0.4519 ])\n",
    "ydata.append([ 50.4796 , 0.4555 ])\n",
    "ydata.append([ 56.9219 , 0.4591 ])\n",
    "ydata.append([ 65.2492 , 0.4628 ])\n",
    "ydata.append([ 76.4304 , 0.4665 ])\n",
    "ydata.append([ 58.2822 , 0.4672 ])\n",
    "ydata.append([ 64.8785 , 0.4693 ])\n",
    "ydata.append([ 73.1584 , 0.4715 ])\n",
    "ydata.append([ 83.8610 , 0.4738 ])\n",
    "ydata.append([ 98.2316 , 0.4760 ])\n",
    "\n",
    "'''#convert to:\n",
    "ydata =  [[ 35.1316/almed , 0.3808/efmed ], [ 40.3764/almed , 0.38686/efmed ]]\n",
    "ydata.append([ 47.4620/almed , 0.3930/efmed ])\n",
    "ydata.append([ 57.5639/almed , 0.39949/efmed ])\n",
    "ydata.append([ 73.1286/almed , 0.40612/efmed ])'''\n",
    "#narmalizing the ydata using the median value.\n",
    "mediany=np.median(ydata,axis=0)\n",
    "print(mediany)\n",
    "almed=mediany[0]\n",
    "efmed=mediany[1]\n",
    "Ny=[]\n",
    "for i in range(len(ydata)):\n",
    "    Ny.append([ ydata[i][0]/almed , ydata[i][1]/efmed ])\n",
    "ydata=Ny\n",
    "yarray= np.array(ydata)\n",
    "#print (ydata)\n",
    "print ('ydata:', yarray)\n",
    "%store xarray\n",
    "%store yarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a624f36-e5c9-4c6f-97bb-f451a6e426bf",
   "metadata": {},
   "source": [
    "## Task 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e616647d-6857-4ffb-bb58-37b49aad4356",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0febc8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "\n",
    "#As seen below, we have created four dense layers. \n",
    "#A dense layer is a layer in neural network that’s fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 1 in our case. \n",
    "#The activation function we have chosen is elu, which stands for exponential linear unit. .\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 1.2\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(16, activation=K.elu, input_shape=[3],  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(32, activation=K.relu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(16, activation=K.relu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(2,  kernel_initializer=initializer)\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b76a093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean squared error. After the compilation of the model, we’ll use the fit method with ~500 epochs.\n",
    "#Number of epochs can be varied.\n",
    "\n",
    "#from tf.keras import optimizers\n",
    "rms = keras.optimizers.RMSprop(0.001)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a054c-06f2-4c44-a189-a684d18f2059",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9faae4e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 7.1724\n",
      "Epoch 2/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 5.8566\n",
      "Epoch 3/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 5.0474\n",
      "Epoch 4/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 4.4274\n",
      "Epoch 5/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 3.9182\n",
      "Epoch 6/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 3.4910\n",
      "Epoch 7/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 3.1367\n",
      "Epoch 8/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 2.8423\n",
      "Epoch 9/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 2.5930\n",
      "Epoch 10/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 2.3717\n",
      "Epoch 11/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 2.1742\n",
      "Epoch 12/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 1.9920\n",
      "Epoch 13/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 1.8226\n",
      "Epoch 14/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 1.6606\n",
      "Epoch 15/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 1.5099\n",
      "Epoch 16/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 1.3640\n",
      "Epoch 17/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 1.2268\n",
      "Epoch 18/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 1.0958\n",
      "Epoch 19/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.9711\n",
      "Epoch 20/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.8523\n",
      "Epoch 21/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.7392\n",
      "Epoch 22/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.6331\n",
      "Epoch 23/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.5423\n",
      "Epoch 24/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.4516\n",
      "Epoch 25/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.3732\n",
      "Epoch 26/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.3085\n",
      "Epoch 27/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.2562\n",
      "Epoch 28/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.2177\n",
      "Epoch 29/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.1958\n",
      "Epoch 30/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.1908\n",
      "Epoch 31/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.1797\n",
      "Epoch 32/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.1764\n",
      "Epoch 33/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.1688\n",
      "Epoch 34/600\n",
      "60/60 [==============================] - 0s 121us/step - loss: 0.1610\n",
      "Epoch 35/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.1560\n",
      "Epoch 36/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.1509\n",
      "Epoch 37/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.1513\n",
      "Epoch 38/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.1460\n",
      "Epoch 39/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.1383\n",
      "Epoch 40/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.1358\n",
      "Epoch 41/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.1298\n",
      "Epoch 42/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.1255\n",
      "Epoch 43/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.1313\n",
      "Epoch 44/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.1206\n",
      "Epoch 45/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.1201\n",
      "Epoch 46/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.1129\n",
      "Epoch 47/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.1170\n",
      "Epoch 48/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.1238\n",
      "Epoch 49/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.1052\n",
      "Epoch 50/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.1076\n",
      "Epoch 51/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0995\n",
      "Epoch 52/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0950\n",
      "Epoch 53/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0926\n",
      "Epoch 54/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0887\n",
      "Epoch 55/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0901\n",
      "Epoch 56/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.1002\n",
      "Epoch 57/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.1085\n",
      "Epoch 58/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0856\n",
      "Epoch 59/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0894\n",
      "Epoch 60/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0883\n",
      "Epoch 61/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0812\n",
      "Epoch 62/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0867\n",
      "Epoch 63/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0846\n",
      "Epoch 64/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0811\n",
      "Epoch 65/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0728\n",
      "Epoch 66/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0754\n",
      "Epoch 67/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0889\n",
      "Epoch 68/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0755\n",
      "Epoch 69/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0700\n",
      "Epoch 70/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0785\n",
      "Epoch 71/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0829\n",
      "Epoch 72/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0686\n",
      "Epoch 73/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0817\n",
      "Epoch 74/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0844\n",
      "Epoch 75/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0710\n",
      "Epoch 76/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0709\n",
      "Epoch 77/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0732\n",
      "Epoch 78/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0640\n",
      "Epoch 79/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0698\n",
      "Epoch 80/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0828\n",
      "Epoch 81/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0652\n",
      "Epoch 82/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0695\n",
      "Epoch 83/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0640\n",
      "Epoch 84/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0788\n",
      "Epoch 85/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0757\n",
      "Epoch 86/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0685\n",
      "Epoch 87/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0752\n",
      "Epoch 88/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0689\n",
      "Epoch 89/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0693\n",
      "Epoch 90/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0610\n",
      "Epoch 91/600\n",
      "60/60 [==============================] - 0s 54us/step - loss: 0.0604\n",
      "Epoch 92/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0783\n",
      "Epoch 93/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0666\n",
      "Epoch 94/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0589\n",
      "Epoch 95/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0625\n",
      "Epoch 96/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0712\n",
      "Epoch 97/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0689\n",
      "Epoch 98/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0592\n",
      "Epoch 99/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0606\n",
      "Epoch 100/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0638\n",
      "Epoch 101/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0726\n",
      "Epoch 102/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0710\n",
      "Epoch 103/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0745\n",
      "Epoch 104/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0658\n",
      "Epoch 105/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0654\n",
      "Epoch 106/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0655\n",
      "Epoch 107/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0609\n",
      "Epoch 108/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0597\n",
      "Epoch 109/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0633\n",
      "Epoch 110/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0693\n",
      "Epoch 111/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0734\n",
      "Epoch 112/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0633\n",
      "Epoch 113/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0718\n",
      "Epoch 114/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0722\n",
      "Epoch 115/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0612\n",
      "Epoch 116/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0615\n",
      "Epoch 117/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0584\n",
      "Epoch 118/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0670\n",
      "Epoch 119/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0638\n",
      "Epoch 120/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0729\n",
      "Epoch 121/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0573\n",
      "Epoch 122/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0692\n",
      "Epoch 123/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0651\n",
      "Epoch 124/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0664\n",
      "Epoch 125/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0552\n",
      "Epoch 126/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0598\n",
      "Epoch 127/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0683\n",
      "Epoch 128/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0700\n",
      "Epoch 129/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0696\n",
      "Epoch 130/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0593\n",
      "Epoch 131/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0548\n",
      "Epoch 132/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0547\n",
      "Epoch 133/600\n",
      "60/60 [==============================] - 0s 51us/step - loss: 0.0640\n",
      "Epoch 134/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0764\n",
      "Epoch 135/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0676\n",
      "Epoch 136/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0594\n",
      "Epoch 137/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0667\n",
      "Epoch 138/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0690\n",
      "Epoch 139/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0688\n",
      "Epoch 140/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0625\n",
      "Epoch 141/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0667\n",
      "Epoch 142/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0640\n",
      "Epoch 143/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0568\n",
      "Epoch 144/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0536\n",
      "Epoch 145/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0586\n",
      "Epoch 146/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0747\n",
      "Epoch 147/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0645\n",
      "Epoch 148/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0582\n",
      "Epoch 149/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0622\n",
      "Epoch 150/600\n",
      "60/60 [==============================] - 0s 76us/step - loss: 0.0731\n",
      "Epoch 151/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0585\n",
      "Epoch 152/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0598\n",
      "Epoch 153/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0644\n",
      "Epoch 154/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0631\n",
      "Epoch 155/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0669\n",
      "Epoch 156/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0615\n",
      "Epoch 157/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0670\n",
      "Epoch 158/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0693\n",
      "Epoch 159/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0583\n",
      "Epoch 160/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0557\n",
      "Epoch 161/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0540\n",
      "Epoch 162/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0531\n",
      "Epoch 163/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0724\n",
      "Epoch 164/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0570\n",
      "Epoch 165/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0661\n",
      "Epoch 166/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0568\n",
      "Epoch 167/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0544\n",
      "Epoch 168/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0599\n",
      "Epoch 169/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0676\n",
      "Epoch 170/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0725\n",
      "Epoch 171/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0522\n",
      "Epoch 172/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0598\n",
      "Epoch 173/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0633\n",
      "Epoch 174/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0694\n",
      "Epoch 175/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0559\n",
      "Epoch 176/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0631\n",
      "Epoch 177/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0583\n",
      "Epoch 178/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0662\n",
      "Epoch 179/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0564\n",
      "Epoch 180/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0520\n",
      "Epoch 181/600\n",
      "60/60 [==============================] - 0s 53us/step - loss: 0.0526\n",
      "Epoch 182/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0695\n",
      "Epoch 183/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0667\n",
      "Epoch 184/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0633\n",
      "Epoch 185/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0598\n",
      "Epoch 186/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0667\n",
      "Epoch 187/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0578\n",
      "Epoch 188/600\n",
      "60/60 [==============================] - 0s 86us/step - loss: 0.0554\n",
      "Epoch 189/600\n",
      "60/60 [==============================] - 0s 76us/step - loss: 0.0664\n",
      "Epoch 190/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0638\n",
      "Epoch 191/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0654\n",
      "Epoch 192/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0628\n",
      "Epoch 193/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0616\n",
      "Epoch 194/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0595\n",
      "Epoch 195/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0542\n",
      "Epoch 196/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0583\n",
      "Epoch 197/600\n",
      "60/60 [==============================] - 0s 54us/step - loss: 0.0728\n",
      "Epoch 198/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0583\n",
      "Epoch 199/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0609\n",
      "Epoch 200/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0581\n",
      "Epoch 201/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0599\n",
      "Epoch 202/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0523\n",
      "Epoch 203/600\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.0563\n",
      "Epoch 204/600\n",
      "60/60 [==============================] - 0s 101us/step - loss: 0.0493\n",
      "Epoch 205/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0562\n",
      "Epoch 206/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0672\n",
      "Epoch 207/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0553\n",
      "Epoch 208/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0603\n",
      "Epoch 209/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0573\n",
      "Epoch 210/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0561\n",
      "Epoch 211/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0565\n",
      "Epoch 212/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0643\n",
      "Epoch 213/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0545\n",
      "Epoch 214/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0632\n",
      "Epoch 215/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0498\n",
      "Epoch 216/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0558\n",
      "Epoch 217/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0607\n",
      "Epoch 218/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0621\n",
      "Epoch 219/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0497\n",
      "Epoch 220/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0501\n",
      "Epoch 221/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0650\n",
      "Epoch 222/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0517\n",
      "Epoch 223/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0507\n",
      "Epoch 224/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0577\n",
      "Epoch 225/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0524\n",
      "Epoch 226/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0705\n",
      "Epoch 227/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0564\n",
      "Epoch 228/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0607\n",
      "Epoch 229/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0552\n",
      "Epoch 230/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0562\n",
      "Epoch 231/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0607\n",
      "Epoch 232/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0645\n",
      "Epoch 233/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0603\n",
      "Epoch 234/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0612\n",
      "Epoch 235/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0572\n",
      "Epoch 236/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0514\n",
      "Epoch 237/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0538\n",
      "Epoch 238/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0583\n",
      "Epoch 239/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0576\n",
      "Epoch 240/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0559\n",
      "Epoch 241/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0600\n",
      "Epoch 242/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0517\n",
      "Epoch 243/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0537\n",
      "Epoch 244/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0514\n",
      "Epoch 245/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0529\n",
      "Epoch 246/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0649\n",
      "Epoch 247/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0690\n",
      "Epoch 248/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0568\n",
      "Epoch 249/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0580\n",
      "Epoch 250/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0543\n",
      "Epoch 251/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0523\n",
      "Epoch 252/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0512\n",
      "Epoch 253/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0548\n",
      "Epoch 254/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0670\n",
      "Epoch 255/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0558\n",
      "Epoch 256/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0545\n",
      "Epoch 257/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0569\n",
      "Epoch 258/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0581\n",
      "Epoch 259/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0622\n",
      "Epoch 260/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0554\n",
      "Epoch 261/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0554\n",
      "Epoch 262/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0644\n",
      "Epoch 263/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0542\n",
      "Epoch 264/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0556\n",
      "Epoch 265/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0545\n",
      "Epoch 266/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0495\n",
      "Epoch 267/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0669\n",
      "Epoch 268/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0537\n",
      "Epoch 269/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0550\n",
      "Epoch 270/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0511\n",
      "Epoch 271/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0530\n",
      "Epoch 272/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0534\n",
      "Epoch 273/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0535\n",
      "Epoch 274/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0559\n",
      "Epoch 275/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0643\n",
      "Epoch 276/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0592\n",
      "Epoch 277/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0546\n",
      "Epoch 278/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0539\n",
      "Epoch 279/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0533\n",
      "Epoch 280/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0597\n",
      "Epoch 281/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0573\n",
      "Epoch 282/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0557\n",
      "Epoch 283/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0471\n",
      "Epoch 284/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0463\n",
      "Epoch 285/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0564\n",
      "Epoch 286/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0651\n",
      "Epoch 287/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0515\n",
      "Epoch 288/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0528\n",
      "Epoch 289/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0558\n",
      "Epoch 290/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0507\n",
      "Epoch 291/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0548\n",
      "Epoch 292/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0557\n",
      "Epoch 293/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0545\n",
      "Epoch 294/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0581\n",
      "Epoch 295/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0479\n",
      "Epoch 296/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0501\n",
      "Epoch 297/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0531\n",
      "Epoch 298/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0473\n",
      "Epoch 299/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0580\n",
      "Epoch 300/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0552\n",
      "Epoch 301/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0467\n",
      "Epoch 302/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0453\n",
      "Epoch 303/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0588\n",
      "Epoch 304/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0564\n",
      "Epoch 305/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0491\n",
      "Epoch 306/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0481\n",
      "Epoch 307/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0602\n",
      "Epoch 308/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0556\n",
      "Epoch 309/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0541\n",
      "Epoch 310/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0477\n",
      "Epoch 311/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0511\n",
      "Epoch 312/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0619\n",
      "Epoch 313/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0599\n",
      "Epoch 314/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0541\n",
      "Epoch 315/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0460\n",
      "Epoch 316/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0489\n",
      "Epoch 317/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0482\n",
      "Epoch 318/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0589\n",
      "Epoch 319/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0489\n",
      "Epoch 320/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0468\n",
      "Epoch 321/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0496\n",
      "Epoch 322/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0485\n",
      "Epoch 323/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0499\n",
      "Epoch 324/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0472\n",
      "Epoch 325/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0500\n",
      "Epoch 326/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0632\n",
      "Epoch 327/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0556\n",
      "Epoch 328/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0500\n",
      "Epoch 329/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0511\n",
      "Epoch 330/600\n",
      "60/60 [==============================] - 0s 76us/step - loss: 0.0574\n",
      "Epoch 331/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0536\n",
      "Epoch 332/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0555\n",
      "Epoch 333/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0548\n",
      "Epoch 334/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0475\n",
      "Epoch 335/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0557\n",
      "Epoch 336/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0529\n",
      "Epoch 337/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0501\n",
      "Epoch 338/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0515\n",
      "Epoch 339/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0515\n",
      "Epoch 340/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0481\n",
      "Epoch 341/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0463\n",
      "Epoch 342/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0580\n",
      "Epoch 343/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0501\n",
      "Epoch 344/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0526\n",
      "Epoch 345/600\n",
      "60/60 [==============================] - 0s 78us/step - loss: 0.0592\n",
      "Epoch 346/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0504\n",
      "Epoch 347/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0432\n",
      "Epoch 348/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0473\n",
      "Epoch 349/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0443\n",
      "Epoch 350/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0425\n",
      "Epoch 351/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0429\n",
      "Epoch 352/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0486\n",
      "Epoch 353/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0495\n",
      "Epoch 354/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0538\n",
      "Epoch 355/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0512\n",
      "Epoch 356/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0592\n",
      "Epoch 357/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0607\n",
      "Epoch 358/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0443\n",
      "Epoch 359/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0457\n",
      "Epoch 360/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0501\n",
      "Epoch 361/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0509\n",
      "Epoch 362/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0413\n",
      "Epoch 363/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0400\n",
      "Epoch 364/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0506\n",
      "Epoch 365/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0474\n",
      "Epoch 366/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0460\n",
      "Epoch 367/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0589\n",
      "Epoch 368/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0545\n",
      "Epoch 369/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0478\n",
      "Epoch 370/600\n",
      "60/60 [==============================] - 0s 80us/step - loss: 0.0459\n",
      "Epoch 371/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0480\n",
      "Epoch 372/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0535\n",
      "Epoch 373/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0498\n",
      "Epoch 374/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0510\n",
      "Epoch 375/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0487\n",
      "Epoch 376/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0481\n",
      "Epoch 377/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0425\n",
      "Epoch 378/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0523\n",
      "Epoch 379/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0558\n",
      "Epoch 380/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0539\n",
      "Epoch 381/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0487\n",
      "Epoch 382/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0458\n",
      "Epoch 383/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0417\n",
      "Epoch 384/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0542\n",
      "Epoch 385/600\n",
      "60/60 [==============================] - 0s 76us/step - loss: 0.0489\n",
      "Epoch 386/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0447\n",
      "Epoch 387/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0498\n",
      "Epoch 388/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0498\n",
      "Epoch 389/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0476\n",
      "Epoch 390/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0488\n",
      "Epoch 391/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0570\n",
      "Epoch 392/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0418\n",
      "Epoch 393/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0416\n",
      "Epoch 394/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0452\n",
      "Epoch 395/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0464\n",
      "Epoch 396/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0530\n",
      "Epoch 397/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0506\n",
      "Epoch 398/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0449\n",
      "Epoch 399/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0486\n",
      "Epoch 400/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0481\n",
      "Epoch 401/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0491\n",
      "Epoch 402/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0417\n",
      "Epoch 403/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0443\n",
      "Epoch 404/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0453\n",
      "Epoch 405/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0440\n",
      "Epoch 406/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0447\n",
      "Epoch 407/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0568\n",
      "Epoch 408/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0447\n",
      "Epoch 409/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0434\n",
      "Epoch 410/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0472\n",
      "Epoch 411/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0398\n",
      "Epoch 412/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0379\n",
      "Epoch 413/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0650\n",
      "Epoch 414/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0439\n",
      "Epoch 415/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0380\n",
      "Epoch 416/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0414\n",
      "Epoch 417/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0466\n",
      "Epoch 418/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0571\n",
      "Epoch 419/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0572\n",
      "Epoch 420/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0444\n",
      "Epoch 421/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0439\n",
      "Epoch 422/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0458\n",
      "Epoch 423/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0498\n",
      "Epoch 424/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0480\n",
      "Epoch 425/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0433\n",
      "Epoch 426/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0540\n",
      "Epoch 427/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0417\n",
      "Epoch 428/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0430\n",
      "Epoch 429/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0378\n",
      "Epoch 430/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0444\n",
      "Epoch 431/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0405\n",
      "Epoch 432/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0487\n",
      "Epoch 433/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0460\n",
      "Epoch 434/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0496\n",
      "Epoch 435/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0471\n",
      "Epoch 436/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0452\n",
      "Epoch 437/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0405\n",
      "Epoch 438/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0372\n",
      "Epoch 439/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0424\n",
      "Epoch 440/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0466\n",
      "Epoch 441/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0461\n",
      "Epoch 442/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0428\n",
      "Epoch 443/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0391\n",
      "Epoch 444/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0614\n",
      "Epoch 445/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0429\n",
      "Epoch 446/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0408\n",
      "Epoch 447/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0420\n",
      "Epoch 448/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0386\n",
      "Epoch 449/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0441\n",
      "Epoch 450/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0509\n",
      "Epoch 451/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0473\n",
      "Epoch 452/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0413\n",
      "Epoch 453/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0386\n",
      "Epoch 454/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0471\n",
      "Epoch 455/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0414\n",
      "Epoch 456/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0462\n",
      "Epoch 457/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0416\n",
      "Epoch 458/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0476\n",
      "Epoch 459/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0501\n",
      "Epoch 460/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0451\n",
      "Epoch 461/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0519\n",
      "Epoch 462/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0341\n",
      "Epoch 463/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0381\n",
      "Epoch 464/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0532\n",
      "Epoch 465/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0399\n",
      "Epoch 466/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0349\n",
      "Epoch 467/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0446\n",
      "Epoch 468/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0564\n",
      "Epoch 469/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0425\n",
      "Epoch 470/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0344\n",
      "Epoch 471/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0468\n",
      "Epoch 472/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0498\n",
      "Epoch 473/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0491\n",
      "Epoch 474/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0355\n",
      "Epoch 475/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0354\n",
      "Epoch 476/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0378\n",
      "Epoch 477/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0543\n",
      "Epoch 478/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0503\n",
      "Epoch 479/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0464\n",
      "Epoch 480/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0527\n",
      "Epoch 481/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0436\n",
      "Epoch 482/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0379\n",
      "Epoch 483/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0408\n",
      "Epoch 484/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0430\n",
      "Epoch 485/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0439\n",
      "Epoch 486/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0489\n",
      "Epoch 487/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0503\n",
      "Epoch 488/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0390\n",
      "Epoch 489/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0388\n",
      "Epoch 490/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0441\n",
      "Epoch 491/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0357\n",
      "Epoch 492/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0325\n",
      "Epoch 493/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0374\n",
      "Epoch 494/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0475\n",
      "Epoch 495/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0382\n",
      "Epoch 496/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0340\n",
      "Epoch 497/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0497\n",
      "Epoch 498/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0447\n",
      "Epoch 499/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0501\n",
      "Epoch 500/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0526\n",
      "Epoch 501/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0391\n",
      "Epoch 502/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0432\n",
      "Epoch 503/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0426\n",
      "Epoch 504/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0427\n",
      "Epoch 505/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0471\n",
      "Epoch 506/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0402\n",
      "Epoch 507/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0416\n",
      "Epoch 508/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0379\n",
      "Epoch 509/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0408\n",
      "Epoch 510/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0413\n",
      "Epoch 511/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0441\n",
      "Epoch 512/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0395\n",
      "Epoch 513/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0333\n",
      "Epoch 514/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0362\n",
      "Epoch 515/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0528\n",
      "Epoch 516/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0476\n",
      "Epoch 517/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0378\n",
      "Epoch 518/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0452\n",
      "Epoch 519/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0465\n",
      "Epoch 520/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0461\n",
      "Epoch 521/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0433\n",
      "Epoch 522/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0492\n",
      "Epoch 523/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0412\n",
      "Epoch 524/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0343\n",
      "Epoch 525/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0431\n",
      "Epoch 526/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0369\n",
      "Epoch 527/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0373\n",
      "Epoch 528/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0359\n",
      "Epoch 529/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0622\n",
      "Epoch 530/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0406\n",
      "Epoch 531/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0323\n",
      "Epoch 532/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0346\n",
      "Epoch 533/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0417\n",
      "Epoch 534/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0476\n",
      "Epoch 535/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0551\n",
      "Epoch 536/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0367\n",
      "Epoch 537/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0403\n",
      "Epoch 538/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0342\n",
      "Epoch 539/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0436\n",
      "Epoch 540/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0429\n",
      "Epoch 541/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0376\n",
      "Epoch 542/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0426\n",
      "Epoch 543/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0424\n",
      "Epoch 544/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0422\n",
      "Epoch 545/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0477\n",
      "Epoch 546/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0497\n",
      "Epoch 547/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0397\n",
      "Epoch 548/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0393\n",
      "Epoch 549/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0380\n",
      "Epoch 550/600\n",
      "60/60 [==============================] - 0s 84us/step - loss: 0.0397\n",
      "Epoch 551/600\n",
      "60/60 [==============================] - 0s 96us/step - loss: 0.0394\n",
      "Epoch 552/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0377\n",
      "Epoch 553/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0411\n",
      "Epoch 554/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0364\n",
      "Epoch 555/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0429\n",
      "Epoch 556/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0475\n",
      "Epoch 557/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0436\n",
      "Epoch 558/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0463\n",
      "Epoch 559/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0390\n",
      "Epoch 560/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0381\n",
      "Epoch 561/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0393\n",
      "Epoch 562/600\n",
      "60/60 [==============================] - 0s 80us/step - loss: 0.0430\n",
      "Epoch 563/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0359\n",
      "Epoch 564/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0417\n",
      "Epoch 565/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0395\n",
      "Epoch 566/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0486\n",
      "Epoch 567/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0422\n",
      "Epoch 568/600\n",
      "60/60 [==============================] - 0s 79us/step - loss: 0.0315\n",
      "Epoch 569/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0438\n",
      "Epoch 570/600\n",
      "60/60 [==============================] - 0s 76us/step - loss: 0.0417\n",
      "Epoch 571/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0468\n",
      "Epoch 572/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0439\n",
      "Epoch 573/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0388\n",
      "Epoch 574/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0386\n",
      "Epoch 575/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0371\n",
      "Epoch 576/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0327\n",
      "Epoch 577/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0329\n",
      "Epoch 578/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0429\n",
      "Epoch 579/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0495\n",
      "Epoch 580/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0416\n",
      "Epoch 581/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0383\n",
      "Epoch 582/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0416\n",
      "Epoch 583/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0384\n",
      "Epoch 584/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0439\n",
      "Epoch 585/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0381\n",
      "Epoch 586/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0321\n",
      "Epoch 587/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0385\n",
      "Epoch 588/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0368\n",
      "Epoch 589/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0478\n",
      "Epoch 590/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0537\n",
      "Epoch 591/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0402\n",
      "Epoch 592/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0342\n",
      "Epoch 593/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0445\n",
      "Epoch 594/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0344\n",
      "Epoch 595/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0322\n",
      "Epoch 596/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0315\n",
      "Epoch 597/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0344\n",
      "Epoch 598/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0410\n",
      "Epoch 599/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0469\n",
      "Epoch 600/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0376\n",
      "best epoch =  568\n",
      "smallest loss = 0.03148321534196536\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 80, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(xarray,yarray,epochs=600,callbacks=[es])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8029e58b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# creating a surface plot\n",
    "import matplotlib.pyplot as plt\n",
    "test = []\n",
    "outpt=[]\n",
    "T1 = np.linspace( 268,318,num=35)\n",
    "Qs = np.linspace(500,2500,num=35)\n",
    "Z = np.zeros((len(Qs),len(T1)))\n",
    "for i in range(len(T1)):\n",
    "    for j in range(len(Qs)):\n",
    "        test = [[ T1[i]/Tmed , 0.25/gamed , Qs[j]/qsmed ]]\n",
    "        testarray = np.array(test)\n",
    "        outpt = model.predict(testarray)\n",
    "        Z[i][j]=outpt[0][0]*almed\n",
    "X,Y = np.meshgrid(T1,Qs)\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "        \n",
    "surf = ax.plot_surface(X,Y, Z, cmap=plt.cm.coolwarm, linewidth = 0, antialiased = False)\n",
    "\n",
    "ax.set_xlabel('T1', fontsize=20)\n",
    "ax.set_ylabel('Qs', fontsize = 20)\n",
    "ax.zaxis.set_rotate_label(False)\n",
    "ax.set_zlabel('Alpha', fontsize = 20, rotation = 90)\n",
    "fig.colorbar(surf,shrink=0.5,aspect=10)\n",
    "\n",
    "ax.view_init(30,225)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e462eb0e-7025-4d92-938e-b3d661174287",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Task 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350d550f-77f4-4d0a-88ee-819423dd29c7",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1859fc2-7159-41bb-b88f-a21b02830093",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0761421319796953, 0.0, 0.3333333333333333], [1.0761421319796953, 0.0, 1.0], [1.0761421319796953, 0.0, 1.6666666666666667], [1.0761421319796953, 1.0, 1.0], [1.0761421319796953, 2.0, 0.3333333333333333], [1.0761421319796953, 2.0, 1.0], [1.0761421319796953, 2.0, 1.6666666666666667], [1.0253807106598984, 0.0, 0.6666666666666666], [1.0253807106598984, 0.0, 1.3333333333333333], [1.0253807106598984, 1.0, 0.6666666666666666], [1.0253807106598984, 1.0, 1.3333333333333333], [1.0253807106598984, 2.0, 0.6666666666666666], [1.0253807106598984, 2.0, 1.3333333333333333], [0.9746192893401016, 0.0, 0.3333333333333333], [0.9746192893401016, 0.0, 1.6666666666666667], [0.9746192893401016, 1.0, 1.6666666666666667], [0.9746192893401016, 2.0, 1.0], [0.9069373942470389, 0.0, 1.0], [0.9069373942470389, 1.0, 1.3333333333333333], [0.9069373942470389, 2.0, 1.6666666666666667]]\n",
      "[[0.5741195158961486, 0.8814814814814815], [0.7756251700663596, 0.9097222222222223], [1.1949791916403754, 0.9400462962962963], [1.0841755959166097, 0.9486111111111111], [1.03106177790743, 0.961574074074074], [1.3928894488991956, 0.9715277777777779], [2.1461251018355316, 0.9819444444444445], [0.6372023889778204, 0.9287037037037037], [0.8792379719673439, 0.9574074074074075], [0.8908412983631955, 0.9756944444444444], [1.229298889430922, 0.9930555555555556], [1.1446436348809066, 1.0039351851851852], [1.5795232340268364, 1.0143518518518517], [0.5466637576637111, 0.9469907407407407], [0.9936369646025002, 1.0032407407407409], [1.3898497042377471, 1.0363425925925926], [1.2675408383975315, 1.0453703703703703], [0.6648215743425939, 1.0145833333333334], [1.0661986113596564, 1.0712962962962962], [1.6053447209359144, 1.1018518518518519]]\n",
      "[35.13, 47.46, 73.12, 66.34, 63.09, 85.23, 131.32, 38.99, 53.8, 54.51, 75.22, 70.04, 96.65, 33.45, 60.8, 85.044, 77.56, 40.68, 65.24, 98.23]\n",
      "[35.984717345792056, 46.945716231805086, 67.48897452878953, 65.39534607143999, 63.525836178070314, 83.74066686421037, 112.60955962534548, 38.76179618461132, 52.58438976759017, 54.51526693447531, 73.91983880381585, 69.71203373631836, 94.64697279683948, 33.11060191603303, 61.55809342217446, 84.27486048225761, 77.21311612651348, 39.693742810803656, 67.02186694598794, 101.50361493022443]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rmse deviation of alpha test from alpha predicted: 4.525983397229046\n"
     ]
    }
   ],
   "source": [
    "#Test data(distinct from training data) provided for predicting alpha \n",
    "import math\n",
    "testDataX = []\n",
    "testDataX.append([ 318.0 , 0.0 , 500.0 ])\n",
    "testDataX.append([ 318.0 , 0.0 , 1500.0 ])\n",
    "testDataX.append([ 318.0 , 0.0 , 2500.0 ])\n",
    "testDataX.append([ 318.0 , 0.25 , 1500.0 ])\n",
    "testDataX.append([ 318.0 , 0.5 , 500.0 ])\n",
    "testDataX.append([ 318.0 , 0.5 , 1500.0 ])\n",
    "testDataX.append([ 318.0 , 0.5 , 2500.0 ])\n",
    "testDataX.append([ 303.0 , 0.0 , 1000.0 ])\n",
    "testDataX.append([ 303.0 , 0.0 , 2000.0 ])\n",
    "testDataX.append([ 303.0 , 0.25 , 1000.0 ])\n",
    "testDataX.append([ 303.0 , 0.25 , 2000.0 ])\n",
    "testDataX.append([ 303.0 , 0.5 , 1000.0 ])\n",
    "testDataX.append([ 303.0 , 0.5 , 2000.0 ])\n",
    "testDataX.append([ 288.0 , 0.0 , 500.0 ])\n",
    "testDataX.append([ 288.0 , 0.0 , 2500.0 ])\n",
    "testDataX.append([ 288.0 , 0.25 , 2500.0 ])\n",
    "testDataX.append([ 288.0 , 0.5 , 1500.0 ])\n",
    "testDataX.append([ 268.0 , 0.0 , 1500.0 ])\n",
    "testDataX.append([ 268.0 , 0.25 , 2000.0 ])\n",
    "testDataX.append([ 268.0 , 0.5 , 2500.0 ])\n",
    "\n",
    "testDataY = []\n",
    "testDataY.append([ 35.13 , 0.3808 ])\n",
    "testDataY.append([ 47.46 , 0.3930 ])\n",
    "testDataY.append([ 73.12 , 0.4061 ])\n",
    "testDataY.append([ 66.34 , 0.4098 ])\n",
    "testDataY.append([ 63.09, 0.4154 ])\n",
    "testDataY.append([ 85.23 , 0.4197 ])\n",
    "testDataY.append([131.32 , 0.4242 ])\n",
    "testDataY.append([ 38.99 , 0.4012 ])\n",
    "testDataY.append([ 53.80 , 0.4136 ])\n",
    "testDataY.append([ 54.51 , 0.4215 ])\n",
    "testDataY.append([ 75.22 , 0.4290 ])\n",
    "testDataY.append([ 70.04, 0.4337 ])\n",
    "testDataY.append([ 96.65, 0.4382 ])\n",
    "testDataY.append([ 33.45 , 0.4091 ])\n",
    "testDataY.append([ 60.80 , 0.4334 ])\n",
    "testDataY.append([ 85.044, 0.4477])\n",
    "testDataY.append([ 77.56 , 0.4516 ])\n",
    "testDataY.append([ 40.68 , 0.4383 ])\n",
    "testDataY.append([ 65.24 , 0.4628 ])\n",
    "testDataY.append([ 98.23 , 0.4760 ])\n",
    "\n",
    "#normalizing the test data using the median values calculated using the training data\n",
    "Nx = []\n",
    "for i in range(len(testDataX)):\n",
    "    Nx.append([ testDataX[i][0]/Tmed , testDataX[i][1]/gamed , testDataX[i][2]/qsmed ])\n",
    "testDataX = Nx\n",
    "Ny=[]\n",
    "altest=[]\n",
    "for i in range(len(testDataY)):\n",
    "    altest.append(testDataY[i][0])\n",
    "    Ny.append([ testDataY[i][0]/almed , testDataY[i][1]/efmed ])\n",
    "testDataY=Ny\n",
    "print(testDataX)\n",
    "print(testDataY)\n",
    "alpred=[]\n",
    "#calculating the predicted alpha using the model predict function\n",
    "for i in range(len(testDataX)):\n",
    "    test = [[ testDataX[i][0] , testDataX[i][1] , testDataX[i][2] ]]\n",
    "    testarray = np.array(test)\n",
    "    outpt = model.predict(testarray)\n",
    "    alpred.append(outpt[0][0]*almed)\n",
    "print(altest)\n",
    "print(alpred)\n",
    "#plot alpha test data vs. alpha predicted\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.scatter(altest,alpred)\n",
    "plt.xlabel('alpha test data', fontsize='16')\n",
    "plt.ylabel('alpha predicted', fontsize='16')\n",
    "plt.loglog()\n",
    "plt.show()\n",
    "\n",
    "#calculate the rmse value     \n",
    "MSE = np.square(np.subtract(alpred,altest)).mean() \n",
    "RMSE = math.sqrt(MSE)\n",
    "print(\"Rmse deviation of alpha test from alpha predicted:\", RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d4f491-5b3c-4bc6-8e08-261cb2d447b1",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9841803e-6c02-4d41-98a0-b026ae9b5c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data for a daylong variation of operating conditions given\n",
    "time = [9,10,11,12,13,14,15,16,17,18,19]\n",
    "\n",
    "#alpha prediction for gamma =0\n",
    "#Data with propane to fuel ratio (gamma)=0\n",
    "operData = []\n",
    "operData.append([ 287.0 ,  0, 490.0])\n",
    "operData.append([ 295.0 ,  0, 720.0])\n",
    "operData.append([ 301.0 ,  0, 980.0 ])\n",
    "operData.append([ 305.0 ,  0, 2420.0])\n",
    "operData.append([ 307.0 ,  0, 2570.0])\n",
    "operData.append([ 308.0 ,  0, 2380.0])\n",
    "operData.append([ 308.0 ,  0, 2075.0])\n",
    "operData.append([ 305.0 ,  0, 1680.0])\n",
    "operData.append([ 295.0 ,  0, 1000.0])\n",
    "operData.append([ 292.0 ,  0, 800.0])\n",
    "operData.append([ 295.0 ,  0, 250.0])\n",
    "Nx = []\n",
    "alpred=[]\n",
    "for i in range(len(operData)):\n",
    "    Nx.append([ operData[i][0]/Tmed , operData[i][1]/gamed , operData[i][2]/qsmed ])\n",
    "operData = Nx\n",
    "#calculating the predicted alpha using the model predict function\n",
    "for i in range(len(operData)):\n",
    "    test = [[ operData[i][0] , operData[i][1] , operData[i][2] ]]\n",
    "    testarray = np.array(test)\n",
    "    outpt = model.predict(testarray)\n",
    "    alpred.append(outpt[0][0]*almed)\n",
    "#plot alpha predicted vs. time of the day\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.scatter(time,alpred)\n",
    "plt.xlabel('Time of day', fontsize='16')\n",
    "plt.ylabel('alpha predicted', fontsize='16')\n",
    "plt.loglog()\n",
    "plt.show()\n",
    "\n",
    "#alpha prediction for gamma =0.5\n",
    "#Data with propane to fuel ratio (gamma)=0.5\n",
    "operData = []\n",
    "operData.append([ 287.0 ,  0.5, 490.0])\n",
    "operData.append([ 295.0 ,  0.5, 720.0])\n",
    "operData.append([ 301.0 ,  0.5, 980.0 ])\n",
    "operData.append([ 305.0 ,  0.5, 2420.0])\n",
    "operData.append([ 307.0 ,  0.5, 2570.0])\n",
    "operData.append([ 308.0 ,  0.5, 2380.0])\n",
    "operData.append([ 308.0 ,  0.5, 2075.0])\n",
    "operData.append([ 305.0 ,  0.5, 1680.0])\n",
    "operData.append([ 295.0 ,  0.5, 1000.0])\n",
    "operData.append([ 292.0 ,  0.5, 800.0])\n",
    "operData.append([ 295.0 ,  0.5, 250.0])\n",
    "Nx = []\n",
    "alpred=[]\n",
    "for i in range(len(operData)):\n",
    "    Nx.append([ operData[i][0]/Tmed , operData[i][1]/gamed , operData[i][2]/qsmed ])\n",
    "operData = Nx\n",
    "#calculating the predicted alpha using the model predict function\n",
    "for i in range(len(operData)):\n",
    "    test = [[ operData[i][0] , operData[i][1] , operData[i][2] ]]\n",
    "    testarray = np.array(test)\n",
    "    outpt = model.predict(testarray)\n",
    "    alpred.append(outpt[0][0]*almed)\n",
    "#plot alpha predicted vs. time of the day\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.scatter(time,alpred)\n",
    "plt.xlabel('Time of day', fontsize='16')\n",
    "plt.ylabel('alpha predicted', fontsize='16')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf937c3-5c49-4806-a759-1cb5af0417b1",
   "metadata": {},
   "source": [
    "## Task 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ddb22e-684f-4e32-85cd-d9c49ea5f44c",
   "metadata": {},
   "source": [
    "### Modification one\n",
    "activation function changed to elu from relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c6c8566-a21a-442b-8300-08c51480b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "\n",
    "#As seen below, we have created four dense layers. \n",
    "#A dense layer is a layer in neural network that’s fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 1 in our case. \n",
    "#The activation function we have chosen is elu, which stands for exponential linear unit. .\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 1.2\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(16, activation=K.elu, input_shape=[3],  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(32, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(16, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(2,  kernel_initializer=initializer)\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e445286-c0b2-43e4-8ca4-b5e4d97d2384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean squared error. After the compilation of the model, we’ll use the fit method with ~500 epochs.\n",
    "#Number of epochs can be varied.\n",
    "\n",
    "#from tf.keras import optimizers\n",
    "rms = keras.optimizers.RMSprop(0.001)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f430a3e-818b-4149-a855-2900636a63eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "60/60 [==============================] - 0s 163us/step - loss: 0.0626\n",
      "Epoch 2/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0663\n",
      "Epoch 3/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0701\n",
      "Epoch 4/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0574\n",
      "Epoch 5/600\n",
      "60/60 [==============================] - 0s 54us/step - loss: 0.0516\n",
      "Epoch 6/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0651\n",
      "Epoch 7/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0740\n",
      "Epoch 8/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0474\n",
      "Epoch 9/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0629\n",
      "Epoch 10/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0503\n",
      "Epoch 11/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0655\n",
      "Epoch 12/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0653\n",
      "Epoch 13/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0510\n",
      "Epoch 14/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0717\n",
      "Epoch 15/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0657\n",
      "Epoch 16/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0521\n",
      "Epoch 17/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0549\n",
      "Epoch 18/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0674\n",
      "Epoch 19/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0488\n",
      "Epoch 20/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0596\n",
      "Epoch 21/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0499\n",
      "Epoch 22/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0574\n",
      "Epoch 23/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0533\n",
      "Epoch 24/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0512\n",
      "Epoch 25/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0633\n",
      "Epoch 26/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0688\n",
      "Epoch 27/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0534\n",
      "Epoch 28/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0633\n",
      "Epoch 29/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0619\n",
      "Epoch 30/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0548\n",
      "Epoch 31/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0553\n",
      "Epoch 32/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0670\n",
      "Epoch 33/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0514\n",
      "Epoch 34/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0508\n",
      "Epoch 35/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0656\n",
      "Epoch 36/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0525\n",
      "Epoch 37/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0499\n",
      "Epoch 38/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0525\n",
      "Epoch 39/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0791\n",
      "Epoch 40/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0615\n",
      "Epoch 41/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0601\n",
      "Epoch 42/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0663\n",
      "Epoch 43/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0438\n",
      "Epoch 44/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0489\n",
      "Epoch 45/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0639\n",
      "Epoch 46/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0566\n",
      "Epoch 47/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0668\n",
      "Epoch 48/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0469\n",
      "Epoch 49/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0497\n",
      "Epoch 50/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0658\n",
      "Epoch 51/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0571\n",
      "Epoch 52/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0572\n",
      "Epoch 53/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0601\n",
      "Epoch 54/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0465\n",
      "Epoch 55/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0647\n",
      "Epoch 56/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0793\n",
      "Epoch 57/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0498\n",
      "Epoch 58/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0690\n",
      "Epoch 59/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0579\n",
      "Epoch 60/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0647\n",
      "Epoch 61/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0542\n",
      "Epoch 62/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0510\n",
      "Epoch 63/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0503\n",
      "Epoch 64/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0521\n",
      "Epoch 65/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0663\n",
      "Epoch 66/600\n",
      "60/60 [==============================] - 0s 79us/step - loss: 0.0543\n",
      "Epoch 67/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0562\n",
      "Epoch 68/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0553\n",
      "Epoch 69/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0773\n",
      "Epoch 70/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0542\n",
      "Epoch 71/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0462\n",
      "Epoch 72/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0525\n",
      "Epoch 73/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0569\n",
      "Epoch 74/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0609\n",
      "Epoch 75/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0698\n",
      "Epoch 76/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0535\n",
      "Epoch 77/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0593\n",
      "Epoch 78/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0556\n",
      "Epoch 79/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0555\n",
      "Epoch 80/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0683\n",
      "Epoch 81/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0629\n",
      "Epoch 82/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0557\n",
      "Epoch 83/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0521\n",
      "Epoch 84/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0553\n",
      "Epoch 85/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0438\n",
      "Epoch 86/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0450\n",
      "Epoch 87/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0522\n",
      "Epoch 88/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0591\n",
      "Epoch 89/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0630\n",
      "Epoch 90/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0788\n",
      "Epoch 91/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0580\n",
      "Epoch 92/600\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.046 - 0s 66us/step - loss: 0.0554\n",
      "Epoch 93/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0560\n",
      "Epoch 94/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0457\n",
      "Epoch 95/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0560\n",
      "Epoch 96/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0458\n",
      "Epoch 97/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0413\n",
      "Epoch 98/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0456\n",
      "Epoch 99/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0705\n",
      "Epoch 100/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0622\n",
      "Epoch 101/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0589\n",
      "Epoch 102/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0625\n",
      "Epoch 103/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0710\n",
      "Epoch 104/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0517\n",
      "Epoch 105/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0531\n",
      "Epoch 106/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0589\n",
      "Epoch 107/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0464\n",
      "Epoch 108/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0559\n",
      "Epoch 109/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0542\n",
      "Epoch 110/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0653\n",
      "Epoch 111/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0567\n",
      "Epoch 112/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0598\n",
      "Epoch 113/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0468\n",
      "Epoch 114/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0405\n",
      "Epoch 115/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0564\n",
      "Epoch 116/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0598\n",
      "Epoch 117/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0687\n",
      "Epoch 118/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0538\n",
      "Epoch 119/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0573\n",
      "Epoch 120/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0615\n",
      "Epoch 121/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0572\n",
      "Epoch 122/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0523\n",
      "Epoch 123/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0572\n",
      "Epoch 124/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0585\n",
      "Epoch 125/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0500\n",
      "Epoch 126/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0579\n",
      "Epoch 127/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0678\n",
      "Epoch 128/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0608\n",
      "Epoch 129/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0496\n",
      "Epoch 130/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0559\n",
      "Epoch 131/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0523\n",
      "Epoch 132/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0518\n",
      "Epoch 133/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0683\n",
      "Epoch 134/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0531\n",
      "Epoch 135/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0562\n",
      "Epoch 136/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0627\n",
      "Epoch 137/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0424\n",
      "Epoch 138/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0551\n",
      "Epoch 139/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0532\n",
      "Epoch 140/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0516\n",
      "Epoch 141/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0555\n",
      "Epoch 142/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0497\n",
      "Epoch 143/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0539\n",
      "Epoch 144/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0424\n",
      "Epoch 145/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0525\n",
      "Epoch 146/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0700\n",
      "Epoch 147/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0673\n",
      "Epoch 148/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0523\n",
      "Epoch 149/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0462\n",
      "Epoch 150/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0443\n",
      "Epoch 151/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0520\n",
      "Epoch 152/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0566\n",
      "Epoch 153/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0526\n",
      "Epoch 154/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0533\n",
      "Epoch 155/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0546\n",
      "Epoch 156/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0566\n",
      "Epoch 157/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0719\n",
      "Epoch 158/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0481\n",
      "Epoch 159/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0510\n",
      "Epoch 160/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0574\n",
      "Epoch 161/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0684\n",
      "Epoch 162/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0483\n",
      "Epoch 163/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0394\n",
      "Epoch 164/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0457\n",
      "Epoch 165/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0527\n",
      "Epoch 166/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0537\n",
      "Epoch 167/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0724\n",
      "Epoch 168/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0577\n",
      "Epoch 169/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0516\n",
      "Epoch 170/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0511\n",
      "Epoch 171/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0518\n",
      "Epoch 172/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0651\n",
      "Epoch 173/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0535\n",
      "Epoch 174/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0541\n",
      "Epoch 175/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0602\n",
      "Epoch 176/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0533\n",
      "Epoch 177/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0608\n",
      "Epoch 178/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0523\n",
      "Epoch 179/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0538\n",
      "Epoch 180/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0513\n",
      "Epoch 181/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0615\n",
      "Epoch 182/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0493\n",
      "Epoch 183/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0455\n",
      "Epoch 184/600\n",
      "60/60 [==============================] - 0s 53us/step - loss: 0.0663\n",
      "Epoch 185/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0478\n",
      "Epoch 186/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0536\n",
      "Epoch 187/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0512\n",
      "Epoch 188/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0504\n",
      "Epoch 189/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0616\n",
      "Epoch 190/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0389\n",
      "Epoch 191/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0554\n",
      "Epoch 192/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0577\n",
      "Epoch 193/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0598\n",
      "Epoch 194/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0554\n",
      "Epoch 195/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0478\n",
      "Epoch 196/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0504\n",
      "Epoch 197/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0569\n",
      "Epoch 198/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0594\n",
      "Epoch 199/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0535\n",
      "Epoch 200/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0494\n",
      "Epoch 201/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0391\n",
      "Epoch 202/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0479\n",
      "Epoch 203/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0577\n",
      "Epoch 204/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0527\n",
      "Epoch 205/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0542\n",
      "Epoch 206/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0568\n",
      "Epoch 207/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0616\n",
      "Epoch 208/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0547\n",
      "Epoch 209/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0514\n",
      "Epoch 210/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0493\n",
      "Epoch 211/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0595\n",
      "Epoch 212/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0548\n",
      "Epoch 213/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0483\n",
      "Epoch 214/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0580\n",
      "Epoch 215/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0469\n",
      "Epoch 216/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0562\n",
      "Epoch 217/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0451\n",
      "Epoch 218/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0592\n",
      "Epoch 219/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0621\n",
      "Epoch 220/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0530\n",
      "Epoch 221/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0523\n",
      "Epoch 222/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0480\n",
      "Epoch 223/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0495\n",
      "Epoch 224/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0514\n",
      "Epoch 225/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0506\n",
      "Epoch 226/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0570\n",
      "Epoch 227/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0577\n",
      "Epoch 228/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0514\n",
      "Epoch 229/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0467\n",
      "Epoch 230/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0536\n",
      "Epoch 231/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0549\n",
      "Epoch 232/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0543\n",
      "Epoch 233/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0574\n",
      "Epoch 234/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0480\n",
      "Epoch 235/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0525\n",
      "Epoch 236/600\n",
      "60/60 [==============================] - 0s 54us/step - loss: 0.0533\n",
      "Epoch 237/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0562\n",
      "Epoch 238/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0514\n",
      "Epoch 239/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0570\n",
      "Epoch 240/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0471\n",
      "Epoch 241/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0454\n",
      "Epoch 242/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0675\n",
      "Epoch 243/600\n",
      "60/60 [==============================] - 0s 76us/step - loss: 0.0602\n",
      "Epoch 244/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0522\n",
      "Epoch 245/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0438\n",
      "Epoch 246/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0488\n",
      "Epoch 247/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0534\n",
      "Epoch 248/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0516\n",
      "Epoch 249/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0564\n",
      "Epoch 250/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0514\n",
      "Epoch 251/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0659\n",
      "Epoch 252/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0528\n",
      "Epoch 253/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0542\n",
      "Epoch 254/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0542\n",
      "Epoch 255/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0429\n",
      "Epoch 256/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0524\n",
      "Epoch 257/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0481\n",
      "Epoch 258/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0635\n",
      "Epoch 259/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0491\n",
      "Epoch 260/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0562\n",
      "Epoch 261/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0495\n",
      "Epoch 262/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0549\n",
      "Epoch 263/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0457\n",
      "Epoch 264/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0526\n",
      "Epoch 265/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0588\n",
      "Epoch 266/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0464\n",
      "Epoch 267/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0456\n",
      "Epoch 268/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0614\n",
      "Epoch 269/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0506\n",
      "Epoch 270/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0436\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00270: early stopping\n",
      "best epoch =  190\n",
      "smallest loss = 0.03891446627676487\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 80, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(xarray,yarray,epochs=600,callbacks=[es])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9279cb13-c947-4240-94b1-af0577ce3583",
   "metadata": {},
   "source": [
    "### Modification two\n",
    "baseline neural network with an added layer and number of neurons in layers set to 12,24,12,12,2\n",
    "All activation functions assigned as relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "babd1bef-1a0a-4d8d-b9c4-a27481842c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "\n",
    "#As seen below, we have created four dense layers. \n",
    "#A dense layer is a layer in neural network that’s fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 1 in our case. \n",
    "#The activation function we have chosen is elu, which stands for exponential linear unit. .\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 1.2\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(12, activation=K.relu, input_shape=[3],  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(24, activation=K.relu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(12, activation=K.relu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(12, activation=K.relu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(2,  kernel_initializer=initializer)\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db2e7705-01ce-4e75-b8a6-f1704e702887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean squared error. After the compilation of the model, we’ll use the fit method with ~500 epochs.\n",
    "#Number of epochs can be varied.\n",
    "\n",
    "#from tf.keras import optimizers\n",
    "rms = keras.optimizers.RMSprop(0.001)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9054bfa-3855-438d-852e-e46b89674ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "60/60 [==============================] - 0s 115us/step - loss: 0.0438\n",
      "Epoch 2/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0439\n",
      "Epoch 3/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0422\n",
      "Epoch 4/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0450\n",
      "Epoch 5/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0463\n",
      "Epoch 6/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0444\n",
      "Epoch 7/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0377\n",
      "Epoch 8/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0452\n",
      "Epoch 9/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0436\n",
      "Epoch 10/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0577\n",
      "Epoch 11/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0464\n",
      "Epoch 12/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0427\n",
      "Epoch 13/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0483\n",
      "Epoch 14/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0407\n",
      "Epoch 15/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0439\n",
      "Epoch 16/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0456\n",
      "Epoch 17/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0528\n",
      "Epoch 18/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0422\n",
      "Epoch 19/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0374\n",
      "Epoch 20/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0398\n",
      "Epoch 21/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0520\n",
      "Epoch 22/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0441\n",
      "Epoch 23/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0433\n",
      "Epoch 24/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0435\n",
      "Epoch 25/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0484\n",
      "Epoch 26/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0580\n",
      "Epoch 27/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0406\n",
      "Epoch 28/600\n",
      "60/60 [==============================] - 0s 78us/step - loss: 0.0395\n",
      "Epoch 29/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0420\n",
      "Epoch 30/600\n",
      "60/60 [==============================] - 0s 78us/step - loss: 0.0482\n",
      "Epoch 31/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0496\n",
      "Epoch 32/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0447\n",
      "Epoch 33/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0417\n",
      "Epoch 34/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0407\n",
      "Epoch 35/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0459\n",
      "Epoch 36/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0450\n",
      "Epoch 37/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0411\n",
      "Epoch 38/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0411\n",
      "Epoch 39/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0394\n",
      "Epoch 40/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0436\n",
      "Epoch 41/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0430\n",
      "Epoch 42/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0471\n",
      "Epoch 43/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0440\n",
      "Epoch 44/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0465\n",
      "Epoch 45/600\n",
      "60/60 [==============================] - 0s 85us/step - loss: 0.0375\n",
      "Epoch 46/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0412\n",
      "Epoch 47/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0441\n",
      "Epoch 48/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0446\n",
      "Epoch 49/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0585\n",
      "Epoch 50/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0460\n",
      "Epoch 51/600\n",
      "60/60 [==============================] - 0s 85us/step - loss: 0.0391\n",
      "Epoch 52/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0490\n",
      "Epoch 53/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0484\n",
      "Epoch 54/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0541\n",
      "Epoch 55/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0463\n",
      "Epoch 56/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0400\n",
      "Epoch 57/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0410\n",
      "Epoch 58/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0446\n",
      "Epoch 59/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0433\n",
      "Epoch 60/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0364\n",
      "Epoch 61/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0388\n",
      "Epoch 62/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0569\n",
      "Epoch 63/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0444\n",
      "Epoch 64/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0405\n",
      "Epoch 65/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0350\n",
      "Epoch 66/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0539\n",
      "Epoch 67/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0432\n",
      "Epoch 68/600\n",
      "60/60 [==============================] - 0s 81us/step - loss: 0.0401\n",
      "Epoch 69/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0385\n",
      "Epoch 70/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0551\n",
      "Epoch 71/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0474\n",
      "Epoch 72/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0406\n",
      "Epoch 73/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0397\n",
      "Epoch 74/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0568\n",
      "Epoch 75/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0465\n",
      "Epoch 76/600\n",
      "60/60 [==============================] - 0s 80us/step - loss: 0.0500\n",
      "Epoch 77/600\n",
      "60/60 [==============================] - 0s 80us/step - loss: 0.0481\n",
      "Epoch 78/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0412\n",
      "Epoch 79/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0410\n",
      "Epoch 80/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0421\n",
      "Epoch 81/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0369\n",
      "Epoch 82/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0401\n",
      "Epoch 83/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0394\n",
      "Epoch 84/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0359\n",
      "Epoch 85/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0543\n",
      "Epoch 86/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0474\n",
      "Epoch 87/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0410\n",
      "Epoch 88/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0407\n",
      "Epoch 89/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0376\n",
      "Epoch 90/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0402\n",
      "Epoch 91/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0357\n",
      "Epoch 92/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0377\n",
      "Epoch 93/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0525\n",
      "Epoch 94/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0412\n",
      "Epoch 95/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0362\n",
      "Epoch 96/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0416\n",
      "Epoch 97/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0600\n",
      "Epoch 98/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0409\n",
      "Epoch 99/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0393\n",
      "Epoch 100/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0437\n",
      "Epoch 101/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0431\n",
      "Epoch 102/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0443\n",
      "Epoch 103/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0484\n",
      "Epoch 104/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0357\n",
      "Epoch 105/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0352\n",
      "Epoch 106/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0388\n",
      "Epoch 107/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0414\n",
      "Epoch 108/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0431\n",
      "Epoch 109/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0494\n",
      "Epoch 110/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0486\n",
      "Epoch 111/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0396\n",
      "Epoch 112/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0382\n",
      "Epoch 113/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0432\n",
      "Epoch 114/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0429\n",
      "Epoch 115/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0386\n",
      "Epoch 116/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0445\n",
      "Epoch 117/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0364\n",
      "Epoch 118/600\n",
      "60/60 [==============================] - 0s 80us/step - loss: 0.0484\n",
      "Epoch 119/600\n",
      "60/60 [==============================] - 0s 84us/step - loss: 0.0403\n",
      "Epoch 120/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0350\n",
      "Epoch 121/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0507\n",
      "Epoch 122/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0459\n",
      "Epoch 123/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0463\n",
      "Epoch 124/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0463\n",
      "Epoch 125/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0409\n",
      "Epoch 126/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0454\n",
      "Epoch 127/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0429\n",
      "Epoch 128/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0367\n",
      "Epoch 129/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0361\n",
      "Epoch 130/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0414\n",
      "Epoch 131/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0454\n",
      "Epoch 132/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0531\n",
      "Epoch 133/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0400\n",
      "Epoch 134/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0445\n",
      "Epoch 135/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0447\n",
      "Epoch 136/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0468\n",
      "Epoch 137/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0410\n",
      "Epoch 138/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0384\n",
      "Epoch 139/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0449\n",
      "Epoch 140/600\n",
      "60/60 [==============================] - 0s 79us/step - loss: 0.0372\n",
      "Epoch 141/600\n",
      "60/60 [==============================] - 0s 89us/step - loss: 0.0427\n",
      "Epoch 142/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0337\n",
      "Epoch 143/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0453\n",
      "Epoch 144/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0377\n",
      "Epoch 145/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0351\n",
      "Epoch 146/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0527\n",
      "Epoch 147/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0474\n",
      "Epoch 148/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0482\n",
      "Epoch 149/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0434\n",
      "Epoch 150/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0426\n",
      "Epoch 151/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0435\n",
      "Epoch 152/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0496\n",
      "Epoch 153/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0447\n",
      "Epoch 154/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0460\n",
      "Epoch 155/600\n",
      "60/60 [==============================] - 0s 80us/step - loss: 0.0391\n",
      "Epoch 156/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0401\n",
      "Epoch 157/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0374\n",
      "Epoch 158/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0470\n",
      "Epoch 159/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0465\n",
      "Epoch 160/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0329\n",
      "Epoch 161/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0396\n",
      "Epoch 162/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0430\n",
      "Epoch 163/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0519\n",
      "Epoch 164/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0311\n",
      "Epoch 165/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0456\n",
      "Epoch 166/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0352\n",
      "Epoch 167/600\n",
      "60/60 [==============================] - 0s 78us/step - loss: 0.0389\n",
      "Epoch 168/600\n",
      "60/60 [==============================] - 0s 80us/step - loss: 0.0376\n",
      "Epoch 169/600\n",
      "60/60 [==============================] - 0s 81us/step - loss: 0.0344\n",
      "Epoch 170/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0374\n",
      "Epoch 171/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0419\n",
      "Epoch 172/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0644\n",
      "Epoch 173/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0464\n",
      "Epoch 174/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0523\n",
      "Epoch 175/600\n",
      "60/60 [==============================] - 0s 81us/step - loss: 0.0373\n",
      "Epoch 176/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0422\n",
      "Epoch 177/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0474\n",
      "Epoch 178/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0360\n",
      "Epoch 179/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0336\n",
      "Epoch 180/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0352\n",
      "Epoch 181/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0386\n",
      "Epoch 182/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0396\n",
      "Epoch 183/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0429\n",
      "Epoch 184/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0432\n",
      "Epoch 185/600\n",
      "60/60 [==============================] - 0s 78us/step - loss: 0.0516\n",
      "Epoch 186/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0496\n",
      "Epoch 187/600\n",
      "60/60 [==============================] - 0s 86us/step - loss: 0.0342\n",
      "Epoch 188/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0314\n",
      "Epoch 189/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0350\n",
      "Epoch 190/600\n",
      "60/60 [==============================] - 0s 78us/step - loss: 0.0448\n",
      "Epoch 191/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0407\n",
      "Epoch 192/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0383\n",
      "Epoch 193/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0414\n",
      "Epoch 194/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0322\n",
      "Epoch 195/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0423\n",
      "Epoch 196/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0389\n",
      "Epoch 197/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0416\n",
      "Epoch 198/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0374\n",
      "Epoch 199/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0348\n",
      "Epoch 200/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0340\n",
      "Epoch 201/600\n",
      "60/60 [==============================] - 0s 76us/step - loss: 0.0439\n",
      "Epoch 202/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0415\n",
      "Epoch 203/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0391\n",
      "Epoch 204/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0425\n",
      "Epoch 205/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0373\n",
      "Epoch 206/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0342\n",
      "Epoch 207/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0418\n",
      "Epoch 208/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0431\n",
      "Epoch 209/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0438\n",
      "Epoch 210/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0445\n",
      "Epoch 211/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0358\n",
      "Epoch 212/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0418\n",
      "Epoch 213/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0364\n",
      "Epoch 214/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0441\n",
      "Epoch 215/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0390\n",
      "Epoch 216/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0491\n",
      "Epoch 217/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0384\n",
      "Epoch 218/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0317\n",
      "Epoch 219/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0313\n",
      "Epoch 220/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0384\n",
      "Epoch 221/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0421\n",
      "Epoch 222/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0381\n",
      "Epoch 223/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0509\n",
      "Epoch 224/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0411\n",
      "Epoch 225/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0349\n",
      "Epoch 226/600\n",
      "60/60 [==============================] - 0s 79us/step - loss: 0.0390\n",
      "Epoch 227/600\n",
      "60/60 [==============================] - 0s 82us/step - loss: 0.0354\n",
      "Epoch 228/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0396\n",
      "Epoch 229/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0372\n",
      "Epoch 230/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0349\n",
      "Epoch 231/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0437\n",
      "Epoch 232/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0453\n",
      "Epoch 233/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0493\n",
      "Epoch 234/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0358\n",
      "Epoch 235/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0311\n",
      "Epoch 236/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0416\n",
      "Epoch 237/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0342\n",
      "Epoch 238/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0315\n",
      "Epoch 239/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0386\n",
      "Epoch 240/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0457\n",
      "Epoch 241/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0420\n",
      "Epoch 242/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0455\n",
      "Epoch 243/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0410\n",
      "Epoch 244/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0353\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00244: early stopping\n",
      "best epoch =  164\n",
      "smallest loss = 0.03110383525490761\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 80, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(xarray,yarray,epochs=600,callbacks=[es])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916bfb33-45ee-4055-b197-ab6d420a17de",
   "metadata": {},
   "source": [
    "### Modification three\n",
    "baseline neural network with number of neurons changed to 8,16,8,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf571301-2a27-43a7-bfe1-08a055e9f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "\n",
    "#As seen below, we have created four dense layers. \n",
    "#A dense layer is a layer in neural network that’s fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 1 in our case. \n",
    "#The activation function we have chosen is elu, which stands for exponential linear unit. .\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 1.2\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(8, activation=K.elu, input_shape=[3],  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(16, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(8, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(2,  kernel_initializer=initializer)\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13a2d73c-b37c-444c-b2a0-ec7d42e99b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean squared error. After the compilation of the model, we’ll use the fit method with ~500 epochs.\n",
    "#Number of epochs can be varied.\n",
    "\n",
    "#from tf.keras import optimizers\n",
    "rms = keras.optimizers.RMSprop(0.001)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efc9b9f1-659c-49c5-abbb-3ed744abc322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "60/60 [==============================] - 0s 145us/step - loss: 0.0554\n",
      "Epoch 2/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0566\n",
      "Epoch 3/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0631\n",
      "Epoch 4/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0589\n",
      "Epoch 5/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0561\n",
      "Epoch 6/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0560\n",
      "Epoch 7/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0538\n",
      "Epoch 8/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0537\n",
      "Epoch 9/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0555\n",
      "Epoch 10/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0569\n",
      "Epoch 11/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0582\n",
      "Epoch 12/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0589\n",
      "Epoch 13/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0550\n",
      "Epoch 14/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0541\n",
      "Epoch 15/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0541\n",
      "Epoch 16/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0565\n",
      "Epoch 17/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0547\n",
      "Epoch 18/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0591\n",
      "Epoch 19/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0611\n",
      "Epoch 20/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0535\n",
      "Epoch 21/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0552\n",
      "Epoch 22/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0537\n",
      "Epoch 23/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0548\n",
      "Epoch 24/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0591\n",
      "Epoch 25/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0561\n",
      "Epoch 26/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0623\n",
      "Epoch 27/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0568\n",
      "Epoch 28/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0528\n",
      "Epoch 29/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0530\n",
      "Epoch 30/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0530\n",
      "Epoch 31/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0535\n",
      "Epoch 32/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0549\n",
      "Epoch 33/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0554\n",
      "Epoch 34/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0533\n",
      "Epoch 35/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0593\n",
      "Epoch 36/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0589\n",
      "Epoch 37/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0527\n",
      "Epoch 38/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0535\n",
      "Epoch 39/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0595\n",
      "Epoch 40/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0592\n",
      "Epoch 41/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0523\n",
      "Epoch 42/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0546\n",
      "Epoch 43/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0537\n",
      "Epoch 44/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0569\n",
      "Epoch 45/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0610\n",
      "Epoch 46/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0539\n",
      "Epoch 47/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0595\n",
      "Epoch 48/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0545\n",
      "Epoch 49/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0560\n",
      "Epoch 50/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0544\n",
      "Epoch 51/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0536\n",
      "Epoch 52/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0552\n",
      "Epoch 53/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0538\n",
      "Epoch 54/600\n",
      "60/60 [==============================] - 0s 84us/step - loss: 0.0578\n",
      "Epoch 55/600\n",
      "60/60 [==============================] - 0s 79us/step - loss: 0.0592\n",
      "Epoch 56/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0537\n",
      "Epoch 57/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0544\n",
      "Epoch 58/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0575\n",
      "Epoch 59/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0564\n",
      "Epoch 60/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0535\n",
      "Epoch 61/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0525\n",
      "Epoch 62/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0585\n",
      "Epoch 63/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0539\n",
      "Epoch 64/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0516\n",
      "Epoch 65/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0553\n",
      "Epoch 66/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0539\n",
      "Epoch 67/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0543\n",
      "Epoch 68/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0543\n",
      "Epoch 69/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0548\n",
      "Epoch 70/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0520\n",
      "Epoch 71/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0594\n",
      "Epoch 72/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0583\n",
      "Epoch 73/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0630\n",
      "Epoch 74/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0519\n",
      "Epoch 75/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0515\n",
      "Epoch 76/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0521\n",
      "Epoch 77/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0517\n",
      "Epoch 78/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0548\n",
      "Epoch 79/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0578\n",
      "Epoch 80/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0531\n",
      "Epoch 81/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0507\n",
      "Epoch 82/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0516\n",
      "Epoch 83/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0512\n",
      "Epoch 84/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0548\n",
      "Epoch 85/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0550\n",
      "Epoch 86/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0576\n",
      "Epoch 87/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0596\n",
      "Epoch 88/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0538\n",
      "Epoch 89/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0514\n",
      "Epoch 90/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0522\n",
      "Epoch 91/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0537\n",
      "Epoch 92/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0574\n",
      "Epoch 93/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0527\n",
      "Epoch 94/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0509\n",
      "Epoch 95/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0577\n",
      "Epoch 96/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0537\n",
      "Epoch 97/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0588\n",
      "Epoch 98/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0515\n",
      "Epoch 99/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0513\n",
      "Epoch 100/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0521\n",
      "Epoch 101/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0570\n",
      "Epoch 102/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0619\n",
      "Epoch 103/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0553\n",
      "Epoch 104/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0506\n",
      "Epoch 105/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0512\n",
      "Epoch 106/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0523\n",
      "Epoch 107/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0526\n",
      "Epoch 108/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0515\n",
      "Epoch 109/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0515\n",
      "Epoch 110/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0505\n",
      "Epoch 111/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0521\n",
      "Epoch 112/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0601\n",
      "Epoch 113/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0576\n",
      "Epoch 114/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0585\n",
      "Epoch 115/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0539\n",
      "Epoch 116/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0515\n",
      "Epoch 117/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0504\n",
      "Epoch 118/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0496\n",
      "Epoch 119/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0499\n",
      "Epoch 120/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0513\n",
      "Epoch 121/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0656\n",
      "Epoch 122/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0538\n",
      "Epoch 123/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0510\n",
      "Epoch 124/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0506\n",
      "Epoch 125/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0525\n",
      "Epoch 126/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0584\n",
      "Epoch 127/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0553\n",
      "Epoch 128/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0539\n",
      "Epoch 129/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0506\n",
      "Epoch 130/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0497\n",
      "Epoch 131/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0540\n",
      "Epoch 132/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0585\n",
      "Epoch 133/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0537\n",
      "Epoch 134/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0497\n",
      "Epoch 135/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0506\n",
      "Epoch 136/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0510\n",
      "Epoch 137/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0542\n",
      "Epoch 138/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0535\n",
      "Epoch 139/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0561\n",
      "Epoch 140/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0571\n",
      "Epoch 141/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0543\n",
      "Epoch 142/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0572\n",
      "Epoch 143/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0524\n",
      "Epoch 144/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0532\n",
      "Epoch 145/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0525\n",
      "Epoch 146/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0512\n",
      "Epoch 147/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0514\n",
      "Epoch 148/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0576\n",
      "Epoch 149/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0507\n",
      "Epoch 150/600\n",
      "60/60 [==============================] - 0s 78us/step - loss: 0.0508\n",
      "Epoch 151/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0488\n",
      "Epoch 152/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0507\n",
      "Epoch 153/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0533\n",
      "Epoch 154/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0540\n",
      "Epoch 155/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0584\n",
      "Epoch 156/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0535\n",
      "Epoch 157/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0518\n",
      "Epoch 158/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0536\n",
      "Epoch 159/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0505\n",
      "Epoch 160/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0482\n",
      "Epoch 161/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0533\n",
      "Epoch 162/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0567\n",
      "Epoch 163/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0519\n",
      "Epoch 164/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0564\n",
      "Epoch 165/600\n",
      "60/60 [==============================] - 0s 80us/step - loss: 0.0503\n",
      "Epoch 166/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0498\n",
      "Epoch 167/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0550\n",
      "Epoch 168/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0496\n",
      "Epoch 169/600\n",
      "60/60 [==============================] - 0s 79us/step - loss: 0.0476\n",
      "Epoch 170/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0500\n",
      "Epoch 171/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0484\n",
      "Epoch 172/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0582\n",
      "Epoch 173/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0584\n",
      "Epoch 174/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0526\n",
      "Epoch 175/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0519\n",
      "Epoch 176/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0503\n",
      "Epoch 177/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0487\n",
      "Epoch 178/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0501\n",
      "Epoch 179/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0499\n",
      "Epoch 180/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0510\n",
      "Epoch 181/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0527\n",
      "Epoch 182/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0560\n",
      "Epoch 183/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0532\n",
      "Epoch 184/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0549\n",
      "Epoch 185/600\n",
      "60/60 [==============================] - 0s 94us/step - loss: 0.0525\n",
      "Epoch 186/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0526\n",
      "Epoch 187/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0524\n",
      "Epoch 188/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0504\n",
      "Epoch 189/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0512\n",
      "Epoch 190/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0485\n",
      "Epoch 191/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0525\n",
      "Epoch 192/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0533\n",
      "Epoch 193/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0536\n",
      "Epoch 194/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0558\n",
      "Epoch 195/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0482\n",
      "Epoch 196/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0520\n",
      "Epoch 197/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0503\n",
      "Epoch 198/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0502\n",
      "Epoch 199/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0520\n",
      "Epoch 200/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0538\n",
      "Epoch 201/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0520\n",
      "Epoch 202/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0496\n",
      "Epoch 203/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0510\n",
      "Epoch 204/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0513\n",
      "Epoch 205/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0547\n",
      "Epoch 206/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0536\n",
      "Epoch 207/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0500\n",
      "Epoch 208/600\n",
      "60/60 [==============================] - 0s 81us/step - loss: 0.0495\n",
      "Epoch 209/600\n",
      "60/60 [==============================] - 0s 76us/step - loss: 0.0465\n",
      "Epoch 210/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0470\n",
      "Epoch 211/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0479\n",
      "Epoch 212/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0474\n",
      "Epoch 213/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0481\n",
      "Epoch 214/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0501\n",
      "Epoch 215/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0562\n",
      "Epoch 216/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0558\n",
      "Epoch 217/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0512\n",
      "Epoch 218/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0514\n",
      "Epoch 219/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0528\n",
      "Epoch 220/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0486\n",
      "Epoch 221/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0516\n",
      "Epoch 222/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0536\n",
      "Epoch 223/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0497\n",
      "Epoch 224/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0501\n",
      "Epoch 225/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0478\n",
      "Epoch 226/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0468\n",
      "Epoch 227/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0464\n",
      "Epoch 228/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0521\n",
      "Epoch 229/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0601\n",
      "Epoch 230/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0520\n",
      "Epoch 231/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0528\n",
      "Epoch 232/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0488\n",
      "Epoch 233/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0526\n",
      "Epoch 234/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0519\n",
      "Epoch 235/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0461\n",
      "Epoch 236/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0472\n",
      "Epoch 237/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0457\n",
      "Epoch 238/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0471\n",
      "Epoch 239/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0547\n",
      "Epoch 240/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0560\n",
      "Epoch 241/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0468\n",
      "Epoch 242/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0492\n",
      "Epoch 243/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0471\n",
      "Epoch 244/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0471\n",
      "Epoch 245/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0535\n",
      "Epoch 246/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0532\n",
      "Epoch 247/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0540\n",
      "Epoch 248/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0459\n",
      "Epoch 249/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0471\n",
      "Epoch 250/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0485\n",
      "Epoch 251/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0473\n",
      "Epoch 252/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0448\n",
      "Epoch 253/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0459\n",
      "Epoch 254/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0519\n",
      "Epoch 255/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0598\n",
      "Epoch 256/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0559\n",
      "Epoch 257/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0489\n",
      "Epoch 258/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0494\n",
      "Epoch 259/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0508\n",
      "Epoch 260/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0548\n",
      "Epoch 261/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0529\n",
      "Epoch 262/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0468\n",
      "Epoch 263/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0473\n",
      "Epoch 264/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0485\n",
      "Epoch 265/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0508\n",
      "Epoch 266/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0555\n",
      "Epoch 267/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0468\n",
      "Epoch 268/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0533\n",
      "Epoch 269/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0480\n",
      "Epoch 270/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0494\n",
      "Epoch 271/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0541\n",
      "Epoch 272/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0531\n",
      "Epoch 273/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0487\n",
      "Epoch 274/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0467\n",
      "Epoch 275/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0496\n",
      "Epoch 276/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0491\n",
      "Epoch 277/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0544\n",
      "Epoch 278/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0530\n",
      "Epoch 279/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0453\n",
      "Epoch 280/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0451\n",
      "Epoch 281/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0476\n",
      "Epoch 282/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0510\n",
      "Epoch 283/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0570\n",
      "Epoch 284/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0548\n",
      "Epoch 285/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0482\n",
      "Epoch 286/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0450\n",
      "Epoch 287/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0499\n",
      "Epoch 288/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0515\n",
      "Epoch 289/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0525\n",
      "Epoch 290/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0467\n",
      "Epoch 291/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0479\n",
      "Epoch 292/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0506\n",
      "Epoch 293/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0515\n",
      "Epoch 294/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0530\n",
      "Epoch 295/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0461\n",
      "Epoch 296/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0453\n",
      "Epoch 297/600\n",
      "60/60 [==============================] - 0s 76us/step - loss: 0.0482\n",
      "Epoch 298/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0473\n",
      "Epoch 299/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0465\n",
      "Epoch 300/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0538\n",
      "Epoch 301/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0524\n",
      "Epoch 302/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0520\n",
      "Epoch 303/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0460\n",
      "Epoch 304/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0463\n",
      "Epoch 305/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0446\n",
      "Epoch 306/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0494\n",
      "Epoch 307/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0492\n",
      "Epoch 308/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0556\n",
      "Epoch 309/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0493\n",
      "Epoch 310/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0485\n",
      "Epoch 311/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0480\n",
      "Epoch 312/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0461\n",
      "Epoch 313/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0452\n",
      "Epoch 314/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0482\n",
      "Epoch 315/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0553\n",
      "Epoch 316/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0496\n",
      "Epoch 317/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0475\n",
      "Epoch 318/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0488\n",
      "Epoch 319/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0443\n",
      "Epoch 320/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0466\n",
      "Epoch 321/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0496\n",
      "Epoch 322/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0441\n",
      "Epoch 323/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0485\n",
      "Epoch 324/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0504\n",
      "Epoch 325/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0510\n",
      "Epoch 326/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0498\n",
      "Epoch 327/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0486\n",
      "Epoch 328/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0500\n",
      "Epoch 329/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0494\n",
      "Epoch 330/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0488\n",
      "Epoch 331/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0494\n",
      "Epoch 332/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0536\n",
      "Epoch 333/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0449\n",
      "Epoch 334/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0447\n",
      "Epoch 335/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0513\n",
      "Epoch 336/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0521\n",
      "Epoch 337/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0473\n",
      "Epoch 338/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0505\n",
      "Epoch 339/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0436\n",
      "Epoch 340/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0451\n",
      "Epoch 341/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0492\n",
      "Epoch 342/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0500\n",
      "Epoch 343/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0460\n",
      "Epoch 344/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0471\n",
      "Epoch 345/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0451\n",
      "Epoch 346/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0432\n",
      "Epoch 347/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0491\n",
      "Epoch 348/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0495\n",
      "Epoch 349/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0489\n",
      "Epoch 350/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0504\n",
      "Epoch 351/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0468\n",
      "Epoch 352/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0449\n",
      "Epoch 353/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0437\n",
      "Epoch 354/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0454\n",
      "Epoch 355/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0488\n",
      "Epoch 356/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0517\n",
      "Epoch 357/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0514\n",
      "Epoch 358/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0441\n",
      "Epoch 359/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0446\n",
      "Epoch 360/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0439\n",
      "Epoch 361/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0515\n",
      "Epoch 362/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0511\n",
      "Epoch 363/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0464\n",
      "Epoch 364/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0479\n",
      "Epoch 365/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0485\n",
      "Epoch 366/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0504\n",
      "Epoch 367/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0474\n",
      "Epoch 368/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0469\n",
      "Epoch 369/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0498\n",
      "Epoch 370/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0452\n",
      "Epoch 371/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0436\n",
      "Epoch 372/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0433\n",
      "Epoch 373/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0520\n",
      "Epoch 374/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0505\n",
      "Epoch 375/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0508\n",
      "Epoch 376/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0449\n",
      "Epoch 377/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0431\n",
      "Epoch 378/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0468\n",
      "Epoch 379/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0515\n",
      "Epoch 380/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0500\n",
      "Epoch 381/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0499\n",
      "Epoch 382/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0466\n",
      "Epoch 383/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0428\n",
      "Epoch 384/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0472\n",
      "Epoch 385/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0460\n",
      "Epoch 386/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0485\n",
      "Epoch 387/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0500\n",
      "Epoch 388/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0529\n",
      "Epoch 389/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0484\n",
      "Epoch 390/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0504\n",
      "Epoch 391/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0415\n",
      "Epoch 392/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0485\n",
      "Epoch 393/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0491\n",
      "Epoch 394/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0492\n",
      "Epoch 395/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0484\n",
      "Epoch 396/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0482\n",
      "Epoch 397/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0444\n",
      "Epoch 398/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0412\n",
      "Epoch 399/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0416\n",
      "Epoch 400/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0490\n",
      "Epoch 401/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0513\n",
      "Epoch 402/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0513\n",
      "Epoch 403/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0494\n",
      "Epoch 404/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0483\n",
      "Epoch 405/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0454\n",
      "Epoch 406/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0463\n",
      "Epoch 407/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0472\n",
      "Epoch 408/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0543\n",
      "Epoch 409/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0466\n",
      "Epoch 410/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0455\n",
      "Epoch 411/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0432\n",
      "Epoch 412/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0432\n",
      "Epoch 413/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0518\n",
      "Epoch 414/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0460\n",
      "Epoch 415/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0445\n",
      "Epoch 416/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0443\n",
      "Epoch 417/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0471\n",
      "Epoch 418/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0486\n",
      "Epoch 419/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0467\n",
      "Epoch 420/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0472\n",
      "Epoch 421/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0476\n",
      "Epoch 422/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0489\n",
      "Epoch 423/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0487\n",
      "Epoch 424/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0462\n",
      "Epoch 425/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0443\n",
      "Epoch 426/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0468\n",
      "Epoch 427/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0508\n",
      "Epoch 428/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0469\n",
      "Epoch 429/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0520\n",
      "Epoch 430/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0445\n",
      "Epoch 431/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0477\n",
      "Epoch 432/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0509\n",
      "Epoch 433/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0454\n",
      "Epoch 434/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0471\n",
      "Epoch 435/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0439\n",
      "Epoch 436/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0430\n",
      "Epoch 437/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0415\n",
      "Epoch 438/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0435\n",
      "Epoch 439/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0507\n",
      "Epoch 440/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0515\n",
      "Epoch 441/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0520\n",
      "Epoch 442/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0476\n",
      "Epoch 443/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0490\n",
      "Epoch 444/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0483\n",
      "Epoch 445/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0452\n",
      "Epoch 446/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0452\n",
      "Epoch 447/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0483\n",
      "Epoch 448/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0477\n",
      "Epoch 449/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0469\n",
      "Epoch 450/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0486\n",
      "Epoch 451/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0445\n",
      "Epoch 452/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0511\n",
      "Epoch 453/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0453\n",
      "Epoch 454/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0425\n",
      "Epoch 455/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0460\n",
      "Epoch 456/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0505\n",
      "Epoch 457/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0449\n",
      "Epoch 458/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0431\n",
      "Epoch 459/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0500\n",
      "Epoch 460/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0478\n",
      "Epoch 461/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0466\n",
      "Epoch 462/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0481\n",
      "Epoch 463/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0443\n",
      "Epoch 464/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0478\n",
      "Epoch 465/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0449\n",
      "Epoch 466/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0459\n",
      "Epoch 467/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0446\n",
      "Epoch 468/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0498\n",
      "Epoch 469/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0481\n",
      "Epoch 470/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0458\n",
      "Epoch 471/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0438\n",
      "Epoch 472/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0476\n",
      "Epoch 473/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0411\n",
      "Epoch 474/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0401\n",
      "Epoch 475/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0460\n",
      "Epoch 476/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0505\n",
      "Epoch 477/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0468\n",
      "Epoch 478/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0475\n",
      "Epoch 479/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0456\n",
      "Epoch 480/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0434\n",
      "Epoch 481/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0479\n",
      "Epoch 482/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0484\n",
      "Epoch 483/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0433\n",
      "Epoch 484/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0413\n",
      "Epoch 485/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0422\n",
      "Epoch 486/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0416\n",
      "Epoch 487/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0497\n",
      "Epoch 488/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0534\n",
      "Epoch 489/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0478\n",
      "Epoch 490/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0471\n",
      "Epoch 491/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0495\n",
      "Epoch 492/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0449\n",
      "Epoch 493/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0452\n",
      "Epoch 494/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0453\n",
      "Epoch 495/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0426\n",
      "Epoch 496/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0463\n",
      "Epoch 497/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0488\n",
      "Epoch 498/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0435\n",
      "Epoch 499/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0443\n",
      "Epoch 500/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0479\n",
      "Epoch 501/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0431\n",
      "Epoch 502/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0459\n",
      "Epoch 503/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0448\n",
      "Epoch 504/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0468\n",
      "Epoch 505/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0421\n",
      "Epoch 506/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0440\n",
      "Epoch 507/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0469\n",
      "Epoch 508/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0447\n",
      "Epoch 509/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0433\n",
      "Epoch 510/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0460\n",
      "Epoch 511/600\n",
      "60/60 [==============================] - 0s 54us/step - loss: 0.0458\n",
      "Epoch 512/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0442\n",
      "Epoch 513/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0484\n",
      "Epoch 514/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0459\n",
      "Epoch 515/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0478\n",
      "Epoch 516/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0450\n",
      "Epoch 517/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0453\n",
      "Epoch 518/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0504\n",
      "Epoch 519/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0476\n",
      "Epoch 520/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0445\n",
      "Epoch 521/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0448\n",
      "Epoch 522/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0426\n",
      "Epoch 523/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0476\n",
      "Epoch 524/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0506\n",
      "Epoch 525/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0435\n",
      "Epoch 526/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0458\n",
      "Epoch 527/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0413\n",
      "Epoch 528/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0475\n",
      "Epoch 529/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0450\n",
      "Epoch 530/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0464\n",
      "Epoch 531/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0425\n",
      "Epoch 532/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0456\n",
      "Epoch 533/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0469\n",
      "Epoch 534/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0473\n",
      "Epoch 535/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0487\n",
      "Epoch 536/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0450\n",
      "Epoch 537/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0398\n",
      "Epoch 538/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0407\n",
      "Epoch 539/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0491\n",
      "Epoch 540/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0451\n",
      "Epoch 541/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0468\n",
      "Epoch 542/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0442\n",
      "Epoch 543/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0424\n",
      "Epoch 544/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0441\n",
      "Epoch 545/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0500\n",
      "Epoch 546/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0446\n",
      "Epoch 547/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0430\n",
      "Epoch 548/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0485\n",
      "Epoch 549/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0462\n",
      "Epoch 550/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0435\n",
      "Epoch 551/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0430\n",
      "Epoch 552/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0486\n",
      "Epoch 553/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0423\n",
      "Epoch 554/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0447\n",
      "Epoch 555/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0444\n",
      "Epoch 556/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0502\n",
      "Epoch 557/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0489\n",
      "Epoch 558/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0461\n",
      "Epoch 559/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0446\n",
      "Epoch 560/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0441\n",
      "Epoch 561/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0421\n",
      "Epoch 562/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0454\n",
      "Epoch 563/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0459\n",
      "Epoch 564/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0454\n",
      "Epoch 565/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0452\n",
      "Epoch 566/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0457\n",
      "Epoch 567/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0425\n",
      "Epoch 568/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0448\n",
      "Epoch 569/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0441\n",
      "Epoch 570/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0437\n",
      "Epoch 571/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0432\n",
      "Epoch 572/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0485\n",
      "Epoch 573/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0445\n",
      "Epoch 574/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0475\n",
      "Epoch 575/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0489\n",
      "Epoch 576/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0437\n",
      "Epoch 577/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0454\n",
      "Epoch 578/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0433\n",
      "Epoch 579/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0493\n",
      "Epoch 580/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0452\n",
      "Epoch 581/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0443\n",
      "Epoch 582/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0443\n",
      "Epoch 583/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0468\n",
      "Epoch 584/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0432\n",
      "Epoch 585/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0416\n",
      "Epoch 586/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0497\n",
      "Epoch 587/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0444\n",
      "Epoch 588/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0426\n",
      "Epoch 589/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0496\n",
      "Epoch 590/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0452\n",
      "Epoch 591/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0438\n",
      "Epoch 592/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0453\n",
      "Epoch 593/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0413\n",
      "Epoch 594/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0444\n",
      "Epoch 595/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0451\n",
      "Epoch 596/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0464\n",
      "Epoch 597/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0446\n",
      "Epoch 598/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0461\n",
      "Epoch 599/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0438\n",
      "Epoch 600/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0458\n",
      "best epoch =  537\n",
      "smallest loss = 0.0398373082280159\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 80, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(xarray,yarray,epochs=600,callbacks=[es])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1915c-da49-48c6-9054-469956e1bee4",
   "metadata": {},
   "source": [
    "### Modification four\n",
    "baseline neural network with number of neurons changed to 20,40,20,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5b6c8a7-50d1-44ca-8206-23007065f6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "\n",
    "#As seen below, we have created four dense layers. \n",
    "#A dense layer is a layer in neural network that’s fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 1 in our case. \n",
    "#The activation function we have chosen is elu, which stands for exponential linear unit. .\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 1.2\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(20, activation=K.elu, input_shape=[3],  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(40, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(20, activation=K.elu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(2,  kernel_initializer=initializer)\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c4aa007-2f9d-4439-a034-ddee645242ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean squared error. After the compilation of the model, we’ll use the fit method with ~500 epochs.\n",
    "#Number of epochs can be varied.\n",
    "\n",
    "#from tf.keras import optimizers\n",
    "rms = keras.optimizers.RMSprop(0.001)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f195dc6e-26df-4601-ae3a-ba98e45db28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 20.6707\n",
      "Epoch 2/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 17.5573\n",
      "Epoch 3/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 15.5973\n",
      "Epoch 4/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 14.0705\n",
      "Epoch 5/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 12.7999\n",
      "Epoch 6/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 11.6865\n",
      "Epoch 7/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 10.6863\n",
      "Epoch 8/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 9.7756\n",
      "Epoch 9/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 8.9406\n",
      "Epoch 10/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 8.1676\n",
      "Epoch 11/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 7.4427\n",
      "Epoch 12/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 6.7753\n",
      "Epoch 13/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 6.1618\n",
      "Epoch 14/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 5.5954\n",
      "Epoch 15/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 5.0669\n",
      "Epoch 16/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 4.5754\n",
      "Epoch 17/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 4.1143\n",
      "Epoch 18/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 3.6924\n",
      "Epoch 19/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 3.3146\n",
      "Epoch 20/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 2.9573\n",
      "Epoch 21/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 2.6344\n",
      "Epoch 22/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 2.3447\n",
      "Epoch 23/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 2.0722\n",
      "Epoch 24/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 1.8478\n",
      "Epoch 25/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 1.6483\n",
      "Epoch 26/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 1.4867\n",
      "Epoch 27/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 1.3482\n",
      "Epoch 28/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 1.2261\n",
      "Epoch 29/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 1.1078\n",
      "Epoch 30/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.9994\n",
      "Epoch 31/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.8921\n",
      "Epoch 32/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.8020\n",
      "Epoch 33/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.7563\n",
      "Epoch 34/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.7172\n",
      "Epoch 35/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.6775\n",
      "Epoch 36/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.6391\n",
      "Epoch 37/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.6048\n",
      "Epoch 38/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.5692\n",
      "Epoch 39/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.5262\n",
      "Epoch 40/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.4864\n",
      "Epoch 41/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.4482\n",
      "Epoch 42/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.4079\n",
      "Epoch 43/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.3668\n",
      "Epoch 44/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.3424\n",
      "Epoch 45/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.3180\n",
      "Epoch 46/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.2783\n",
      "Epoch 47/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.2610\n",
      "Epoch 48/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.2623\n",
      "Epoch 49/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.2262\n",
      "Epoch 50/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.2239\n",
      "Epoch 51/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.2235\n",
      "Epoch 52/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.1888\n",
      "Epoch 53/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.1779\n",
      "Epoch 54/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.1797\n",
      "Epoch 55/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.1853\n",
      "Epoch 56/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.1600\n",
      "Epoch 57/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.1506\n",
      "Epoch 58/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.1498\n",
      "Epoch 59/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.1469\n",
      "Epoch 60/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.1441\n",
      "Epoch 61/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.1364\n",
      "Epoch 62/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.1083\n",
      "Epoch 63/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.1116\n",
      "Epoch 64/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.1127\n",
      "Epoch 65/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.1003\n",
      "Epoch 66/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.1291\n",
      "Epoch 67/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.1147\n",
      "Epoch 68/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0944\n",
      "Epoch 69/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.1137\n",
      "Epoch 70/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0972\n",
      "Epoch 71/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0941\n",
      "Epoch 72/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0843\n",
      "Epoch 73/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0962\n",
      "Epoch 74/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.1229\n",
      "Epoch 75/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.1081\n",
      "Epoch 76/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.1109\n",
      "Epoch 77/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0862\n",
      "Epoch 78/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.1084\n",
      "Epoch 79/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0898\n",
      "Epoch 80/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0873\n",
      "Epoch 81/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.1090\n",
      "Epoch 82/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.1164\n",
      "Epoch 83/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0991\n",
      "Epoch 84/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.1050\n",
      "Epoch 85/600\n",
      "60/60 [==============================] - 0s 86us/step - loss: 0.0973\n",
      "Epoch 86/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0897\n",
      "Epoch 87/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0981\n",
      "Epoch 88/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0795\n",
      "Epoch 89/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0894\n",
      "Epoch 90/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0796\n",
      "Epoch 91/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0957\n",
      "Epoch 92/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.1082\n",
      "Epoch 93/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.1000\n",
      "Epoch 94/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0920\n",
      "Epoch 95/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.1000\n",
      "Epoch 96/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0947\n",
      "Epoch 97/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0975\n",
      "Epoch 98/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0960\n",
      "Epoch 99/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0949\n",
      "Epoch 100/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0948\n",
      "Epoch 101/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0841\n",
      "Epoch 102/600\n",
      "60/60 [==============================] - 0s 81us/step - loss: 0.0737\n",
      "Epoch 103/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0783\n",
      "Epoch 104/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.1053\n",
      "Epoch 105/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.1025\n",
      "Epoch 106/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0939\n",
      "Epoch 107/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0833\n",
      "Epoch 108/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.1028\n",
      "Epoch 109/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0882\n",
      "Epoch 110/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0728\n",
      "Epoch 111/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.1060\n",
      "Epoch 112/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0934\n",
      "Epoch 113/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0884\n",
      "Epoch 114/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0830\n",
      "Epoch 115/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.1117\n",
      "Epoch 116/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0772\n",
      "Epoch 117/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0818\n",
      "Epoch 118/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0889\n",
      "Epoch 119/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.1019\n",
      "Epoch 120/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0982\n",
      "Epoch 121/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0847\n",
      "Epoch 122/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0734\n",
      "Epoch 123/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0969\n",
      "Epoch 124/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0798\n",
      "Epoch 125/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0920\n",
      "Epoch 126/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0782\n",
      "Epoch 127/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0933\n",
      "Epoch 128/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0836\n",
      "Epoch 129/600\n",
      "60/60 [==============================] - 0s 82us/step - loss: 0.0964\n",
      "Epoch 130/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0881\n",
      "Epoch 131/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0946\n",
      "Epoch 132/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0905\n",
      "Epoch 133/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0898\n",
      "Epoch 134/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0718\n",
      "Epoch 135/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0684\n",
      "Epoch 136/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0877\n",
      "Epoch 137/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0901\n",
      "Epoch 138/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0851\n",
      "Epoch 139/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0681\n",
      "Epoch 140/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0738\n",
      "Epoch 141/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0878\n",
      "Epoch 142/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0896\n",
      "Epoch 143/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0940\n",
      "Epoch 144/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0878\n",
      "Epoch 145/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0879\n",
      "Epoch 146/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0993\n",
      "Epoch 147/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0682\n",
      "Epoch 148/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0841\n",
      "Epoch 149/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0962\n",
      "Epoch 150/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.1000\n",
      "Epoch 151/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0872\n",
      "Epoch 152/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0739\n",
      "Epoch 153/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0897\n",
      "Epoch 154/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0830\n",
      "Epoch 155/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0831\n",
      "Epoch 156/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0926\n",
      "Epoch 157/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0725\n",
      "Epoch 158/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0757\n",
      "Epoch 159/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0789\n",
      "Epoch 160/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0884\n",
      "Epoch 161/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0977\n",
      "Epoch 162/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0824\n",
      "Epoch 163/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0748\n",
      "Epoch 164/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0950\n",
      "Epoch 165/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0827\n",
      "Epoch 166/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0687\n",
      "Epoch 167/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0739\n",
      "Epoch 168/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0853\n",
      "Epoch 169/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0797\n",
      "Epoch 170/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0931\n",
      "Epoch 171/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0729\n",
      "Epoch 172/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0754\n",
      "Epoch 173/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0901\n",
      "Epoch 174/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0973\n",
      "Epoch 175/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0731\n",
      "Epoch 176/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0824\n",
      "Epoch 177/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0647\n",
      "Epoch 178/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0813\n",
      "Epoch 179/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0900\n",
      "Epoch 180/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0792\n",
      "Epoch 181/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0754\n",
      "Epoch 182/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0745\n",
      "Epoch 183/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0775\n",
      "Epoch 184/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0824\n",
      "Epoch 185/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0809\n",
      "Epoch 186/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0916\n",
      "Epoch 187/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0990\n",
      "Epoch 188/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0803\n",
      "Epoch 189/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0749\n",
      "Epoch 190/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0687\n",
      "Epoch 191/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0795\n",
      "Epoch 192/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0894\n",
      "Epoch 193/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0789\n",
      "Epoch 194/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0931\n",
      "Epoch 195/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0734\n",
      "Epoch 196/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0632\n",
      "Epoch 197/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0726\n",
      "Epoch 198/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0720\n",
      "Epoch 199/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0782\n",
      "Epoch 200/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0881\n",
      "Epoch 201/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0848\n",
      "Epoch 202/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0736\n",
      "Epoch 203/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0721\n",
      "Epoch 204/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0645\n",
      "Epoch 205/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0799\n",
      "Epoch 206/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0618\n",
      "Epoch 207/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.1050\n",
      "Epoch 208/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0822\n",
      "Epoch 209/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0843\n",
      "Epoch 210/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0731\n",
      "Epoch 211/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0700\n",
      "Epoch 212/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0785\n",
      "Epoch 213/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0783\n",
      "Epoch 214/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0893\n",
      "Epoch 215/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0743\n",
      "Epoch 216/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0632\n",
      "Epoch 217/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0799\n",
      "Epoch 218/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0742\n",
      "Epoch 219/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0843\n",
      "Epoch 220/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0708\n",
      "Epoch 221/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0731\n",
      "Epoch 222/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0672\n",
      "Epoch 223/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0863\n",
      "Epoch 224/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0769\n",
      "Epoch 225/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0715\n",
      "Epoch 226/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0621\n",
      "Epoch 227/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0622\n",
      "Epoch 228/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0851\n",
      "Epoch 229/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0919\n",
      "Epoch 230/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0792\n",
      "Epoch 231/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0651\n",
      "Epoch 232/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0603\n",
      "Epoch 233/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0975\n",
      "Epoch 234/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0761\n",
      "Epoch 235/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0848\n",
      "Epoch 236/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0637\n",
      "Epoch 237/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0712\n",
      "Epoch 238/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0718\n",
      "Epoch 239/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0649\n",
      "Epoch 240/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0884\n",
      "Epoch 241/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0780\n",
      "Epoch 242/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0675\n",
      "Epoch 243/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0738\n",
      "Epoch 244/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0728\n",
      "Epoch 245/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0834\n",
      "Epoch 246/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0605\n",
      "Epoch 247/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0814\n",
      "Epoch 248/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0655\n",
      "Epoch 249/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0765\n",
      "Epoch 250/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0758\n",
      "Epoch 251/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0715\n",
      "Epoch 252/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0803\n",
      "Epoch 253/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0571\n",
      "Epoch 254/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0586\n",
      "Epoch 255/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0691\n",
      "Epoch 256/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0779\n",
      "Epoch 257/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0754\n",
      "Epoch 258/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0687\n",
      "Epoch 259/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0664\n",
      "Epoch 260/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0717\n",
      "Epoch 261/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0577\n",
      "Epoch 262/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0870\n",
      "Epoch 263/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0981\n",
      "Epoch 264/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0656\n",
      "Epoch 265/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0661\n",
      "Epoch 266/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0674\n",
      "Epoch 267/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0791\n",
      "Epoch 268/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0580\n",
      "Epoch 269/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0661\n",
      "Epoch 270/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0889\n",
      "Epoch 271/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0678\n",
      "Epoch 272/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0638\n",
      "Epoch 273/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0605\n",
      "Epoch 274/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0905\n",
      "Epoch 275/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0813\n",
      "Epoch 276/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0708\n",
      "Epoch 277/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0581\n",
      "Epoch 278/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0725\n",
      "Epoch 279/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0576\n",
      "Epoch 280/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0656\n",
      "Epoch 281/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0563\n",
      "Epoch 282/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0841\n",
      "Epoch 283/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0703\n",
      "Epoch 284/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0620\n",
      "Epoch 285/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0716\n",
      "Epoch 286/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0721\n",
      "Epoch 287/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0648\n",
      "Epoch 288/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0744\n",
      "Epoch 289/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0633\n",
      "Epoch 290/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0722\n",
      "Epoch 291/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0826\n",
      "Epoch 292/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0552\n",
      "Epoch 293/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0790\n",
      "Epoch 294/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0736\n",
      "Epoch 295/600\n",
      "60/60 [==============================] - 0s 76us/step - loss: 0.0526\n",
      "Epoch 296/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0514\n",
      "Epoch 297/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0611\n",
      "Epoch 298/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0725\n",
      "Epoch 299/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0611\n",
      "Epoch 300/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0769\n",
      "Epoch 301/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0876\n",
      "Epoch 302/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0553\n",
      "Epoch 303/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0800\n",
      "Epoch 304/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0566\n",
      "Epoch 305/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0750\n",
      "Epoch 306/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0796\n",
      "Epoch 307/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0633\n",
      "Epoch 308/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0533\n",
      "Epoch 309/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0806\n",
      "Epoch 310/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0689\n",
      "Epoch 311/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0689\n",
      "Epoch 312/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0699\n",
      "Epoch 313/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0647\n",
      "Epoch 314/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0627\n",
      "Epoch 315/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0653\n",
      "Epoch 316/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0668\n",
      "Epoch 317/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0793\n",
      "Epoch 318/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0740\n",
      "Epoch 319/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0766\n",
      "Epoch 320/600\n",
      "60/60 [==============================] - 0s 76us/step - loss: 0.0643\n",
      "Epoch 321/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0542\n",
      "Epoch 322/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0508\n",
      "Epoch 323/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0756\n",
      "Epoch 324/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0662\n",
      "Epoch 325/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0753\n",
      "Epoch 326/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0584\n",
      "Epoch 327/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0585\n",
      "Epoch 328/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0738\n",
      "Epoch 329/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0652\n",
      "Epoch 330/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0550\n",
      "Epoch 331/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0660\n",
      "Epoch 332/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0627\n",
      "Epoch 333/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0659\n",
      "Epoch 334/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0582\n",
      "Epoch 335/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0738\n",
      "Epoch 336/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0669\n",
      "Epoch 337/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0826\n",
      "Epoch 338/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0732\n",
      "Epoch 339/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0647\n",
      "Epoch 340/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0620\n",
      "Epoch 341/600\n",
      "60/60 [==============================] - 0s 77us/step - loss: 0.0616\n",
      "Epoch 342/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0756\n",
      "Epoch 343/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0547\n",
      "Epoch 344/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0503\n",
      "Epoch 345/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0708\n",
      "Epoch 346/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0590\n",
      "Epoch 347/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0714\n",
      "Epoch 348/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0499\n",
      "Epoch 349/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0558\n",
      "Epoch 350/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0801\n",
      "Epoch 351/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0610\n",
      "Epoch 352/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0597\n",
      "Epoch 353/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0659\n",
      "Epoch 354/600\n",
      "60/60 [==============================] - 0s 90us/step - loss: 0.0501\n",
      "Epoch 355/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0607\n",
      "Epoch 356/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0695\n",
      "Epoch 357/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0747\n",
      "Epoch 358/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0834\n",
      "Epoch 359/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0565\n",
      "Epoch 360/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0603\n",
      "Epoch 361/600\n",
      "60/60 [==============================] - 0s 76us/step - loss: 0.0627\n",
      "Epoch 362/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0555\n",
      "Epoch 363/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0615\n",
      "Epoch 364/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0577\n",
      "Epoch 365/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0546\n",
      "Epoch 366/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0728\n",
      "Epoch 367/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0799\n",
      "Epoch 368/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0583\n",
      "Epoch 369/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0491\n",
      "Epoch 370/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0511\n",
      "Epoch 371/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0662\n",
      "Epoch 372/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0650\n",
      "Epoch 373/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0639\n",
      "Epoch 374/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0593\n",
      "Epoch 375/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0635\n",
      "Epoch 376/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0727\n",
      "Epoch 377/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0546\n",
      "Epoch 378/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0741\n",
      "Epoch 379/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0615\n",
      "Epoch 380/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0581\n",
      "Epoch 381/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0602\n",
      "Epoch 382/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0657\n",
      "Epoch 383/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0652\n",
      "Epoch 384/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0543\n",
      "Epoch 385/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0624\n",
      "Epoch 386/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0731\n",
      "Epoch 387/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0560\n",
      "Epoch 388/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0637\n",
      "Epoch 389/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0587\n",
      "Epoch 390/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0623\n",
      "Epoch 391/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0498\n",
      "Epoch 392/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0622\n",
      "Epoch 393/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0493\n",
      "Epoch 394/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0552\n",
      "Epoch 395/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0590\n",
      "Epoch 396/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0597\n",
      "Epoch 397/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0751\n",
      "Epoch 398/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0529\n",
      "Epoch 399/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0505\n",
      "Epoch 400/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0645\n",
      "Epoch 401/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0640\n",
      "Epoch 402/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0647\n",
      "Epoch 403/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0728\n",
      "Epoch 404/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0455\n",
      "Epoch 405/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0572\n",
      "Epoch 406/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0599\n",
      "Epoch 407/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0553\n",
      "Epoch 408/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0489\n",
      "Epoch 409/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0710\n",
      "Epoch 410/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0589\n",
      "Epoch 411/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0628\n",
      "Epoch 412/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0771\n",
      "Epoch 413/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0557\n",
      "Epoch 414/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0694\n",
      "Epoch 415/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0524\n",
      "Epoch 416/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0586\n",
      "Epoch 417/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0581\n",
      "Epoch 418/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0503\n",
      "Epoch 419/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0649\n",
      "Epoch 420/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0463\n",
      "Epoch 421/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0588\n",
      "Epoch 422/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0488\n",
      "Epoch 423/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0416\n",
      "Epoch 424/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0675\n",
      "Epoch 425/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0693\n",
      "Epoch 426/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0514\n",
      "Epoch 427/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0576\n",
      "Epoch 428/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0571\n",
      "Epoch 429/600\n",
      "60/60 [==============================] - 0s 87us/step - loss: 0.0586\n",
      "Epoch 430/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0583\n",
      "Epoch 431/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0612\n",
      "Epoch 432/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0746\n",
      "Epoch 433/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0611\n",
      "Epoch 434/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0535\n",
      "Epoch 435/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0518\n",
      "Epoch 436/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0549\n",
      "Epoch 437/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0509\n",
      "Epoch 438/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0561\n",
      "Epoch 439/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0546\n",
      "Epoch 440/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0610\n",
      "Epoch 441/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0613\n",
      "Epoch 442/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0440\n",
      "Epoch 443/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0459\n",
      "Epoch 444/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0655\n",
      "Epoch 445/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0526\n",
      "Epoch 446/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0767\n",
      "Epoch 447/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0590\n",
      "Epoch 448/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0586\n",
      "Epoch 449/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0494\n",
      "Epoch 450/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0483\n",
      "Epoch 451/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0653\n",
      "Epoch 452/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0629\n",
      "Epoch 453/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0515\n",
      "Epoch 454/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0614\n",
      "Epoch 455/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0585\n",
      "Epoch 456/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0507\n",
      "Epoch 457/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0582\n",
      "Epoch 458/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0494\n",
      "Epoch 459/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0598\n",
      "Epoch 460/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0677\n",
      "Epoch 461/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0538\n",
      "Epoch 462/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0440\n",
      "Epoch 463/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0524\n",
      "Epoch 464/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0483\n",
      "Epoch 465/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0688\n",
      "Epoch 466/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0515\n",
      "Epoch 467/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0703\n",
      "Epoch 468/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0599\n",
      "Epoch 469/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0608\n",
      "Epoch 470/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0646\n",
      "Epoch 471/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0543\n",
      "Epoch 472/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0455\n",
      "Epoch 473/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0545\n",
      "Epoch 474/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0555\n",
      "Epoch 475/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0673\n",
      "Epoch 476/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0624\n",
      "Epoch 477/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0526\n",
      "Epoch 478/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0393\n",
      "Epoch 479/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0504\n",
      "Epoch 480/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0566\n",
      "Epoch 481/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0596\n",
      "Epoch 482/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0463\n",
      "Epoch 483/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0480\n",
      "Epoch 484/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0569\n",
      "Epoch 485/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0605\n",
      "Epoch 486/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0529\n",
      "Epoch 487/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0707\n",
      "Epoch 488/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0472\n",
      "Epoch 489/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0537\n",
      "Epoch 490/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0594\n",
      "Epoch 491/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0647\n",
      "Epoch 492/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0523\n",
      "Epoch 493/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0541\n",
      "Epoch 494/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0526\n",
      "Epoch 495/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0468\n",
      "Epoch 496/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0571\n",
      "Epoch 497/600\n",
      "60/60 [==============================] - 0s 54us/step - loss: 0.0543\n",
      "Epoch 498/600\n",
      "60/60 [==============================] - 0s 55us/step - loss: 0.0516\n",
      "Epoch 499/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0708\n",
      "Epoch 500/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0719\n",
      "Epoch 501/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0403\n",
      "Epoch 502/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0436\n",
      "Epoch 503/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0540\n",
      "Epoch 504/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0485\n",
      "Epoch 505/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0574\n",
      "Epoch 506/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0516\n",
      "Epoch 507/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0390\n",
      "Epoch 508/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0411\n",
      "Epoch 509/600\n",
      "60/60 [==============================] - 0s 58us/step - loss: 0.0526\n",
      "Epoch 510/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0608\n",
      "Epoch 511/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0625\n",
      "Epoch 512/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0653\n",
      "Epoch 513/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0550\n",
      "Epoch 514/600\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.0544\n",
      "Epoch 515/600\n",
      "60/60 [==============================] - 0s 74us/step - loss: 0.0573\n",
      "Epoch 516/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0497\n",
      "Epoch 517/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0643\n",
      "Epoch 518/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0515\n",
      "Epoch 519/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0529\n",
      "Epoch 520/600\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.0471\n",
      "Epoch 521/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0545\n",
      "Epoch 522/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0528\n",
      "Epoch 523/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0402\n",
      "Epoch 524/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0402\n",
      "Epoch 525/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0492\n",
      "Epoch 526/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0378\n",
      "Epoch 527/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0639\n",
      "Epoch 528/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0660\n",
      "Epoch 529/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0588\n",
      "Epoch 530/600\n",
      "60/60 [==============================] - 0s 56us/step - loss: 0.0558\n",
      "Epoch 531/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0467\n",
      "Epoch 532/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0415\n",
      "Epoch 533/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0556\n",
      "Epoch 534/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0585\n",
      "Epoch 535/600\n",
      "60/60 [==============================] - 0s 57us/step - loss: 0.0507\n",
      "Epoch 536/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0432\n",
      "Epoch 537/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0528\n",
      "Epoch 538/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0509\n",
      "Epoch 539/600\n",
      "60/60 [==============================] - 0s 82us/step - loss: 0.0443\n",
      "Epoch 540/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0424\n",
      "Epoch 541/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0574\n",
      "Epoch 542/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0760\n",
      "Epoch 543/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0560\n",
      "Epoch 544/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0511\n",
      "Epoch 545/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0506\n",
      "Epoch 546/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0495\n",
      "Epoch 547/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0575\n",
      "Epoch 548/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0616\n",
      "Epoch 549/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0469\n",
      "Epoch 550/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0445\n",
      "Epoch 551/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0519\n",
      "Epoch 552/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0428\n",
      "Epoch 553/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0469\n",
      "Epoch 554/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0620\n",
      "Epoch 555/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0514\n",
      "Epoch 556/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0487\n",
      "Epoch 557/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0556\n",
      "Epoch 558/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0422\n",
      "Epoch 559/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0460\n",
      "Epoch 560/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0585\n",
      "Epoch 561/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0762\n",
      "Epoch 562/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0522\n",
      "Epoch 563/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0535\n",
      "Epoch 564/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0451\n",
      "Epoch 565/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0479\n",
      "Epoch 566/600\n",
      "60/60 [==============================] - 0s 70us/step - loss: 0.0528\n",
      "Epoch 567/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0552\n",
      "Epoch 568/600\n",
      "60/60 [==============================] - 0s 65us/step - loss: 0.0455\n",
      "Epoch 569/600\n",
      "60/60 [==============================] - 0s 62us/step - loss: 0.0582\n",
      "Epoch 570/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0512\n",
      "Epoch 571/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0506\n",
      "Epoch 572/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0513\n",
      "Epoch 573/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0546\n",
      "Epoch 574/600\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.0583\n",
      "Epoch 575/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0488\n",
      "Epoch 576/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0580\n",
      "Epoch 577/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0585\n",
      "Epoch 578/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0427\n",
      "Epoch 579/600\n",
      "60/60 [==============================] - 0s 60us/step - loss: 0.0388\n",
      "Epoch 580/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0706\n",
      "Epoch 581/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0442\n",
      "Epoch 582/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0480\n",
      "Epoch 583/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0450\n",
      "Epoch 584/600\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.0524\n",
      "Epoch 585/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0471\n",
      "Epoch 586/600\n",
      "60/60 [==============================] - 0s 69us/step - loss: 0.0514\n",
      "Epoch 587/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0504\n",
      "Epoch 588/600\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.0410\n",
      "Epoch 589/600\n",
      "60/60 [==============================] - 0s 72us/step - loss: 0.0452\n",
      "Epoch 590/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0635\n",
      "Epoch 591/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0623\n",
      "Epoch 592/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0580\n",
      "Epoch 593/600\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.0517\n",
      "Epoch 594/600\n",
      "60/60 [==============================] - 0s 63us/step - loss: 0.0474\n",
      "Epoch 595/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0545\n",
      "Epoch 596/600\n",
      "60/60 [==============================] - 0s 59us/step - loss: 0.0551\n",
      "Epoch 597/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0516\n",
      "Epoch 598/600\n",
      "60/60 [==============================] - 0s 64us/step - loss: 0.0510\n",
      "Epoch 599/600\n",
      "60/60 [==============================] - 0s 68us/step - loss: 0.0590\n",
      "Epoch 600/600\n",
      "60/60 [==============================] - 0s 61us/step - loss: 0.0551\n",
      "best epoch =  526\n",
      "smallest loss = 0.03778704876701037\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 80, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(xarray,yarray,epochs=600,callbacks=[es])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c474e14-3bf8-4ad4-9d4a-82eeed3835c6",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- __Modification one:__<br>\n",
    "  best epoch =  190<br>\n",
    "  smallest loss = 0.03891446627676487<br>\n",
    "\n",
    "- __Modification two:__<br>\n",
    "  best epoch =  164<br>\n",
    "  smallest loss = 0.03110383525490761<br>\n",
    "\n",
    "- __Modification three:__<br>\n",
    "  best epoch =  537<br>\n",
    "  smallest loss = 0.0398373082280159<br>\n",
    "\n",
    "- __Modification four:__<br>\n",
    "  best epoch =  526<br>\n",
    "  smallest loss = 0.03778704876701037<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b2fce-89eb-41c1-972d-4695b4b31bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
