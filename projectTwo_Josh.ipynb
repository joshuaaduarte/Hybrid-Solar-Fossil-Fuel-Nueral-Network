{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7cd8036-5b18-46bd-a2aa-11693b7b5c70",
   "metadata": {},
   "source": [
    "# Project Two\n",
    "## Work Done by Joshua Duarte\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72595b5-cd1b-4d38-8ecc-b28245d3f40e",
   "metadata": {},
   "source": [
    "## Code P2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a1e6e22-9369-4fcf-99c5-576ebe93bf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9900990099009901, 0.896551724137931, 1.009090909090909, 0.9558641975308642], [0.9900990099009901, 1.0, 1.0, 0.9969135802469136], [0.9900990099009901, 1.0551724137931036, 0.9935064935064936, 0.9722222222222222], [1.0, 0.896551724137931, 1.009090909090909, 0.9540123456790124], [0.9900990099009901, 1.0, 1.0, 1.0030864197530864], [0.9900990099009901, 1.0551724137931036, 0.9935064935064936, 0.9691358024691358], [1.188118811881188, 0.896551724137931, 1.009090909090909, 1.098456790123457], [1.7821782178217822, 1.0, 1.0, 1.4320987654320987]]\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.23 0.4 0.7 0.72 0.7\n",
      "-0.15 -0.12 0.01\n",
      "E3 =  0.0023304004322608684 icount = 8 rms fractional error = 0.048274221197869865\n",
      "next ws: 1.2296434158887675 0.39957113223001967 0.699579524559478 0.7198734737335699 0.6998677891900275\n",
      "next bs: -0.15042093558581818 -0.12030307362178909 0.009787848464747631\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2296434158887675 0.39957113223001967 0.699579524559478 0.7198734737335699 0.6998677891900275\n",
      "-0.15042093558581818 -0.12030307362178909 0.009787848464747631\n",
      "E3 =  0.0021840849759191035 icount = 8 rms fractional error = 0.04673419493175317\n",
      "next ws: 1.2292964670859656 0.39915326838751664 0.6991697325786222 0.7197502260960085 0.6997389830406646\n",
      "next bs: -0.15083116577443514 -0.12059838745269916 0.009581167826791363\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2292964670859656 0.39915326838751664 0.6991697325786222 0.7197502260960085 0.6997389830406646\n",
      "-0.15083116577443514 -0.12059838745269916 0.009581167826791363\n",
      "E3 =  0.0020469858368763563 icount = 8 rms fractional error = 0.0452436275830791\n",
      "next ws: 1.2289587571591187 0.3987459330220186 0.6987701578062104 0.7196301217470222 0.6996134424991525\n",
      "next bs: -0.1512311573122343 -0.12088628145246659 0.00937971717217059\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2289587571591187 0.3987459330220186 0.6987701578062104 0.7196301217470222 0.6996134424991525\n",
      "-0.1512311573122343 -0.12088628145246659 0.00937971717217059\n",
      "E3 =  0.001918523317958733 icount = 8 rms fractional error = 0.04380095110792382\n",
      "next ws: 1.2286298945367442 0.3983486544742073 0.6983803373102373 0.7195130264113502 0.6994910294723081\n",
      "next bs: -0.151621373583563 -0.12116709283531053 0.00918325775392619\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2286298945367442 0.3983486544742073 0.6983803373102373 0.7195130264113502 0.6994910294723081\n",
      "-0.151621373583563 -0.12116709283531053 0.00918325775392619\n",
      "E3 =  0.0017981542579855589 icount = 8 rms fractional error = 0.04240464901382346\n",
      "next ws: 1.2283094914522146 0.3979609633695991 0.6979998099524185 0.7193988064959883 0.6993716064394926\n",
      "next bs: -0.15200227613306355 -0.12144115718146947 0.008991552202289818\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2283094914522146 0.3979609633695991 0.6979998099524185 0.7193988064959883 0.6993716064394926\n",
      "-0.15200227613306355 -0.12144115718146947 0.008991552202289818\n",
      "E3 =  0.001685369741179922 icount = 8 rms fractional error = 0.04105325494013748\n",
      "next ws: 1.2279971627592152 0.39758239090732356 0.6976281146513041 0.7192873286536903 0.6992550360093652\n",
      "next bs: -0.15237432639858192 -0.1217088096984399 0.00880436363152863\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2279971627592152 0.39758239090732356 0.6976281146513041 0.7192873286536903 0.6992550360093652\n",
      "-0.15237432639858192 -0.1217088096984399 0.00880436363152863\n",
      "E3 =  0.0015796929522765102 icount = 8 rms fractional error = 0.03974535132913672\n",
      "next ws: 1.2276925245874635 0.3972124668937366 0.6972647883820485 0.7191784592800671 0.6991411804073469\n",
      "next bs: -0.15273798770639666 -0.12197038666907267 0.008621454617509594\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2276925245874635 0.3972124668937366 0.6972647883820485 0.7191784592800671 0.6991411804073469\n",
      "-0.15273798770639666 -0.12197038666907267 0.008621454617509594\n",
      "E3 =  0.0014806771685807057 icount = 8 rms fractional error = 0.038479568196391\n",
      "next ws: 1.2273951927986773 0.39685071745632006 0.6969093638460495 0.7190720639280301 0.6990299008770173\n",
      "next bs: -0.15309372759527742 -0.1222262271342624 0.00844258601268088\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2273951927986773 0.39685071745632006 0.6969093638460495 0.7190720639280301 0.6990299008770173\n",
      "-0.15309372759527742 -0.1222262271342624 0.00844258601268088\n",
      "E3 =  0.0013879038809075546 icount = 8 rms fractional error = 0.03725458201225125\n",
      "next ws: 1.2271047811911944 0.3964966623541481 0.6965613667237365 0.7189680066185405 0.6989210569737357\n",
      "next bs: -0.15344202055572648 -0.12247667487218411 0.008267515555266593\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2271047811911944 0.3964966623541481 0.6965613667237365 0.7189680066185405 0.6989210569737357\n",
      "-0.15344202055572648 -0.12247667487218411 0.008267515555266593\n",
      "E3 =  0.0013009810360083622 icount = 8 rms fractional error = 0.036069114710626904\n",
      "next ws: 1.2268208993860124 0.3961498117751603 0.6962203123966728 0.718866149020155 0.6988145057220928\n",
      "next bs: -0.15378335129773843 -0.12272208075536607 0.008095996216005485\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2268208993860124 0.3961498117751603 0.6962203123966728 0.718866149020155 0.6988145057220928\n",
      "-0.15378335129773843 -0.12272208075536607 0.008095996216005485\n",
      "E3 =  0.0012195413937946703 icount = 8 rms fractional error = 0.03492193284734781\n",
      "next ws: 1.2265431503056543 0.3958096624746565 0.6958857019877949 0.7187663494609944 0.6987101005996597\n",
      "next bs: -0.15411821869757727 -0.12296280559352062 0.007927774207215486\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2265431503056543 0.3958096624746565 0.6958857019877949 0.7187663494609944 0.6987101005996597\n",
      "-0.15411821869757727 -0.12296280559352062 0.007927774207215486\n",
      "E3 =  0.0011432409934218496 icount = 8 rms fractional error = 0.03381184693893325\n",
      "next ws: 1.2262711271276836 0.39547569305945945 0.6955570175164394 0.7186684617244492 0.6986076902968047\n",
      "next bs: -0.15444714062597661 -0.12319922360725387 0.007762586553056353\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2262711271276836 0.39547569305945945 0.6955570175164394 0.7186684617244492 0.6986076902968047\n",
      "-0.15444714062597661 -0.12319922360725387 0.007762586553056353\n",
      "E3 =  0.0010717577231419684 icount = 8 rms fractional error = 0.03273771102477949\n",
      "next ws: 1.2260044095531155 0.39514735815142243 0.6952337158908171 0.7185723335625825 0.6985071171844649\n",
      "next bs: -0.15477065993378122 -0.12343172673053196 0.007600158083116251\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2260044095531155 0.39514735815142243 0.6952337158908171 0.7185723335625825 0.6985071171844649\n",
      "-0.15477065993378122 -0.12343172673053196 0.007600158083116251\n",
      "E3 =  0.0010047899898382065 icount = 8 rms fractional error = 0.03169842251340288\n",
      "next ws: 1.2257425591706148 0.3948240810620576 0.6949152213538627 0.7184778048363268 0.6984082153961486\n",
      "next bs: -0.15508935197720675 -0.12366073001586406 0.007440197658453154\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2257425591706148 0.3948240810620576 0.6949152213538627 0.7184778048363268 0.6984082153961486\n",
      "-0.15508935197720675 -0.12366073001586406 0.007440197658453154\n",
      "E3 =  0.0009420554854174719 icount = 8 rms fractional error = 0.030692922399430653\n",
      "next ws: 1.2254851136110987 0.3945052444606191 0.6946009158415857 0.7183847051553083 0.6983108083931158\n",
      "next bs: -0.155403834220835 -0.12388667852792609 0.007282393361372496\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2254851136110987 0.3945052444606191 0.6946009158415857 0.7183847051553083 0.6983108083931158\n",
      "-0.155403834220835 -0.12388667852792609 0.007282393361372496\n",
      "E3 =  0.0008832900489247679 icount = 8 rms fractional error = 0.029720195977226797\n",
      "next ws: 1.2252315790595383 0.3941901782943201 0.6942901264779038 0.7182928508361787 0.6982147058261713\n",
      "next bs: -0.1557147786902611 -0.12411005627891443 0.007126406263502796\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2252315790595383 0.3941901782943201 0.6942901264779038 0.7182928508361787 0.6982147058261713\n",
      "-0.1557147786902611 -0.12411005627891443 0.007126406263502796\n",
      "E3 =  0.0008282466256303556 icount = 8 rms fractional error = 0.028779274237380546\n",
      "next ws: 1.22498142049719 0.3938781438770067 0.693982109069215 0.718202040916281 0.6981196994231454\n",
      "next bs: -0.15602292840490228 -0.12433139801592841 0.006971862207706528\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.22498142049719 0.3938781438770067 0.693982109069215 0.718202040916281 0.6981196994231454\n",
      "-0.15602292840490228 -0.12433139801592841 0.006971862207706528\n",
      "E3 =  0.0007766943279005965 icount = 8 rms fractional error = 0.027869236227435378\n",
      "next ws: 1.2247340487472158 0.3935683125251145 0.6936760258942464 0.7181120518315681 0.6980255574997164\n",
      "next bs: -0.1563291194856929 -0.12455130507506258 0.006818340757682751\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2247340487472158 0.3935683125251145 0.6936760258942464 0.7181120518315681 0.6980255574997164\n",
      "-0.1563291194856929 -0.12455130507506258 0.006818340757682751\n",
      "E3 =  0.0007284176082338459 icount = 8 rms fractional error = 0.02698921281241537\n",
      "next ws: 1.2244888029179597 0.39325973625143096 0.6933709151651328 0.7180226301626892 0.6979320174807712\n",
      "next bs: -0.15663431154607013 -0.12477046717174278 0.006665360012964744\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2244888029179597 0.39325973625143096 0.6933709151651328 0.7180226301626892 0.6979320174807712\n",
      "-0.15663431154607013 -0.12477046717174278 0.006665360012964744\n",
      "E3 =  0.0006832155639682926 icount = 8 rms fractional error = 0.026138392528391882\n",
      "next ws: 1.2242449260510289 0.39295130657812766 0.6930656479963966 0.7179334825140589 0.6978387754716769\n",
      "next bs: -0.15693963050359014 -0.12498969309265984 0.0065123552236950235\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2242449260510289 0.39295130657812766 0.6930656479963966 0.7179334825140589 0.6978387754716769\n",
      "-0.15693963050359014 -0.12498969309265984 0.0065123552236950235\n",
      "E3 =  0.0006409014087981729 icount = 8 rms fractional error = 0.02531603066829737\n",
      "next ws: 1.2240015304403065 0.3926416950202824 0.6927588660428413 0.7178442610091103 0.6977454713228496\n",
      "next bs: -0.15724643060628968 -0.12520995515882657 0.0063586478131583595\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2240015304403065 0.3926416950202824 0.6927588660428413 0.7178442610091103 0.6977454713228496\n",
      "-0.15724643060628968 -0.12520995515882657 0.0063586478131583595\n",
      "E3 =  0.0006013021742781325 icount = 8 rms fractional error = 0.02452146354274419\n",
      "next ws: 1.223757546707513 0.3923292642497843 0.6924488881078442 0.7177545418446213 0.6976516665661795\n",
      "next bs: -0.157556387291277 -0.12543245578630613 0.006203399007968012\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.223757546707513 0.3923292642497843 0.6924488881078442 0.7177545418446213 0.6976516665661795\n",
      "-0.157556387291277 -0.12543245578630613 0.006203399007968012\n",
      "E3 =  0.0005642587574225193 icount = 8 rms fractional error = 0.023754131375879003\n",
      "next ws: 1.2235116462856206 0.39201193030345816 0.6921335647296882 0.7176637923921989 0.6975568106035738\n",
      "next bs: -0.15787164171358425 -0.12565873107975378 0.006045537672391513\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2235116462856206 0.39201193030345816 0.6921335647296882 0.7176637923921989 0.6975568106035738\n",
      "-0.15787164171358425 -0.12565873107975378 0.006045537672391513\n",
      "E3 =  0.0005296265362941086 icount = 8 rms fractional error = 0.023013616323692122\n",
      "next ws: 1.2232621182139656 0.39168693870255994 0.6918100408454192 0.7175713184394906 0.6974601865516628\n",
      "next bs: -0.15819503653242536 -0.12589081983188327 0.005883642582679103\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2232621182139656 0.39168693870255994 0.6918100408454192 0.7175713184394906 0.6974601865516628\n",
      "-0.15819503653242536 -0.12589081983188327 0.005883642582679103\n",
      "E3 =  0.0004972770016679842 icount = 8 rms fractional error = 0.02229970855567364\n",
      "next ws: 1.2230066626509053 0.3913504792089674 0.6914743451478547 0.71747617482628 0.6973608196517687\n",
      "next bs: -0.1585305236507243 -0.1261315557656805 0.005715738853383202\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2230066626509053 0.3913504792089674 0.6914743451478547 0.71747617482628 0.6973608196517687\n",
      "-0.1585305236507243 -0.1261315557656805 0.005715738853383202\n",
      "E3 =  0.00046710137759391895 icount = 8 rms fractional error = 0.021612528255479945\n",
      "next ws: 1.2227420208697226 0.39099697269610445 0.6911206247202265 0.7173770032291261 0.6972573113274504\n",
      "next bs: -0.15888392365226905 -0.12638511184697243 0.0055389187767057695\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2227420208697226 0.39099697269610445 0.6911206247202265 0.7173770032291261 0.6972573113274504\n",
      "-0.15888392365226905 -0.12638511184697243 0.0055389187767057695\n",
      "E3 =  0.00043901855157933847 icount = 8 rms fractional error = 0.020952769544366645\n",
      "next ws: 1.2224632517535439 0.39061761747808227 0.6907395709551339 0.7172717097263503 0.6971475101396006\n",
      "next bs: -0.1592644863081726 -0.12665811874460545 0.005348562721288328\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2224632517535439 0.39061761747808227 0.6907395709551339 0.7172717097263503 0.6971475101396006\n",
      "-0.1592644863081726 -0.12665811874460545 0.005348562721288328\n",
      "E3 =  0.000412993586190917 icount = 8 rms fractional error = 0.02032224363083262\n",
      "next ws: 1.2221621375889002 0.39019700149729497 0.6903147059918033 0.7171567386460879 0.6970277731622578\n",
      "next bs: -0.15968856761859146 -0.12696230027119257 0.005136503327397658\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2221621375889002 0.39019700149729497 0.6903147059918033 0.7171567386460879 0.6970277731622578\n",
      "-0.15968856761859146 -0.12696230027119257 0.005136503327397658\n",
      "E3 =  0.00038908694840807074 icount = 8 rms fractional error = 0.01972528702980189\n",
      "next ws: 1.2218230002379897 0.3897034509803377 0.6898116064575909 0.7170251059677899 0.696890975084889\n",
      "next bs: -0.16019028035095448 -0.12732210693807125 0.004885708087614283\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2218230002379897 0.3897034509803377 0.6898116064575909 0.7170251059677899 0.696890975084889\n",
      "-0.16019028035095448 -0.12732210693807125 0.004885708087614283\n",
      "E3 =  0.0003676179821777909 icount = 8 rms fractional error = 0.019173366480036595\n",
      "next ws: 1.2214080817125266 0.3890502373534693 0.6891331255452056 0.7168591593515998 0.696719237221325\n",
      "next bs: -0.1608656007822733 -0.12780632864189984 0.004548258352275913\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2214080817125266 0.3890502373534693 0.6891331255452056 0.7168591593515998 0.696719237221325\n",
      "-0.1608656007822733 -0.12780632864189984 0.004548258352275913\n",
      "E3 =  0.0003499794936508059 icount = 8 rms fractional error = 0.01870773887060662\n",
      "next ws: 1.2207649255815238 0.387741815062798 0.6876667588637975 0.7165786188771192 0.6964327735054727\n",
      "next bs: -0.16231342389870826 -0.12884421390403722 0.0038251437241163004\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2207649255815238 0.387741815062798 0.6876667588637975 0.7165786188771192 0.6964327735054727\n",
      "-0.16231342389870826 -0.12884421390403722 0.0038251437241163004\n",
      "E3 =  0.00035038728454023867 icount = 8 rms fractional error = 0.018718634686863213\n",
      "next ws: 1.2235301726306473 0.3888601164166848 0.6886465868562739 0.7171189227480413 0.6970410967564209\n",
      "next bs: -0.16132227915810934 -0.12813398077471153 0.0043197733522080594\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2235301726306473 0.3888601164166848 0.6886465868562739 0.7171189227480413 0.6970410967564209\n",
      "-0.16132227915810934 -0.12813398077471153 0.0043197733522080594\n",
      "E3 =  0.00036225435877188775 icount = 8 rms fractional error = 0.01903298081677927\n",
      "next ws: 1.223016269676443 0.38794627272056387 0.6876701279619271 0.7169045476416664 0.6968205685541922\n",
      "next bs: -0.16229136031051242 -0.12882892720677824 0.0038353671290133062\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.223016269676443 0.38794627272056387 0.6876701279619271 0.7169045476416664 0.6968205685541922\n",
      "-0.16229136031051242 -0.12882892720677824 0.0038353671290133062\n",
      "E3 =  0.0003502849771911097 icount = 8 rms fractional error = 0.01871590171995754\n",
      "next ws: 1.2215160969790517 0.4191348743429785 0.6950450855852889 0.7159223943277965 0.6958945362144514\n",
      "next bs: -0.1543217390769469 -0.12311546950145355 0.007816621975647989\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2215160969790517 0.4191348743429785 0.6950450855852889 0.7159223943277965 0.6958945362144514\n",
      "-0.1543217390769469 -0.12311546950145355 0.007816621975647989\n",
      "E3 =  0.001057499071304542 icount = 8 rms fractional error = 0.032519210803839356\n",
      "next ws: 1.2212491686920233 0.41881183750951423 0.6947264906288928 0.7158278349920845 0.6957955702842429\n",
      "next bs: -0.154640500519524 -0.12334367795664271 0.0076578129585639105\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2212491686920233 0.41881183750951423 0.6947264906288928 0.7158278349920845 0.6957955702842429\n",
      "-0.154640500519524 -0.12334367795664271 0.0076578129585639105\n",
      "E3 =  0.000991385383944392 icount = 8 rms fractional error = 0.03148627294464037\n",
      "next ws: 1.2209872673160744 0.4184942426128875 0.6944130729739746 0.7157349325162101 0.6956983328302869\n",
      "next bs: -0.15495406345692503 -0.12356813503525625 0.007501636717545663\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2209872673160744 0.4184942426128875 0.6944130729739746 0.7157349325162101 0.6956983328302869\n",
      "-0.15495406345692503 -0.12356813503525625 0.007501636717545663\n",
      "E3 =  0.0009294485735077919 icount = 8 rms fractional error = 0.030486859029880266\n",
      "next ws: 1.2207299519478851 0.41818152679651677 0.6941042678032672 0.7156435288253981 0.6956026598819596\n",
      "next bs: -0.1552629920339851 -0.12378924600951068 0.007347810181386383\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2207299519478851 0.41818152679651677 0.6941042678032672 0.7156435288253981 0.6956026598819596\n",
      "-0.1552629920339851 -0.12378924600951068 0.007347810181386383\n",
      "E3 =  0.0008714275853880791 icount = 8 rms fractional error = 0.029519952326995367\n",
      "next ws: 1.220476755372125 0.4178730868528934 0.6937994677597612 0.7155534551292113 0.6955083762807922\n",
      "next bs: -0.15556789268511123 -0.12400744618742372 0.007196029557243349\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.220476755372125 0.4178730868528934 0.6937994677597612 0.7155534551292113 0.6955083762807922\n",
      "-0.15556789268511123 -0.12400744618742372 0.007196029557243349\n",
      "E3 =  0.0008170781663386258 icount = 8 rms fractional error = 0.028584579170220885\n",
      "next ws: 1.2202271759452719 0.4175682671765696 0.6934980103249876 0.7154645287468936 0.6954152923938186\n",
      "next bs: -0.15586942668859982 -0.12422320988545893 0.007045964097962541\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2202271759452719 0.4175682671765696 0.6934980103249876 0.7154645287468936 0.6954152923938186\n",
      "-0.15586942668859982 -0.12422320988545893 0.007045964097962541\n",
      "E3 =  0.0007661719072224109 icount = 8 rms fractional error = 0.027679810462183638\n",
      "next ws: 1.2199806669651472 0.41726634385684547 0.6931991611118813 0.7153765489293233 0.6953231997882644\n",
      "next bs: -0.15616832678056625 -0.12443706229890009 0.006897247859340236\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2199806669651472 0.41726634385684547 0.6931991611118813 0.7153765489293233 0.6953231997882644\n",
      "-0.15616832678056625 -0.12443706229890009 0.006897247859340236\n",
      "E3 =  0.0007184953823824019 icount = 8 rms fractional error = 0.026804764173228645\n",
      "next ws: 1.2197366224794832 0.4169665032596349 0.6929020913107796 0.7152892912552022 0.6952318654312735\n",
      "next bs: -0.1564654195773663 -0.12464959551858666 0.00674946858096646\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2197366224794832 0.4169665032596349 0.6929020913107796 0.7152892912552022 0.6952318654312735\n",
      "-0.1564654195773663 -0.12464959551858666 0.00674946858096646\n",
      "E3 =  0.0006738493966144501 icount = 8 rms fractional error = 0.025958609296617762\n",
      "next ws: 1.2194943579352326 0.4166678125537106 0.6926058465643916 0.7152024999537062 0.6951410237459499\n",
      "next bs: -0.1567616565104203 -0.12486149062447446 0.006602152351224322\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2194943579352326 0.4166678125537106 0.6926058465643916 0.7152024999537062 0.6951410237459499\n",
      "-0.1567616565104203 -0.12486149062447446 0.006602152351224322\n",
      "E3 =  0.0006320483601175633 icount = 8 rms fractional error = 0.025140571992648922\n",
      "next ws: 1.219253083155532 0.4163691781365029 0.6923093029268742 0.7151158771301462 0.6950503654678895\n",
      "next bs: -0.15705815758453118 -0.12507354893391753 0.00645474192090424\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.219253083155532 0.4163691781365029 0.6923093029268742 0.7151158771301462 0.6950503654678895\n",
      "-0.15705815758453118 -0.12507354893391753 0.00645474192090424\n",
      "E3 =  0.0005929198280149513 icount = 8 rms fractional error = 0.024349945133715422\n",
      "next ws: 1.2190118635574159 0.41606928530068243 0.6920111027262771 0.7150290672211852 0.6949595215771812\n",
      "next bs: -0.15735627508186753 -0.12528673748951305 0.006306565137423998\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2190118635574159 0.41606928530068243 0.6920111027262771 0.7150290672211852 0.6949595215771812\n",
      "-0.15735627508186753 -0.12528673748951305 0.006306565137423998\n",
      "E3 =  0.0005563042703878434 icount = 8 rms fractional error = 0.023586103332001312\n",
      "next ws: 1.218769562697915 0.415766507720881 0.6917095579590185 0.7149416338316743 0.69486803937283\n",
      "next bs: -0.15765768947658723 -0.1255022575430165 0.0061567874241509465\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.218769562697915 0.415766507720881 0.6917095579590185 0.7149416338316743 0.69486803937283\n",
      "-0.15765768947658723 -0.1255022575430165 0.0061567874241509465\n",
      "E3 =  0.0005220551946774446 icount = 8 rms fractional error = 0.022848527188364783\n",
      "next ws: 1.2185247539030488 0.4154587661986899 0.6914024988260946 0.7148530238717652 0.6947753454618835\n",
      "next bs: -0.15796455974639761 -0.1257216518750891 0.0060043373147741505\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2185247539030488 0.4154587661986899 0.6914024988260946 0.7148530238717652 0.6947753454618835\n",
      "-0.15796455974639761 -0.1257216518750891 0.0060043373147741505\n",
      "E3 =  0.0004900398552935678 icount = 8 rms fractional error = 0.02213684384219141\n",
      "next ws: 1.2182755780469259 0.4151432974189479 0.6910870244085222 0.7147625093982308 0.6946806858029413\n",
      "next bs: -0.15827977066556512 -0.12594698135381338 0.005847783948350739\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2182755780469259 0.4151432974189479 0.6910870244085222 0.7147625093982308 0.6946806858029413\n",
      "-0.15827977066556512 -0.12594698135381338 0.005847783948350739\n",
      "E3 =  0.0004601410299918342 icount = 8 rms fractional error = 0.021450898116205628\n",
      "next ws: 1.218019501512115 0.41481625222841895 0.6907590666276692 0.7146690877311228 0.6945830228696948\n",
      "next bs: -0.15860736500449915 -0.12618113350557453 0.005685122970983079\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.218019501512115 0.41481625222841895 0.6907590666276692 0.7146690877311228 0.6945830228696948\n",
      "-0.15860736500449915 -0.12618113350557453 0.005685122970983079\n",
      "E3 =  0.0004322609194026364 icount = 8 rms fractional error = 0.020790885488661526\n",
      "next ws: 1.2177528739813737 0.41447194270797955 0.6904125661073757 0.7145712969079792 0.6944808459599312\n",
      "next bs: -0.15895335972781133 -0.12642840523884383 0.005513372223018667\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2177528739813737 0.41447194270797955 0.6904125661073757 0.7145712969079792 0.6944808459599312\n",
      "-0.15895335972781133 -0.12642840523884383 0.005513372223018667\n",
      "E3 =  0.0004063297379073133 icount = 8 rms fractional error = 0.020157622327727873\n",
      "next ws: 1.2174700413681983 0.4141012811749702 0.6900377446742861 0.7144668401262182 0.6943717859863812\n",
      "next bs: -0.15932745497762615 -0.12669572296667111 0.00532772518125708\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2174700413681983 0.4141012811749702 0.6900377446742861 0.7144668401262182 0.6943717859863812\n",
      "-0.15932745497762615 -0.12669572296667111 0.00532772518125708\n",
      "E3 =  0.00038232611508363755 icount = 8 rms fractional error = 0.01955316125550131\n",
      "next ws: 1.2171613204813954 0.4136880519118803 0.6896169159124648 0.7143517114218152 0.6942517212865785\n",
      "next bs: -0.15974717227785012 -0.12699559705990845 0.005119501071564824\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2171613204813954 0.4136880519118803 0.6896169159124648 0.7143517114218152 0.6942517212865785\n",
      "-0.15974717227785012 -0.12699559705990845 0.005119501071564824\n",
      "E3 =  0.00036033300422404235 icount = 8 rms fractional error = 0.018982439364424224\n",
      "next ws: 1.2168073897663392 0.41319786525366015 0.6891117779342353 0.7142177034793993 0.6941122398249969\n",
      "next bs: -0.16025037666165484 -0.12735506197267432 0.004869941937134997\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.2168073897663392 0.41319786525366015 0.6891117779342353 0.7142177034793993 0.6941122398249969\n",
      "-0.16025037666165484 -0.12735506197267432 0.004869941937134997\n",
      "E3 =  0.00034073309683827933 icount = 8 rms fractional error = 0.018458957089670026\n",
      "next ws: 1.216357733025874 0.4125302702148731 0.6884058318375348 0.714042336036248 0.6939304618676472\n",
      "next bs: -0.16095176378660467 -0.127856005074306 0.004522231198836544\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.216357733025874 0.4125302702148731 0.6884058318375348 0.714042336036248 0.6939304618676472\n",
      "-0.16095176378660467 -0.127856005074306 0.004522231198836544\n",
      "E3 =  0.00032528839043788473 icount = 8 rms fractional error = 0.018035753115350762\n",
      "next ws: 1.2155550173401706 0.4109504557396481 0.6864932972921114 0.7136940904813198 0.6935754652339341\n",
      "next bs: -0.1628238544880018 -0.12919275709200334 0.0035946182537933196\n",
      "last w01, w02, w03, w12, w23:\n",
      "last b1, b2, b3:\n",
      "1.216357733025874 0.4125302702148731 0.6884058318375348 0.714042336036248 0.6939304618676472\n",
      "-0.16095176378660467 -0.127856005074306 0.004522231198836544\n",
      "Tdbin, Twbin, qdot, Tdbout, ypredicted:\n",
      "20.0 13.0 310.8 30.97 31.111950636608388\n",
      "20.0 14.5 308.0 32.3 31.696596380009723\n",
      "20.0 15.3 306.0 31.5 31.990227141614145\n",
      "20.2 13.0 310.8 30.91 31.305292042148874\n",
      "20.0 14.5 308.0 32.5 31.696596380009723\n",
      "20.0 15.3 306.0 31.4 31.990227141614145\n",
      "24.0 13.0 310.8 35.59 34.97877874741809\n",
      "36.0 14.5 308.0 46.4 47.163908823248555\n"
     ]
    }
   ],
   "source": [
    "'''#Intro to Neural Network Modeling \n",
    "# Python Neural Network Model of Spray Cooling Test System\n",
    "\n",
    ">>>>> start CodeP2.1F22\n",
    "    V.P. Carey, ME249, Fall 2022'''\n",
    "\n",
    "# version 3 print function\n",
    "from __future__ import print_function\n",
    "\n",
    "# import math, numpy and other usefuk packages\n",
    "import math\n",
    "import numpy \n",
    "\n",
    "%matplotlib inline\n",
    "# importing the required module \n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.figsize'] = [10, 8] # for square canvas\n",
    "\n",
    "\n",
    "#assembling data array\n",
    "#store array where rows are data vectors [x01, x02, x03, y3]\n",
    "xydata = []\n",
    "\n",
    "xydata = [[20./20.2, 13.0/14.5, 310.8/308.0, 30.97/32.4], [20./20.2, 14.5/14.5, 308.0/308.0, 32.3/32.4]]\n",
    "xydata.append([20./20.2, 15.3/14.5, 306.0/308.0, 31.5/32.4])\n",
    "xydata.append([20.2/20.2, 13.0/14.5, 310.8/308.0, 30.91/32.4]) \n",
    "xydata.append([20./20.2, 14.5/14.5, 308.0/308.0, 32.5/32.4]) \n",
    "xydata.append([20./20.2, 15.3/14.5, 306.0/308.0, 31.4/32.4]) \n",
    "xydata.append([24./20.2, 13.0/14.5, 310.8/308.0, 35.59/32.4]) \n",
    "xydata.append([36./20.2, 14.5/14.5, 308.0/308.0, 46.4/32.4]) \n",
    "print (xydata)\n",
    "\n",
    "#set starting values \n",
    "w01n =  1.23 \n",
    "w02n =  0.40 \n",
    "w03n =  0.70\n",
    "b1n =  -0.15\n",
    "w12n =  0.72\n",
    "b2n =  -0.12\n",
    "w23n =  0.7\n",
    "b3n =  0.01\n",
    "\n",
    "#start of batch loop  \n",
    "\n",
    "for k in range (0,200):\n",
    "    icount = 0\n",
    "    #initialize error and derivative parameters\n",
    "    E3ti = 0.\n",
    "    dE3da3 = 0.\n",
    "    dE3dw01ti = 0.\n",
    "    dE3dw02ti = 0.\n",
    "    dE3dw03ti = 0.\n",
    "    dE3db1ti = 0.\n",
    "    dE3dw12ti = 0.\n",
    "    dE3db2ti = 0.\n",
    "    dE3dw23ti = 0.\n",
    "    dE3db3ti = 0.\n",
    " \n",
    "    w01 = w01n \n",
    "    w02 = w02n\n",
    "    w03 = w03n\n",
    "    b1 = b1n \n",
    "    w12 = w12n\n",
    "    b2 = b2n \n",
    "    w23 = w23n \n",
    "    b3 = b3n \n",
    "    \n",
    "    #doing calcuations for each data point \n",
    "    for i in range(0,8):\n",
    "        #compute activation functions and their derivatives\n",
    "        z1 = w01*xydata[i][0]+w02*xydata[i][1]+w03*xydata[i][2]+b1 \n",
    "        sig1 = z1\n",
    "        sigp1 = 1.0\n",
    "        if z1 < 0.0:\n",
    "            sig1 = math.exp(z1) - 1.0\n",
    "            sigp1 = math.exp(z1)\n",
    "        a1 = sig1\n",
    "\n",
    "        z2 = w12*a1+b2 \n",
    "        sig2 = z2\n",
    "        sigp2 = 1.0\n",
    "        if z2 < 0.0:\n",
    "            sig2 = math.exp(z2) - 1.0\n",
    "            sigp2 = math.exp(z2)\n",
    "        a2 = sig2\n",
    "\n",
    "        z3 = w23*a2+b3 \n",
    "        sig3 = z3\n",
    "        sigp3 = 1.0\n",
    "        if z3 < 0.0:\n",
    "            sig3 = math.exp(z3) - 1.0\n",
    "            sigp3 = math.exp(z3)\n",
    "        a3 = sig3\n",
    "        \n",
    "        \n",
    "        #compute derivatives for backpropagation\n",
    "        #add to sum for batch average calculation\n",
    "        E3ti = E3ti +(a3 - xydata[i][3])*(a3 - xydata[i][3])\n",
    "        dE3da3 = 2.*(a3 - xydata[i][3])\n",
    "        \n",
    "        dE3dw01ti = dE3dw01ti + dE3da3*sigp3*w23*sigp2*w12*sigp1*xydata[i][0]\n",
    "        dE3dw02ti = dE3dw02ti + dE3da3*sigp3*w23*sigp2*w12*sigp1*xydata[i][1]\n",
    "        dE3dw03ti = dE3dw03ti + dE3da3*sigp3*w23*sigp2*w12*sigp1*xydata[i][2]\n",
    "        dE3db1ti = dE3db1ti + dE3da3*sigp3*w23*sigp2*w12*sigp1\n",
    "        \n",
    "        dE3dw12ti = dE3dw12ti + dE3da3*sigp3*w23*sigp2*a1\n",
    "        dE3db2ti = dE3db2ti + dE3da3*w23*sigp2\n",
    "        \n",
    "        dE3dw23ti = dE3dw23ti + dE3da3*sigp3*a2\n",
    "        dE3db3ti = dE3db3ti + dE3da3*sigp3\n",
    "        \n",
    "        icount = i + 1\n",
    "        # end  calculations for each data point in batch\n",
    "        \n",
    "    #compute batch averaged values\n",
    "    E3 = E3ti/icount\n",
    "    dE3dw01 = dE3dw01ti/icount\n",
    "    dE3dw02 = dE3dw02ti/icount\n",
    "    dE3dw03 = dE3dw03ti/icount\n",
    "    dE3db1 = dE3db1ti/icount\n",
    "    dE3dw12 = dE3dw12ti/icount\n",
    "    dE3db2 = dE3db2ti/icount\n",
    "    dE3dw23 = dE3dw23ti/icount\n",
    "    dE3db3 = dE3db3ti/icount\n",
    "    \n",
    "    #set gam = learning rate\n",
    "    gam = 0.05\n",
    "    if E3 < 0.07: \n",
    "        gam = 0.008\n",
    "\n",
    "    w01n = w01 + gam*(-E3)/dE3dw01\n",
    "    w02n = w02 + gam*(-E3)/dE3dw02\n",
    "    w03n = w03 + gam*(-E3)/dE3dw03\n",
    "    b1n = b1 + gam*(-E3)/dE3db1\n",
    "    w12n = w12 + gam*(-E3)/dE3dw12\n",
    "    b2n = b2 + gam*(-E3)/dE3db2\n",
    "    \n",
    "    w23n = w23 + gam*(-E3)/dE3dw23\n",
    "    b3n = b3 + gam*(-E3)/dE3db3\n",
    "    \n",
    "    #printing for each iteration\n",
    "    print ('last w01, w02, w03, w12, w23:')\n",
    "    print ('last b1, b2, b3:')\n",
    "    print (w01, w02, w03, w12, w23)\n",
    "    print (b1, b2, b3)\n",
    "    print ('E3 = ', E3, 'icount =', icount, 'rms fractional error =', E3**0.5)\n",
    "    print ('next ws:', w01n, w02n, w03n, w12n, w23n)\n",
    "    print ('next bs:', b1n, b2n, b3n)\n",
    "    \n",
    "    #quit if squared error is below target\n",
    "    if E3 < 0.00034:\n",
    "        break\n",
    "    \n",
    "\n",
    "print ('last w01, w02, w03, w12, w23:')\n",
    "print ('last b1, b2, b3:')\n",
    "print (w01, w02, w03, w12, w23)\n",
    "print (b1, b2, b3)\n",
    "#decomment print statements below if you want to print neuron outputs\n",
    "#print ('z1 =', z1)\n",
    "#print ('a1 =', a1)\n",
    "#print ('z2 =', z2)\n",
    "#print ('a2 =', a2)\n",
    "#print ('z3 =', z3)\n",
    "#print ('a3 =', a3)\n",
    "\n",
    "#print comparison of data and trained network predictions\n",
    "# restore raw data values  \n",
    "xydatar = [[20., 13.0, 310.8, 30.97], [20., 14.5, 308.0, 32.3]]\n",
    "xydatar.append([20., 15.3, 306.0, 31.5])\n",
    "xydatar.append([20.2, 13.0, 310.8, 30.91]) \n",
    "xydatar.append([20., 14.5, 308.0, 32.5]) \n",
    "xydatar.append([20., 15.3, 306.0, 31.4]) \n",
    "xydatar.append([24., 13.0, 310.8, 35.59]) \n",
    "xydatar.append([36., 14.5, 308.0, 46.4])\n",
    "print ('Tdbin, Twbin, qdot, Tdbout, ypredicted:')\n",
    "for i in range(0,8): \n",
    "    z1 = w01*xydata[i][0]+w02*xydata[i][1]+w03*xydata[i][2]+b1 \n",
    "    sig1 = z1\n",
    "    sigp1 = 1.0\n",
    "    if z1 < 0.0:\n",
    "        sig1 = math.exp(z1) - 1.0\n",
    "        sigp1 = math.exp(z1)\n",
    "    a1 = sig1\n",
    "\n",
    "    z2 = w12*a1+b2 \n",
    "    sig2 = z2\n",
    "    sigp2 = 1.0\n",
    "    if z2 < 0.0:\n",
    "        sig2 = math.exp(z2) - 1.0\n",
    "        sigp2 = math.exp(z2)\n",
    "    a2 = sig2\n",
    "\n",
    "    z3 = w23*a2+b3 \n",
    "    sig3 = z3\n",
    "    sigp3 = 1.0\n",
    "    if z3 < 0.0:\n",
    "        sig3 = math.exp(z3) - 1.0\n",
    "        sigp3 = math.exp(z3)\n",
    "    a3 = sig3\n",
    "\n",
    "    print (xydatar[i][0], xydatar[i][1], xydatar[i][2], xydatar[i][3], a3*32.4)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e65cfd-2922-4d1a-9cc6-0b42ae5e476d",
   "metadata": {},
   "source": [
    "--- \n",
    "### Task 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47ff82a9-8bf2-4843-9529-2cca9b031d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E3 =  0.00032528839043788473 icount = 8 rms fractional error = 0.018035753115350762\n",
      "\n",
      "last w01, w02, w03, w12, w23:\n",
      "1.216357733025874 0.4125302702148731 0.6884058318375348 0.714042336036248 0.6939304618676472\n",
      "last b1, b2, b3:\n",
      "-0.16095176378660467 -0.127856005074306 0.004522231198836544\n",
      "\n",
      "Tdbin, Twbin, qdot, Tdbout, ypredicted:\n",
      "20.0 13.0 310.8 30.97 31.111950636608388\n",
      "20.0 14.5 308.0 32.3 31.696596380009723\n",
      "20.0 15.3 306.0 31.5 31.990227141614145\n",
      "20.2 13.0 310.8 30.91 31.305292042148874\n",
      "20.0 14.5 308.0 32.5 31.696596380009723\n",
      "20.0 15.3 306.0 31.4 31.990227141614145\n",
      "24.0 13.0 310.8 35.59 34.97877874741809\n",
      "36.0 14.5 308.0 46.4 47.163908823248555\n",
      "\n",
      "[31.111950636608388, 31.696596380009723, 31.990227141614145, 31.305292042148874, 31.696596380009723, 31.990227141614145, 34.97877874741809, 47.163908823248555]\n"
     ]
    }
   ],
   "source": [
    "print ('E3 = ', E3, 'icount =', icount, 'rms fractional error =', E3**0.5)\n",
    "print('')\n",
    "print ('last w01, w02, w03, w12, w23:')\n",
    "print (w01, w02, w03, w12, w23)\n",
    "print ('last b1, b2, b3:')\n",
    "print (b1, b2, b3)\n",
    "print ('')\n",
    "print ('Tdbin, Twbin, qdot, Tdbout, ypredicted:')\n",
    "fpPredicted = []\n",
    "ydataList = []\n",
    "for i in range(0,8): \n",
    "    z1 = w01*xydata[i][0]+w02*xydata[i][1]+w03*xydata[i][2]+b1 \n",
    "    sig1 = z1\n",
    "    sigp1 = 1.0\n",
    "    if z1 < 0.0:\n",
    "        sig1 = math.exp(z1) - 1.0\n",
    "        sigp1 = math.exp(z1)\n",
    "    a1 = sig1\n",
    "\n",
    "    z2 = w12*a1+b2 \n",
    "    sig2 = z2\n",
    "    sigp2 = 1.0\n",
    "    if z2 < 0.0:\n",
    "        sig2 = math.exp(z2) - 1.0\n",
    "        sigp2 = math.exp(z2)\n",
    "    a2 = sig2\n",
    "\n",
    "    z3 = w23*a2+b3 \n",
    "    sig3 = z3\n",
    "    sigp3 = 1.0\n",
    "    if z3 < 0.0:\n",
    "        sig3 = math.exp(z3) - 1.0\n",
    "        sigp3 = math.exp(z3)\n",
    "    a3 = sig3\n",
    "    fpPredicted.append(a3*32.4)\n",
    "    ydataList.append(xydatar[i][3])\n",
    "\n",
    "    print (xydatar[i][0], xydatar[i][1], xydatar[i][2], xydatar[i][3], a3*32.4)\n",
    "    \n",
    "print('')    \n",
    "print(fpPredicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ca4837-82a9-4740-a274-2dff3535b7e3",
   "metadata": {},
   "source": [
    "---\n",
    "## Code P2.2\n",
    "\n",
    "### Task 1.2 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25b419b2-3d08-415c-a078-f9e3a0989716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.990099\n",
      "1    0.990099\n",
      "2    0.990099\n",
      "3    1.000000\n",
      "4    0.990099\n",
      "5    1.000000\n",
      "6    1.188119\n",
      "7    1.782178\n",
      "Name: x01, dtype: float64 0    0.896552\n",
      "1    1.000000\n",
      "2    1.055172\n",
      "3    0.896552\n",
      "4    1.000000\n",
      "5    1.055172\n",
      "6    0.896552\n",
      "7    1.000000\n",
      "Name: x02, dtype: float64 0    1.009091\n",
      "1    1.000000\n",
      "2    0.993506\n",
      "3    1.009091\n",
      "4    1.000000\n",
      "5    0.993506\n",
      "6    1.009091\n",
      "7    1.000000\n",
      "Name: x03, dtype: float64 0    0.955835\n",
      "1    0.996883\n",
      "2    0.972192\n",
      "3    0.953983\n",
      "4    1.003055\n",
      "5    0.969106\n",
      "6    1.098423\n",
      "7    1.432055\n",
      "Name: y3, dtype: float64\n",
      "[[0.9900990099009901, 0.896551724137931, 1.009090909090909], [0.9900990099009901, 1.0, 1.0], [0.9900990099009901, 1.0551724137931036, 0.9935064935064936], [1.0, 0.896551724137931, 1.009090909090909], [0.9900990099009901, 1.0, 1.0], [1.0, 1.0551724137931036, 0.9935064935064936], [1.188118811881188, 0.896551724137931, 1.009090909090909], [1.7821782178217822, 1.0, 1.0]]\n",
      "[[0.99009901 0.89655172 1.00909091]\n",
      " [0.99009901 1.         1.        ]\n",
      " [0.99009901 1.05517241 0.99350649]\n",
      " [1.         0.89655172 1.00909091]\n",
      " [0.99009901 1.         1.        ]\n",
      " [1.         1.05517241 0.99350649]\n",
      " [1.18811881 0.89655172 1.00909091]\n",
      " [1.78217822 1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "'''>>>>> start CodeP2.2F22\n",
    "    V.P. Carey ME249, Fall 2022\n",
    "\n",
    "Intro to Neural Network Modeling \n",
    "Keras model for comparison with first principles model'''\n",
    "\n",
    "#import useful packages\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#raw data in dictionary form x01, x02, x03, y3\n",
    "my_dict = { \n",
    "    'x01' : [20., 20., 20., 20.2, 20., 20.2, 24.0, 36.],\n",
    "    'x02' : [13., 14.5, 15.3, 13., 14.5, 15.3, 13., 14.5],\n",
    "    'x03' : [310.8, 308.0, 306.0, 310.8, 308.0, 306.0, 310.8, 308.0],\n",
    "    'y3' : [30.97, 32.3, 31.5, 30.91, 32.5, 31.4, 35.59, 46.4]\n",
    "}\n",
    "#normalized inputs in array\n",
    "xdata = []\n",
    "xdata = [[20./20.2, 13.0/14.5, 310.8/308.0], [20./20.2, 14.5/14.5, 308.0/308.0]] \n",
    "xdata.append([20./20.2, 15.3/14.5, 306.0/308.0])\n",
    "xdata.append([20.2/20.2, 13.0/14.5, 310.8/308.0]) \n",
    "xdata.append([20./20.2, 14.5/14.5, 308.0/308.0]) \n",
    "xdata.append([20.2/20.2, 15.3/14.5, 306.0/308.0]) \n",
    "xdata.append([24./20.2, 13.0/14.5, 310.8/308.0]) \n",
    "xdata.append([36./20.2, 14.5/14.5, 308.0/308.0]) \n",
    "\n",
    "#data frame\n",
    "df = pd.DataFrame(my_dict)\n",
    "#devide by the median to normalize \n",
    "df.x01= df.x01/20.2\n",
    "df.x02= df.x02/14.5\n",
    "df.x03= df.x03/308.0\n",
    "#normalize output array\n",
    "df.y3= df.y3/32.401\n",
    "df.head\n",
    "print (df.x01, df.x02, df.x03, df.y3)\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "print (xdata)\n",
    "print (xarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37722659-e9b5-4c26-9ac4-3f28ff2fed50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "Weights and biases of the layers before training the model: \n",
      "\n",
      "dense_one\n",
      "Weights\n",
      "Shape:  (3, 1) \n",
      " [[1.23]\n",
      " [0.4 ]\n",
      " [0.7 ]]\n",
      "Bias\n",
      "Shape:  (1,) \n",
      " [-0.15] \n",
      "\n",
      "dense_two\n",
      "Weights\n",
      "Shape:  (1, 1) \n",
      " [[0.72]]\n",
      "Bias\n",
      "Shape:  (1,) \n",
      " [-0.12] \n",
      "\n",
      "dense_three\n",
      "Weights\n",
      "Shape:  (1, 1) \n",
      " [[0.7]]\n",
      "Bias\n",
      "Shape:  (1,) \n",
      " [0.01] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.dense.Dense at 0x17ad59f9188>,\n",
       " <keras.layers.core.dense.Dense at 0x17ad5d33948>,\n",
       " <keras.layers.core.dense.Dense at 0x17ad5d33d88>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "#As seen below, we have created three dense layers each with just one neuron. \n",
    "#A dense layer is a layer in neural network that’s fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 3 in this case. \n",
    "#The activation function we have chosen is ReLU, which stands for rectified linear unit.\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 1.2\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=1.2)\n",
    "\n",
    "# define three layer model with one neuron in each layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, activation=K.elu, input_shape=[3],  kernel_initializer=initializer, name=\"dense_one\"),\n",
    "    keras.layers.Dense(1, activation=K.elu,  kernel_initializer=initializer, name=\"dense_two\"),\n",
    "    keras.layers.Dense(1, activation=K.elu,  kernel_initializer=initializer, name=\"dense_three\")\n",
    "  ])\n",
    "\n",
    "\n",
    "#set starting values to those used in first principles model\n",
    "w01n =  1.23 \n",
    "w02n =  0.40 \n",
    "w03n =  0.70\n",
    "b1n =  -0.15\n",
    "w12n =  0.72\n",
    "b2n =  -0.12\n",
    "w23n =  0.7\n",
    "b3n =  0.01\n",
    "\n",
    "weights0 =  [[ w01n], [w02n], [ w03n]]\n",
    "w0array= np.array(weights0)\n",
    "print(np.shape(w0array))\n",
    "bias0 = [b1n]\n",
    "bias0array= np.array(bias0)\n",
    "L0=[]\n",
    "L0.append(w0array)\n",
    "L0.append(bias0array)\n",
    "model.layers[0].set_weights(L0) \n",
    "\n",
    "weights1 =  [[ w12n]]\n",
    "w1array= np.array(weights1)\n",
    "print(np.shape(w1array))\n",
    "bias1 = [b2n]\n",
    "bias1array= np.array(bias1)\n",
    "L1=[]\n",
    "L1.append(w1array)\n",
    "L1.append(bias1array)\n",
    "model.layers[1].set_weights(L1)\n",
    "\n",
    "weights2 =  [[ w23n]]\n",
    "w2array= np.array(weights2)\n",
    "print(np.shape(w2array))\n",
    "bias2 = [b3n]\n",
    "bias2array= np.array(bias2)\n",
    "L2=[]\n",
    "L2.append(w2array)\n",
    "L2.append(bias2array)\n",
    "model.layers[2].set_weights(L2)\n",
    "\n",
    "\n",
    "print(\"Weights and biases of the layers before training the model: \\n\")\n",
    "for layer in model.layers:\n",
    "  print(layer.name)\n",
    "  print(\"Weights\")\n",
    "  print(\"Shape: \",layer.get_weights()[0].shape,'\\n',layer.get_weights()[0])\n",
    "  print(\"Bias\")\n",
    "  print(\"Shape: \",layer.get_weights()[1].shape,'\\n',layer.get_weights()[1],'\\n')\n",
    "model.layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7597c220-6cb9-47fa-af74-48dce695a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean absolute error. After the compilation of the model, we’ll use the fit method with 100 epochs.\n",
    "\n",
    "#Running model.fit successive times extends the calculation to addtional epochs.\n",
    "\n",
    "rms = keras.optimizers.RMSprop(0.0035)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "238405ca-6c51-44df-894b-f1945e9e65f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.0198\n",
      "Epoch 2/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0544\n",
      "Epoch 3/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 4/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 5/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0195\n",
      "Epoch 6/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 7/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 8/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0191\n",
      "Epoch 9/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 10/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0194\n",
      "Epoch 11/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0279\n",
      "Epoch 12/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 13/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 14/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 15/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 16/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 17/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 18/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0183\n",
      "Epoch 19/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0203\n",
      "Epoch 20/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0170\n",
      "Epoch 21/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 22/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 23/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0216\n",
      "Epoch 24/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0241\n",
      "Epoch 25/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 26/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 27/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 28/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0170\n",
      "Epoch 29/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 30/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 31/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 32/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0175\n",
      "Epoch 33/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 34/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 35/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 36/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0181\n",
      "Epoch 37/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0137\n",
      "Epoch 38/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 39/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0247\n",
      "Epoch 40/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0267\n",
      "Epoch 41/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 42/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0199\n",
      "Epoch 43/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 44/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 45/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0197\n",
      "Epoch 46/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 47/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 48/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0195\n",
      "Epoch 49/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 50/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0174\n",
      "Epoch 51/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0192\n",
      "Epoch 52/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 53/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0189\n",
      "Epoch 54/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0223\n",
      "Epoch 55/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 56/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 57/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0247\n",
      "Epoch 58/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 59/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 60/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0191\n",
      "Epoch 61/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0229\n",
      "Epoch 62/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 63/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 64/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0189\n",
      "Epoch 65/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 66/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 67/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0188\n",
      "Epoch 68/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 69/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0170\n",
      "Epoch 70/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0186\n",
      "Epoch 71/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 72/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0182\n",
      "Epoch 73/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 74/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 75/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 76/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0240\n",
      "Epoch 77/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 78/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 79/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0188\n",
      "Epoch 80/400\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0195\n",
      "Epoch 81/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 82/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 83/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0194\n",
      "Epoch 84/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 85/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 86/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0193\n",
      "Epoch 87/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 88/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 89/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0191\n",
      "Epoch 90/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 91/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 92/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0188\n",
      "Epoch 93/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 94/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0195\n",
      "Epoch 95/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0271\n",
      "Epoch 96/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 97/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0189\n",
      "Epoch 98/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0196\n",
      "Epoch 99/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 100/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 101/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0195\n",
      "Epoch 102/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 103/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 104/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0193\n",
      "Epoch 105/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 106/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 107/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0191\n",
      "Epoch 108/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 109/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 110/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0187\n",
      "Epoch 111/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 112/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0195\n",
      "Epoch 113/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0272\n",
      "Epoch 114/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 115/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 116/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0181\n",
      "Epoch 117/400\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0178Restoring model weights from the end of the best epoch: 37.\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 117: early stopping\n",
      "best epoch =  37\n",
      "smallest loss = 0.01374276727437973\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 80, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = tf.keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(xarray,df.y3,epochs=400,callbacks=[es])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00ccc57c-253d-4340-8c76-f10cd13b737c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2239491]\n",
      " [0.2895847]\n",
      " [0.7234253]]\n",
      "w01 =  1.2239491 w02 =  0.2895847 w03 =  0.7234253\n",
      "[-0.14015044]\n",
      "b1 =  [-0.14015044]\n",
      "[[0.70647335]]\n",
      "w12 =  0.70647335\n",
      "[-0.10168917]\n",
      "b2 =  [-0.10168917]\n",
      "[[0.6799924]]\n",
      "w23 =  0.6799924\n",
      "[0.03707751]\n",
      "b3 =  [0.03707751]\n",
      "x01/20.2,  x02/14.5,   x03/308.0,  y3/32.4,  a3:\n",
      "0.9900990099009901 0.896551724137931 1.009090909090909 0.9558346964599856 [[0.9581756]]\n",
      "0.9900990099009901 1.0 1.0 0.9968828122588808 [[0.96940756]]\n",
      "0.9900990099009901 1.0551724137931036 0.9935064935064936 0.9721922162896206 [[0.9748261]]\n",
      "1.0 0.896551724137931 1.009090909090909 0.9539829017622912 [[0.9639972]]\n",
      "0.9900990099009901 1.0 1.0 1.003055461251196 [[0.96940756]]\n",
      "1.0 1.0551724137931036 0.9935064935064936 0.9691058917934631 [[0.9806477]]\n",
      "1.188118811881188 0.896551724137931 1.009090909090909 1.0984228881824636 [[1.0746076]]\n",
      "1.7821782178217822 1.0 1.0 1.4320545662170918 [[1.435135]]\n",
      "  \n",
      "x01,  x02,   x03,  y3,  a3*32.4:\n",
      "20.0 13.0 310.8 30.969044165303533 [[31.044891]]\n",
      "20.0 14.5 308.0 32.29900311718774 [[31.408806]]\n",
      "20.0 15.3 306.0 31.499027807783705 [[31.584368]]\n",
      "20.2 13.0 310.8 30.909046017098234 [[31.233511]]\n",
      "20.0 14.5 308.0 32.498996944538746 [[31.408806]]\n",
      "20.2 15.3 306.0 31.3990308941082 [[31.772987]]\n",
      "23.999999999999996 13.0 310.8 35.58890157711182 [[34.817287]]\n",
      "36.0 14.5 308.0 46.398567945433776 [[46.498375]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#For results of training network:\n",
    "\n",
    "#keras.layer.get_weights() function retrieves weight values\n",
    "first_layer_weights = model.layers[0].get_weights()[0]\n",
    "w01 = first_layer_weights[0][0]\n",
    "w02 = first_layer_weights[1][0]\n",
    "w03 = first_layer_weights[2][0]\n",
    "first_layer_bias  = model.layers[0].get_weights()[1]\n",
    "b1 = first_layer_bias\n",
    "second_layer_weights = model.layers[1].get_weights()[0]\n",
    "w12 = second_layer_weights[0][0]\n",
    "second_layer_bias  = model.layers[1].get_weights()[1]\n",
    "b2 = second_layer_bias\n",
    "third_layer_weights = model.layers[2].get_weights()[0]\n",
    "w23 = third_layer_weights[0][0]\n",
    "third_layer_bias  = model.layers[2].get_weights()[1]\n",
    "b3 = third_layer_bias\n",
    "\n",
    "#print weights and biases\n",
    "print (first_layer_weights)\n",
    "print ('w01 = ', w01, 'w02 = ', w02, 'w03 = ', w03)\n",
    "print (first_layer_bias)\n",
    "print ('b1 = ', b1)\n",
    "print (second_layer_weights)\n",
    "print ('w12 = ', w12)\n",
    "print (second_layer_bias)\n",
    "print ('b2 = ', b2)\n",
    "print (third_layer_weights)\n",
    "print ('w23 = ', w23)\n",
    "print (third_layer_bias)\n",
    "print ('b3 = ', b3)\n",
    "\n",
    "#use model.predict() function to print model predictions for data conditions\n",
    "xarray= np.array(xdata)\n",
    "print ('x01/20.2,  x02/14.5,   x03/308.0,  y3/32.4,  a3:')\n",
    "test = []\n",
    "for i in range(0,8): \n",
    "    test = [[xarray[i][0], xarray[i][1], xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    print (xarray[i][0], xarray[i][1], xarray[i][2], df.y3[i], a3)\n",
    "print('  ')\n",
    "print ('x01,  x02,   x03,  y3,  a3*32.4:')\n",
    "for i in range(0,8): \n",
    "    test = [[xarray[i][0], xarray[i][1], xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    print (xarray[i][0]*20.2, xarray[i][1]*14.5, xarray[i][2]*308.0, df.y3[i]*32.4, a3*32.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d547edcd-73d2-428f-aed4-9833a005da03",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 1.2 b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6a37c39-520d-4cbe-913c-f3046f59cba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x01,  x02,   x03,  y3,  a3*32.4:\n",
      "20.0 13.0 310.8 30.969044165303533 [[31.044891]]\n",
      "20.0 14.5 308.0 32.29900311718774 [[31.408806]]\n",
      "20.0 15.3 306.0 31.499027807783705 [[31.584368]]\n",
      "20.2 13.0 310.8 30.909046017098234 [[31.233511]]\n",
      "20.0 14.5 308.0 32.498996944538746 [[31.408806]]\n",
      "20.2 15.3 306.0 31.3990308941082 [[31.772987]]\n",
      "23.999999999999996 13.0 310.8 35.58890157711182 [[34.817287]]\n",
      "36.0 14.5 308.0 46.398567945433776 [[46.498375]]\n",
      "\n",
      "smallest loss = 0.01374276727437973\n",
      "\n",
      "[31.044891357421875, 31.40880584716797, 31.584367752075195, 31.233510971069336, 31.40880584716797, 31.772987365722656, 34.81728744506836, 46.498374938964844]\n"
     ]
    }
   ],
   "source": [
    "print ('x01,  x02,   x03,  y3,  a3*32.4:')\n",
    "kerasPredicted = []\n",
    "for i in range(0,8): \n",
    "    test = [[xarray[i][0], xarray[i][1], xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    kerasPredicted.append(float(a3*32.4))\n",
    "    print (xarray[i][0]*20.2, xarray[i][1]*14.5, xarray[i][2]*308.0, df.y3[i]*32.4, a3*32.4)\n",
    "    \n",
    "print('')\n",
    "print('smallest loss =', np.min(loss_hist))\n",
    "print('')\n",
    "#print(kerasPredicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29843a5-5be0-4815-816a-8131100fc388",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 1.2 c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91f23c57-b2f9-4bfb-a584-b240f5a0a4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.97, 32.3, 31.5, 30.91, 32.5, 31.4, 35.59, 46.4]\n",
      "[31.111950636608388, 31.696596380009723, 31.990227141614145, 31.305292042148874, 31.696596380009723, 31.990227141614145, 34.97877874741809, 47.163908823248555]\n",
      "[31.044891357421875, 31.40880584716797, 31.584367752075195, 31.233510971069336, 31.40880584716797, 31.772987365722656, 34.81728744506836, 46.498374938964844]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ydataList)\n",
    "print(fpPredicted)\n",
    "print(kerasPredicted)\n",
    "print('')\n",
    "\n",
    "plt.scatter(fpPredicted, ydataList)\n",
    "plt.title('First Principle Model')\n",
    "plt.xlabel('Predicted y3 Values')\n",
    "plt.ylabel('Data y3 Values')\n",
    "plt.loglog()\n",
    "#plt.xlim(xmax = 1000, xmin = 10)\n",
    "#plt.ylim(ymax = 1000, ymin = 10)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(kerasPredicted, ydataList)\n",
    "plt.title('Keras Model')\n",
    "plt.xlabel('Predicted y3 Values')\n",
    "plt.ylabel('Data y3 Values')\n",
    "plt.loglog()\n",
    "#plt.xlim(xmax = 1000, xmin = 10)\n",
    "#plt.ylim(ymax = 1000, ymin = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266733b-a004-4f68-910a-3bc98ef98176",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 1.2 d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b01cff69-9922-4abf-a997-18180b03d772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.990099\n",
      "1    0.990099\n",
      "2    0.990099\n",
      "3    1.000000\n",
      "4    0.990099\n",
      "5    1.000000\n",
      "6    1.188119\n",
      "7    1.782178\n",
      "Name: x01, dtype: float64 0    0.896552\n",
      "1    1.000000\n",
      "2    1.055172\n",
      "3    0.896552\n",
      "4    1.000000\n",
      "5    1.055172\n",
      "6    0.896552\n",
      "7    1.000000\n",
      "Name: x02, dtype: float64 0    1.009091\n",
      "1    1.000000\n",
      "2    0.993506\n",
      "3    1.009091\n",
      "4    1.000000\n",
      "5    0.993506\n",
      "6    1.009091\n",
      "7    1.000000\n",
      "Name: x03, dtype: float64 0    0.955835\n",
      "1    0.996883\n",
      "2    0.972192\n",
      "3    0.953983\n",
      "4    1.003055\n",
      "5    0.969106\n",
      "6    1.098423\n",
      "7    1.432055\n",
      "Name: y3, dtype: float64\n",
      "[[0.9900990099009901, 0.896551724137931, 1.009090909090909], [0.9900990099009901, 1.0, 1.0], [0.9900990099009901, 1.0551724137931036, 0.9935064935064936], [1.0, 0.896551724137931, 1.009090909090909], [0.9900990099009901, 1.0, 1.0], [1.0, 1.0551724137931036, 0.9935064935064936], [1.188118811881188, 0.896551724137931, 1.009090909090909], [1.7821782178217822, 1.0, 1.0]]\n",
      "[[0.99009901 0.89655172 1.00909091]\n",
      " [0.99009901 1.         1.        ]\n",
      " [0.99009901 1.05517241 0.99350649]\n",
      " [1.         0.89655172 1.00909091]\n",
      " [0.99009901 1.         1.        ]\n",
      " [1.         1.05517241 0.99350649]\n",
      " [1.18811881 0.89655172 1.00909091]\n",
      " [1.78217822 1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "'''>>>>> start CodeP2.2F22\n",
    "    V.P. Carey ME249, Fall 2022\n",
    "\n",
    "Intro to Neural Network Modeling \n",
    "Keras model for comparison with first principles model'''\n",
    "\n",
    "#import useful packages\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#raw data in dictionary form x01, x02, x03, y3\n",
    "my_dict = { \n",
    "    'x01' : [20., 20., 20., 20.2, 20., 20.2, 24.0, 36.],\n",
    "    'x02' : [13., 14.5, 15.3, 13., 14.5, 15.3, 13., 14.5],\n",
    "    'x03' : [310.8, 308.0, 306.0, 310.8, 308.0, 306.0, 310.8, 308.0],\n",
    "    'y3' : [30.97, 32.3, 31.5, 30.91, 32.5, 31.4, 35.59, 46.4]\n",
    "}\n",
    "#normalized inputs in array\n",
    "xdata = []\n",
    "xdata = [[20./20.2, 13.0/14.5, 310.8/308.0], [20./20.2, 14.5/14.5, 308.0/308.0]] \n",
    "xdata.append([20./20.2, 15.3/14.5, 306.0/308.0])\n",
    "xdata.append([20.2/20.2, 13.0/14.5, 310.8/308.0]) \n",
    "xdata.append([20./20.2, 14.5/14.5, 308.0/308.0]) \n",
    "xdata.append([20.2/20.2, 15.3/14.5, 306.0/308.0]) \n",
    "xdata.append([24./20.2, 13.0/14.5, 310.8/308.0]) \n",
    "xdata.append([36./20.2, 14.5/14.5, 308.0/308.0]) \n",
    "\n",
    "#data frame\n",
    "df = pd.DataFrame(my_dict)\n",
    "#devide by the median to normalize \n",
    "df.x01= df.x01/20.2\n",
    "df.x02= df.x02/14.5\n",
    "df.x03= df.x03/308.0\n",
    "#normalize output array\n",
    "df.y3= df.y3/32.401\n",
    "df.head\n",
    "print (df.x01, df.x02, df.x03, df.y3)\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "print (xdata)\n",
    "print (xarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dadd2551-09ef-43fe-8ab4-bbf22c648b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "Weights and biases of the layers before training the model: \n",
      "\n",
      "dense_one\n",
      "Weights\n",
      "Shape:  (3, 1) \n",
      " [[1.476]\n",
      " [0.48 ]\n",
      " [0.84 ]]\n",
      "Bias\n",
      "Shape:  (1,) \n",
      " [-0.18] \n",
      "\n",
      "dense_two\n",
      "Weights\n",
      "Shape:  (1, 1) \n",
      " [[0.864]]\n",
      "Bias\n",
      "Shape:  (1,) \n",
      " [-0.144] \n",
      "\n",
      "dense_three\n",
      "Weights\n",
      "Shape:  (1, 1) \n",
      " [[0.84]]\n",
      "Bias\n",
      "Shape:  (1,) \n",
      " [0.012] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.dense.Dense at 0x17ada3a8f48>,\n",
       " <keras.layers.core.dense.Dense at 0x17ada3a8248>,\n",
       " <keras.layers.core.dense.Dense at 0x17adaa792c8>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "#As seen below, we have created three dense layers each with just one neuron. \n",
    "#A dense layer is a layer in neural network that’s fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 3 in this case. \n",
    "#The activation function we have chosen is ReLU, which stands for rectified linear unit.\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 1.2\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=1.2)\n",
    "\n",
    "# define three layer model with one neuron in each layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, activation=K.elu, input_shape=[3],  kernel_initializer=initializer, name=\"dense_one\"),\n",
    "    keras.layers.Dense(1, activation=K.elu,  kernel_initializer=initializer, name=\"dense_two\"),\n",
    "    keras.layers.Dense(1, activation=K.elu,  kernel_initializer=initializer, name=\"dense_three\")\n",
    "  ])\n",
    "\n",
    "\n",
    "#set starting values to those used in first principles model\n",
    "w01n =  1.23 * 1.2\n",
    "w02n =  0.40 * 1.2\n",
    "w03n =  0.70 * 1.2\n",
    "b1n =  -0.15 * 1.2\n",
    "w12n =  0.72 * 1.2\n",
    "b2n =  -0.12 * 1.2\n",
    "w23n =  0.7 * 1.2\n",
    "b3n =  0.01 * 1.2\n",
    "\n",
    "weights0 =  [[ w01n], [w02n], [ w03n]]\n",
    "w0array= np.array(weights0)\n",
    "print(np.shape(w0array))\n",
    "bias0 = [b1n]\n",
    "bias0array= np.array(bias0)\n",
    "L0=[]\n",
    "L0.append(w0array)\n",
    "L0.append(bias0array)\n",
    "model.layers[0].set_weights(L0) \n",
    "\n",
    "weights1 =  [[ w12n]]\n",
    "w1array= np.array(weights1)\n",
    "print(np.shape(w1array))\n",
    "bias1 = [b2n]\n",
    "bias1array= np.array(bias1)\n",
    "L1=[]\n",
    "L1.append(w1array)\n",
    "L1.append(bias1array)\n",
    "model.layers[1].set_weights(L1)\n",
    "\n",
    "weights2 =  [[ w23n]]\n",
    "w2array= np.array(weights2)\n",
    "print(np.shape(w2array))\n",
    "bias2 = [b3n]\n",
    "bias2array= np.array(bias2)\n",
    "L2=[]\n",
    "L2.append(w2array)\n",
    "L2.append(bias2array)\n",
    "model.layers[2].set_weights(L2)\n",
    "\n",
    "\n",
    "print(\"Weights and biases of the layers before training the model: \\n\")\n",
    "for layer in model.layers:\n",
    "  print(layer.name)\n",
    "  print(\"Weights\")\n",
    "  print(\"Shape: \",layer.get_weights()[0].shape,'\\n',layer.get_weights()[0])\n",
    "  print(\"Bias\")\n",
    "  print(\"Shape: \",layer.get_weights()[1].shape,'\\n',layer.get_weights()[1],'\\n')\n",
    "model.layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db23bb70-9eab-4603-bb4f-0a9d190228f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean absolute error. After the compilation of the model, we’ll use the fit method with 100 epochs.\n",
    "\n",
    "#Running model.fit successive times extends the calculation to addtional epochs.\n",
    "\n",
    "rms = keras.optimizers.RMSprop(0.0035)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd7143a9-db4a-418c-b5eb-1f5702a2ef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0182\n",
      "Epoch 2/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 3/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0175\n",
      "Epoch 4/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 5/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0228\n",
      "Epoch 6/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 7/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0217\n",
      "Epoch 8/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 9/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 10/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 11/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0205\n",
      "Epoch 12/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 13/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 14/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0202\n",
      "Epoch 15/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 16/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 17/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 18/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 19/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0185\n",
      "Epoch 20/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0236\n",
      "Epoch 21/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 22/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0187\n",
      "Epoch 23/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 24/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0179\n",
      "Epoch 25/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0215\n",
      "Epoch 26/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 27/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0193\n",
      "Epoch 28/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0201\n",
      "Epoch 29/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 30/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 31/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0200\n",
      "Epoch 32/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 33/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 34/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0197\n",
      "Epoch 35/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 36/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 37/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0194\n",
      "Epoch 38/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 39/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 40/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0191\n",
      "Epoch 41/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 42/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0196\n",
      "Epoch 43/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0281\n",
      "Epoch 44/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 45/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 46/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 47/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 48/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 49/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 50/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0185\n",
      "Epoch 51/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0203\n",
      "Epoch 52/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0169\n",
      "Epoch 53/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 54/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0172\n",
      "Epoch 55/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 56/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0174\n",
      "Epoch 57/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 58/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 59/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0233\n",
      "Epoch 60/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0256\n",
      "Epoch 61/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 62/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 63/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 64/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 65/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 66/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 67/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 68/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 69/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 70/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 71/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 72/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0182\n",
      "Epoch 73/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 74/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 75/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 76/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 77/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0258\n",
      "Epoch 78/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0275\n",
      "Epoch 79/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 80/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0201\n",
      "Epoch 81/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 82/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 83/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0198\n",
      "Epoch 84/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 85/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 86/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0196\n",
      "Epoch 87/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 88/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0175\n",
      "Epoch 89/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0192\n",
      "Epoch 90/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 91/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0191\n",
      "Epoch 92/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0224\n",
      "Epoch 93/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 94/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 95/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0248\n",
      "Epoch 96/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 97/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 98/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0193\n",
      "Epoch 99/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0229\n",
      "Epoch 100/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 101/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 102/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0188\n",
      "Epoch 103/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0194\n",
      "Epoch 104/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 105/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 106/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0193\n",
      "Epoch 107/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 108/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 109/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0192\n",
      "Epoch 110/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 111/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 112/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0190\n",
      "Epoch 113/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 114/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 115/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0187\n",
      "Epoch 116/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 117/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0197\n",
      "Epoch 118/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0270\n",
      "Epoch 119/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 120/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0191\n",
      "Epoch 121/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0196\n",
      "Epoch 122/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 123/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 124/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 125/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 126/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 127/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0193\n",
      "Epoch 128/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 129/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0169\n",
      "Epoch 130/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0191\n",
      "Epoch 131/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 132/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 133/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0187\n",
      "Epoch 134/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 135/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0197\n",
      "Epoch 136/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0272\n",
      "Epoch 137/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 138/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0191\n",
      "Epoch 139/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0196\n",
      "Epoch 140/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 141/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 142/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0195\n",
      "Epoch 143/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 144/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 145/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0193\n",
      "Epoch 146/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 147/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0169\n",
      "Epoch 148/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0190\n",
      "Epoch 149/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 150/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 151/400\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 152/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 153/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0197\n",
      "Epoch 154/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0273\n",
      "Epoch 155/400\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0165Restoring model weights from the end of the best epoch: 75.\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0165\n",
      "Epoch 155: early stopping\n",
      "best epoch =  75\n",
      "smallest loss = 0.013805627822875977\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 80, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = tf.keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(xarray,df.y3,epochs=400,callbacks=[es])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "270e672a-4d3b-4170-b2c9-1c46c76bca3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2525225 ]\n",
      " [0.31262684]\n",
      " [0.85114336]]\n",
      "w01 =  1.2525225 w02 =  0.31262684 w03 =  0.85114336\n",
      "[-0.18649891]\n",
      "b1 =  [-0.18649891]\n",
      "[[0.70963174]]\n",
      "w12 =  0.70963174\n",
      "[-0.14175826]\n",
      "b2 =  [-0.14175826]\n",
      "[[0.66086984]]\n",
      "w23 =  0.66086984\n",
      "[0.02373085]\n",
      "b3 =  [0.02373085]\n",
      "x01/20.2,  x02/14.5,   x03/308.0,  y3/32.4,  a3:\n",
      "0.9900990099009901 0.896551724137931 1.009090909090909 0.9558346964599856 [[0.95840883]]\n",
      "0.9900990099009901 1.0 1.0 0.9968828122588808 [[0.96994704]]\n",
      "0.9900990099009901 1.0551724137931036 0.9935064935064936 0.9721922162896206 [[0.97544414]]\n",
      "1.0 0.896551724137931 1.009090909090909 0.9539829017622912 [[0.96422464]]\n",
      "0.9900990099009901 1.0 1.0 1.003055461251196 [[0.96994704]]\n",
      "1.0 1.0551724137931036 0.9935064935064936 0.9691058917934631 [[0.98125994]]\n",
      "1.188118811881188 0.896551724137931 1.009090909090909 1.0984228881824636 [[1.0747257]]\n",
      "1.7821782178217822 1.0 1.0 1.4320545662170918 [[1.435215]]\n",
      "  \n",
      "x01,  x02,   x03,  y3,  a3*32.4:\n",
      "20.0 13.0 310.8 30.969044165303533 [[31.052448]]\n",
      "20.0 14.5 308.0 32.29900311718774 [[31.426285]]\n",
      "20.0 15.3 306.0 31.499027807783705 [[31.604391]]\n",
      "20.2 13.0 310.8 30.909046017098234 [[31.24088]]\n",
      "20.0 14.5 308.0 32.498996944538746 [[31.426285]]\n",
      "20.2 15.3 306.0 31.3990308941082 [[31.792824]]\n",
      "23.999999999999996 13.0 310.8 35.58890157711182 [[34.821117]]\n",
      "36.0 14.5 308.0 46.398567945433776 [[46.50097]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#For results of training network:\n",
    "\n",
    "#keras.layer.get_weights() function retrieves weight values\n",
    "first_layer_weights = model.layers[0].get_weights()[0]\n",
    "w01 = first_layer_weights[0][0]\n",
    "w02 = first_layer_weights[1][0]\n",
    "w03 = first_layer_weights[2][0]\n",
    "first_layer_bias  = model.layers[0].get_weights()[1]\n",
    "b1 = first_layer_bias\n",
    "second_layer_weights = model.layers[1].get_weights()[0]\n",
    "w12 = second_layer_weights[0][0]\n",
    "second_layer_bias  = model.layers[1].get_weights()[1]\n",
    "b2 = second_layer_bias\n",
    "third_layer_weights = model.layers[2].get_weights()[0]\n",
    "w23 = third_layer_weights[0][0]\n",
    "third_layer_bias  = model.layers[2].get_weights()[1]\n",
    "b3 = third_layer_bias\n",
    "\n",
    "#print weights and biases\n",
    "print (first_layer_weights)\n",
    "print ('w01 = ', w01, 'w02 = ', w02, 'w03 = ', w03)\n",
    "print (first_layer_bias)\n",
    "print ('b1 = ', b1)\n",
    "print (second_layer_weights)\n",
    "print ('w12 = ', w12)\n",
    "print (second_layer_bias)\n",
    "print ('b2 = ', b2)\n",
    "print (third_layer_weights)\n",
    "print ('w23 = ', w23)\n",
    "print (third_layer_bias)\n",
    "print ('b3 = ', b3)\n",
    "\n",
    "#use model.predict() function to print model predictions for data conditions\n",
    "xarray= np.array(xdata)\n",
    "print ('x01/20.2,  x02/14.5,   x03/308.0,  y3/32.4,  a3:')\n",
    "test = []\n",
    "for i in range(0,8): \n",
    "    test = [[xarray[i][0], xarray[i][1], xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    print (xarray[i][0], xarray[i][1], xarray[i][2], df.y3[i], a3)\n",
    "print('  ')\n",
    "print ('x01,  x02,   x03,  y3,  a3*32.4:')\n",
    "for i in range(0,8): \n",
    "    test = [[xarray[i][0], xarray[i][1], xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    print (xarray[i][0]*20.2, xarray[i][1]*14.5, xarray[i][2]*308.0, df.y3[i]*32.4, a3*32.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf7b09f-591c-4e83-b847-09519a5afd29",
   "metadata": {},
   "source": [
    "---\n",
    "## Code P2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac12869b-abf9-46c6-a425-b992c0e23707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data In Dimensional Form\n",
      "xdata = [[318.0, 0.0, 500.0], [318.0, 0.0, 1000.0], [318.0, 0.0, 1500.0], [318.0, 0.0, 2000.0], [318.0, 0.0, 2500.0], [318.0, 0.25, 500.0], [318.0, 0.25, 1000.0], [318.0, 0.25, 1500.0], [318.0, 0.25, 2000.0], [318.0, 0.25, 2500.0], [318.0, 0.5, 500.0], [318.0, 0.5, 1000.0], [318.0, 0.5, 1500.0], [318.0, 0.5, 2000.0], [318.0, 0.5, 2500.0], [303.0, 0.0, 500.0], [303.0, 0.0, 1000.0], [303.0, 0.0, 1500.0], [303.0, 0.0, 2000.0], [303.0, 0.0, 2500.0], [303.0, 0.25, 500.0], [303.0, 0.25, 1000.0], [303.0, 0.25, 1500.0], [303.0, 0.25, 2000.0], [303.0, 0.25, 2500.0], [303.0, 0.5, 500.0], [303.0, 0.5, 1000.0], [303.0, 0.5, 1500.0], [303.0, 0.5, 2000.0], [303.0, 0.5, 2500.0], [288.0, 0.0, 500.0], [288.0, 0.0, 1000.0], [288.0, 0.0, 1500.0], [288.0, 0.0, 2000.0], [288.0, 0.0, 2500.0], [288.0, 0.25, 500.0], [288.0, 0.25, 1000.0], [288.0, 0.25, 1500.0], [288.0, 0.25, 2000.0], [288.0, 0.25, 2500.0], [288.0, 0.5, 500.0], [288.0, 0.5, 1000.0], [288.0, 0.5, 1500.0], [288.0, 0.5, 2000.0], [288.0, 0.5, 2500.0], [268.0, 0.0, 500.0], [268.0, 0.0, 1000.0], [268.0, 0.0, 1500.0], [268.0, 0.0, 2000.0], [268.0, 0.0, 2500.0], [268.0, 0.25, 500.0], [268.0, 0.25, 1000.0], [268.0, 0.25, 1500.0], [268.0, 0.25, 2000.0], [268.0, 0.25, 2500.0], [268.0, 0.5, 500.0], [268.0, 0.5, 1000.0], [268.0, 0.5, 1500.0], [268.0, 0.5, 2000.0], [268.0, 0.5, 2500.0]]\n",
      "\n",
      "ydata = [[35.1316, 0.3808], [40.3764, 0.38686], [47.462, 0.393], [57.5639, 0.39949], [73.1286, 0.40612], [49.111, 0.4023], [56.4428, 0.40605], [66.3479, 0.4098], [80.4695, 0.413], [102.2276, 0.4175], [63.0904, 0.4154], [72.5092, 0.4175], [85.2338, 0.4197], [103.375, 0.42192], [131.3266, 0.4242], [34.273, 0.3952], [38.99026, 0.4012], [45.2133, 0.4073], [53.8, 0.4136], [66.413, 0.4201], [47.922, 0.4178], [54.518, 0.4215], [63.22, 0.4252], [75.226, 0.429], [92.862, 0.4329], [61.572, 0.4315], [70.0468, 0.43373], [81.226, 0.43597], [96.653, 0.4382], [119.3124, 0.44045], [33.4521, 0.40913], [37.6911, 0.415], [43.1602, 0.4209], [50.4858, 0.4271], [60.8067, 0.4334], [46.7865, 0.4328], [52.7151, 0.43646], [60.36425, 0.44016], [70.6099, 0.443926], [85.0447, 0.4477], [60.1208, 0.44721], [67.7391, 0.4494], [77.5683, 0.4516], [90.7341, 0.4538], [109.2828, 0.456], [32.4123, 0.42694], [36.0807, 0.4325], [40.6854, 0.4383], [46.6374, 0.4442], [54.6293, 0.4503], [45.3472, 0.4519], [50.4796, 0.4555], [56.9219, 0.4591], [65.2492, 0.4628], [76.4304, 0.4665], [58.2822, 0.4672], [64.8785, 0.4693], [73.1584, 0.4715], [83.861, 0.4738], [98.2316, 0.476]]\n",
      "\n",
      "Data In Normalized Form\n",
      "xdata = [[1.0761421319796953, 0.0, 0.3333333333333333], [1.0761421319796953, 0.0, 0.6666666666666666], [1.0761421319796953, 0.0, 1.0], [1.0761421319796953, 0.0, 1.3333333333333333], [1.0761421319796953, 0.0, 1.6666666666666667], [1.0761421319796953, 1.0, 0.3333333333333333], [1.0761421319796953, 1.0, 0.6666666666666666], [1.0761421319796953, 1.0, 1.0], [1.0761421319796953, 1.0, 1.3333333333333333], [1.0761421319796953, 1.0, 1.6666666666666667], [1.0761421319796953, 2.0, 0.3333333333333333], [1.0761421319796953, 2.0, 0.6666666666666666], [1.0761421319796953, 2.0, 1.0], [1.0761421319796953, 2.0, 1.3333333333333333], [1.0761421319796953, 2.0, 1.6666666666666667], [1.0253807106598984, 0.0, 0.3333333333333333], [1.0253807106598984, 0.0, 0.6666666666666666], [1.0253807106598984, 0.0, 1.0], [1.0253807106598984, 0.0, 1.3333333333333333], [1.0253807106598984, 0.0, 1.6666666666666667], [1.0253807106598984, 1.0, 0.3333333333333333], [1.0253807106598984, 1.0, 0.6666666666666666], [1.0253807106598984, 1.0, 1.0], [1.0253807106598984, 1.0, 1.3333333333333333], [1.0253807106598984, 1.0, 1.6666666666666667], [1.0253807106598984, 2.0, 0.3333333333333333], [1.0253807106598984, 2.0, 0.6666666666666666], [1.0253807106598984, 2.0, 1.0], [1.0253807106598984, 2.0, 1.3333333333333333], [1.0253807106598984, 2.0, 1.6666666666666667], [0.9746192893401016, 0.0, 0.3333333333333333], [0.9746192893401016, 0.0, 0.6666666666666666], [0.9746192893401016, 0.0, 1.0], [0.9746192893401016, 0.0, 1.3333333333333333], [0.9746192893401016, 0.0, 1.6666666666666667], [0.9746192893401016, 1.0, 0.3333333333333333], [0.9746192893401016, 1.0, 0.6666666666666666], [0.9746192893401016, 1.0, 1.0], [0.9746192893401016, 1.0, 1.3333333333333333], [0.9746192893401016, 1.0, 1.6666666666666667], [0.9746192893401016, 2.0, 0.3333333333333333], [0.9746192893401016, 2.0, 0.6666666666666666], [0.9746192893401016, 2.0, 1.0], [0.9746192893401016, 2.0, 1.3333333333333333], [0.9746192893401016, 2.0, 1.6666666666666667], [0.9069373942470389, 0.0, 0.3333333333333333], [0.9069373942470389, 0.0, 0.6666666666666666], [0.9069373942470389, 0.0, 1.0], [0.9069373942470389, 0.0, 1.3333333333333333], [0.9069373942470389, 0.0, 1.6666666666666667], [0.9069373942470389, 1.0, 0.3333333333333333], [0.9069373942470389, 1.0, 0.6666666666666666], [0.9069373942470389, 1.0, 1.0], [0.9069373942470389, 1.0, 1.3333333333333333], [0.9069373942470389, 1.0, 1.6666666666666667], [0.9069373942470389, 2.0, 0.3333333333333333], [0.9069373942470389, 2.0, 0.6666666666666666], [0.9069373942470389, 2.0, 1.0], [0.9069373942470389, 2.0, 1.3333333333333333], [0.9069373942470389, 2.0, 1.6666666666666667]]\n",
      "\n",
      "ydata = [[0.5741456642373223, 0.8814814814814815], [0.6598599266048748, 0.8955092592592592], [0.7756578554928267, 0.9097222222222223], [0.9407503103072674, 0.9247453703703704], [1.1951197389741843, 0.9400925925925926], [0.8026069896150227, 0.93125], [0.9224284945010854, 0.9399305555555556], [1.0843047033511548, 0.9486111111111111], [1.3150899625506725, 0.9560185185185185], [1.6706763513585288, 0.9664351851851851], [1.0310683149927233, 0.961574074074074], [1.1849970623972963, 0.9664351851851851], [1.3929515512094832, 0.9715277777777779], [1.6894279805227543, 0.9766666666666667], [2.1462329637428734, 0.9819444444444445], [0.5601138106549588, 0.9148148148148149], [0.6372066380832612, 0.9287037037037037], [0.7389079962444444, 0.9428240740740741], [0.8792379719673439, 0.9574074074074075], [1.085368613982662, 0.9724537037037037], [0.7831755035802798, 0.9671296296296297], [0.8909720400690643, 0.9756944444444444], [1.033186330627797, 0.9842592592592593], [1.2293969457103238, 0.9930555555555556], [1.517617036297983, 1.0020833333333334], [1.0062535392188345, 0.9988425925925926], [1.144754765330895, 1.0040046296296297], [1.3274532251118862, 1.0091898148148148], [1.5795722621665371, 1.0143518518518517], [1.9498883384118313, 1.0195601851851852], [0.5466980773615017, 0.9470601851851852], [0.6159748387587055, 0.9606481481481481], [0.7053547717045532, 0.9743055555555555], [0.8250749517685675, 0.9886574074074074], [0.9937464607811652, 1.0032407407407409], [0.7646183527035341, 1.001851851851852], [0.8615077623802181, 1.0103240740740742], [0.9865156273109617, 1.018888888888889], [1.1539573471527316, 1.0276064814814814], [1.3898611441370108, 1.0363425925925926], [0.9825369937742434, 1.0352083333333333], [1.1070406860017306, 1.0402777777777779], [1.2676764829173701, 1.0453703703703703], [1.482841376808219, 1.050462962962963], [1.7859774617641793, 1.0555555555555556], [0.5297049241412108, 0.988287037037037], [0.5896565333673262, 1.0011574074074074], [0.6649098249940553, 1.0145833333333334], [0.7621816541604053, 1.0282407407407408], [0.8927909840519632, 1.042361111111111], [0.7410962855464227, 1.0460648148148148], [0.8249736269465192, 1.0543981481481481], [0.9302582884113003, 1.0627314814814814], [1.0663489643214055, 1.0712962962962962], [1.2490801095288642, 1.0798611111111112], [0.952489281222958, 1.0814814814814815], [1.0602907205257124, 1.0863425925925927], [1.1956067518285451, 1.0914351851851851], [1.3705162744824058, 1.0967592592592592], [1.605370869277088, 1.1018518518518519]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''>>>>> start CodeP2.3F22\n",
    "    V.P. Carey ME249, Fall 2022\n",
    "\n",
    "Intro to Neural Network Modeling \n",
    "Data arrays for hybrid solar/fossil-fuel gas turbine power system'''\n",
    "\n",
    "import statistics\n",
    "\n",
    "#create input data array, normalizing input temp\n",
    "#T1(K), gamma, , qsol(kW):\n",
    "xdata = []\n",
    "xdata =  [[ 318.0 , 0.0 , 500.0 ], [ 318.0 , 0.0 , 1000.0 ]]\n",
    "xdata.append([ 318.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 318.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 318.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 2500.0 ])\n",
    "  \n",
    "xdata.append([ 303.0 , 0.0 , 500.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 1000.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 2500.0 ])\n",
    "  \n",
    "xdata.append([ 288.0 , 0.0 , 500.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 1000.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 2500.0 ])\n",
    "  \n",
    "xdata.append([ 268.0 , 0.0 , 500.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 1000.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 2500.0 ])\n",
    "\n",
    "\n",
    "\n",
    "ydata =  [[ 35.1316 , 0.3808 ],[ 40.3764 , 0.38686 ]]\n",
    "ydata.append([ 47.4620 , 0.3930 ])\n",
    "ydata.append([ 57.5639 , 0.39949 ])\n",
    "ydata.append([ 73.1286 , 0.40612 ])\n",
    "ydata.append([ 49.1110 , 0.4023 ])\n",
    "ydata.append([ 56.4428 , 0.40605 ])\n",
    "ydata.append([ 66.3479 , 0.4098 ])\n",
    "ydata.append([ 80.4695 , 0.413 ])\n",
    "ydata.append([ 102.2276 , 0.4175 ])\n",
    "ydata.append([ 63.0904 , 0.41540 ])\n",
    "ydata.append([ 72.5092 , 0.4175 ])\n",
    "ydata.append([ 85.2338, 0.4197 ])\n",
    "ydata.append([ 103.3750 , 0.42192 ])\n",
    "ydata.append([ 131.3266 , 0.4242 ])\n",
    "  \n",
    "ydata.append([ 34.273 , 0.3952 ])\n",
    "ydata.append([ 38.99026 , 0.4012 ])\n",
    "ydata.append([ 45.2133, 0.4073 ])\n",
    "ydata.append([ 53.8000 , 0.4136 ])\n",
    "ydata.append([ 66.4130 , 0.4201 ])\n",
    "ydata.append([ 47.922 , 0.4178 ])\n",
    "ydata.append([ 54.518 , 0.4215 ])\n",
    "ydata.append([ 63.220 , 0.4252 ])\n",
    "ydata.append([ 75.226 , 0.4290 ])\n",
    "ydata.append([ 92.862 , 0.4329 ])\n",
    "ydata.append([ 61.572 , 0.4315 ])\n",
    "ydata.append([ 70.0468 , 0.43373 ])\n",
    "ydata.append([ 81.226 , 0.43597 ])\n",
    "ydata.append([ 96.653 , 0.4382 ])\n",
    "ydata.append([ 119.3124 , 0.44045 ])\n",
    "  \n",
    "ydata.append([ 33.4521 , 0.40913 ])\n",
    "ydata.append([ 37.6911, 0.4150 ])\n",
    "ydata.append([ 43.1602 , 0.4209 ])\n",
    "ydata.append([ 50.4858 , 0.4271 ])\n",
    "ydata.append([ 60.8067 , 0.4334 ])\n",
    "ydata.append([ 46.7865 , 0.4328 ])\n",
    "ydata.append([ 52.7151 , 0.43646 ])\n",
    "ydata.append([ 60.36425 , 0.44016 ])\n",
    "ydata.append([ 70.6099 , 0.443926 ])\n",
    "ydata.append([ 85.0447 , 0.4477 ])\n",
    "ydata.append([ 60.1208 , 0.44721 ])\n",
    "ydata.append([ 67.7391 , 0.44940 ])\n",
    "ydata.append([ 77.56830 , 0.4516 ])\n",
    "ydata.append([ 90.73410 , 0.4538 ])\n",
    "ydata.append([ 109.2828 , 0.4560 ])\n",
    "  \n",
    "ydata.append([ 32.4123 , 0.42694 ])\n",
    "ydata.append([ 36.0807 , 0.4325 ])\n",
    "ydata.append([ 40.6854 , 0.4383 ])\n",
    "ydata.append([ 46.6374 , 0.4442 ])\n",
    "ydata.append([ 54.6293 , 0.4503 ])\n",
    "ydata.append([ 45.3472 , 0.4519 ])\n",
    "ydata.append([ 50.4796 , 0.4555 ])\n",
    "ydata.append([ 56.9219 , 0.4591 ])\n",
    "ydata.append([ 65.2492 , 0.4628 ])\n",
    "ydata.append([ 76.4304 , 0.4665 ])\n",
    "ydata.append([ 58.2822 , 0.4672 ])\n",
    "ydata.append([ 64.8785 , 0.4693 ])\n",
    "ydata.append([ 73.1584 , 0.4715 ])\n",
    "ydata.append([ 83.8610 , 0.4738 ])\n",
    "ydata.append([ 98.2316 , 0.4760 ])\n",
    "\n",
    "print('Data In Dimensional Form')\n",
    "print('xdata =', xdata)\n",
    "print()\n",
    "print('ydata =', ydata)\n",
    "print()\n",
    "\n",
    "#Normalization of Data\n",
    "\n",
    "#Determine Median Value for xdata\n",
    "t1Values = []\n",
    "gammaValues = []\n",
    "qsolValues = []\n",
    "\n",
    "for i in range(len(xdata)):\n",
    "    t1Values.append(xdata[i][0])\n",
    "    gammaValues.append(xdata[i][1])\n",
    "    qsolValues.append(xdata[i][2])\n",
    "\n",
    "tmed = statistics.median(t1Values)\n",
    "gamed = statistics.median(gammaValues)\n",
    "qsmed = statistics.median(qsolValues)\n",
    "    \n",
    "for i in range(len(xdata)):\n",
    "    xdata[i][0] = xdata[i][0] / tmed\n",
    "    xdata[i][1] = xdata[i][1] / gamed\n",
    "    xdata[i][2] = xdata[i][2] / qsmed\n",
    "    \n",
    "    \n",
    "#Determine Median Value for ydata\n",
    "alphaValues = []\n",
    "nsysValues = []\n",
    "\n",
    "for i in range(len(ydata)):\n",
    "    alphaValues.append(ydata[i][0])\n",
    "    nsysValues.append(ydata[i][1])\n",
    "\n",
    "almed = statistics.median(alphaValues)\n",
    "efmed = statistics.median(nsysValues)\n",
    "    \n",
    "\n",
    "for i in range(len(ydata)):\n",
    "    ydata[i][0] = ydata[i][0] / almed\n",
    "    ydata[i][1] = ydata[i][1] / efmed\n",
    "    \n",
    "    \n",
    "\n",
    "print('Data In Normalized Form')\n",
    "print('xdata =', xdata)\n",
    "print()\n",
    "print('ydata =', ydata)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f152f6d3-1551-425b-a3af-2d8d9bed3b1a",
   "metadata": {},
   "source": [
    "## Code P2.4\n",
    "### Task 2.2 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ca3926-2923-46f8-9faa-ec381b71b23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0761421319796953, 0.0, 0.3333333333333333], [1.0761421319796953, 0.0, 0.6666666666666666], [1.0761421319796953, 0.0, 1.0], [1.0761421319796953, 0.0, 1.3333333333333333], [1.0761421319796953, 0.0, 1.6666666666666667], [1.0761421319796953, 1.0, 0.3333333333333333], [1.0761421319796953, 1.0, 0.6666666666666666], [1.0761421319796953, 1.0, 1.0], [1.0761421319796953, 1.0, 1.3333333333333333], [1.0761421319796953, 1.0, 1.6666666666666667], [1.0761421319796953, 2.0, 0.3333333333333333], [1.0761421319796953, 2.0, 0.6666666666666666], [1.0761421319796953, 2.0, 1.0], [1.0761421319796953, 2.0, 1.3333333333333333], [1.0761421319796953, 2.0, 1.6666666666666667], [1.0253807106598984, 0.0, 0.3333333333333333], [1.0253807106598984, 0.0, 0.6666666666666666], [1.0253807106598984, 0.0, 1.0], [1.0253807106598984, 0.0, 1.3333333333333333], [1.0253807106598984, 0.0, 1.6666666666666667], [1.0253807106598984, 1.0, 0.3333333333333333], [1.0253807106598984, 1.0, 0.6666666666666666], [1.0253807106598984, 1.0, 1.0], [1.0253807106598984, 1.0, 1.3333333333333333], [1.0253807106598984, 1.0, 1.6666666666666667], [1.0253807106598984, 2.0, 0.3333333333333333], [1.0253807106598984, 2.0, 0.6666666666666666], [1.0253807106598984, 2.0, 1.0], [1.0253807106598984, 2.0, 1.3333333333333333], [1.0253807106598984, 2.0, 1.6666666666666667], [0.9746192893401016, 0.0, 0.3333333333333333], [0.9746192893401016, 0.0, 0.6666666666666666], [0.9746192893401016, 0.0, 1.0], [0.9746192893401016, 0.0, 1.3333333333333333], [0.9746192893401016, 0.0, 1.6666666666666667], [0.9746192893401016, 1.0, 0.3333333333333333], [0.9746192893401016, 1.0, 0.6666666666666666], [0.9746192893401016, 1.0, 1.0], [0.9746192893401016, 1.0, 1.3333333333333333], [0.9746192893401016, 1.0, 1.6666666666666667], [0.9746192893401016, 2.0, 0.3333333333333333], [0.9746192893401016, 2.0, 0.6666666666666666], [0.9746192893401016, 2.0, 1.0], [0.9746192893401016, 2.0, 1.3333333333333333], [0.9746192893401016, 2.0, 1.6666666666666667], [0.9069373942470389, 0.0, 0.3333333333333333], [0.9069373942470389, 0.0, 0.6666666666666666], [0.9069373942470389, 0.0, 1.0], [0.9069373942470389, 0.0, 1.3333333333333333], [0.9069373942470389, 0.0, 1.6666666666666667], [0.9069373942470389, 1.0, 0.3333333333333333], [0.9069373942470389, 1.0, 0.6666666666666666], [0.9069373942470389, 1.0, 1.0], [0.9069373942470389, 1.0, 1.3333333333333333], [0.9069373942470389, 1.0, 1.6666666666666667], [0.9069373942470389, 2.0, 0.3333333333333333], [0.9069373942470389, 2.0, 0.6666666666666666], [0.9069373942470389, 2.0, 1.0], [0.9069373942470389, 2.0, 1.3333333333333333], [0.9069373942470389, 2.0, 1.6666666666666667]]\n",
      "[[1.07614213 0.         0.33333333]\n",
      " [1.07614213 0.         0.66666667]\n",
      " [1.07614213 0.         1.        ]\n",
      " [1.07614213 0.         1.33333333]\n",
      " [1.07614213 0.         1.66666667]\n",
      " [1.07614213 1.         0.33333333]\n",
      " [1.07614213 1.         0.66666667]\n",
      " [1.07614213 1.         1.        ]\n",
      " [1.07614213 1.         1.33333333]\n",
      " [1.07614213 1.         1.66666667]\n",
      " [1.07614213 2.         0.33333333]\n",
      " [1.07614213 2.         0.66666667]\n",
      " [1.07614213 2.         1.        ]\n",
      " [1.07614213 2.         1.33333333]\n",
      " [1.07614213 2.         1.66666667]\n",
      " [1.02538071 0.         0.33333333]\n",
      " [1.02538071 0.         0.66666667]\n",
      " [1.02538071 0.         1.        ]\n",
      " [1.02538071 0.         1.33333333]\n",
      " [1.02538071 0.         1.66666667]\n",
      " [1.02538071 1.         0.33333333]\n",
      " [1.02538071 1.         0.66666667]\n",
      " [1.02538071 1.         1.        ]\n",
      " [1.02538071 1.         1.33333333]\n",
      " [1.02538071 1.         1.66666667]\n",
      " [1.02538071 2.         0.33333333]\n",
      " [1.02538071 2.         0.66666667]\n",
      " [1.02538071 2.         1.        ]\n",
      " [1.02538071 2.         1.33333333]\n",
      " [1.02538071 2.         1.66666667]\n",
      " [0.97461929 0.         0.33333333]\n",
      " [0.97461929 0.         0.66666667]\n",
      " [0.97461929 0.         1.        ]\n",
      " [0.97461929 0.         1.33333333]\n",
      " [0.97461929 0.         1.66666667]\n",
      " [0.97461929 1.         0.33333333]\n",
      " [0.97461929 1.         0.66666667]\n",
      " [0.97461929 1.         1.        ]\n",
      " [0.97461929 1.         1.33333333]\n",
      " [0.97461929 1.         1.66666667]\n",
      " [0.97461929 2.         0.33333333]\n",
      " [0.97461929 2.         0.66666667]\n",
      " [0.97461929 2.         1.        ]\n",
      " [0.97461929 2.         1.33333333]\n",
      " [0.97461929 2.         1.66666667]\n",
      " [0.90693739 0.         0.33333333]\n",
      " [0.90693739 0.         0.66666667]\n",
      " [0.90693739 0.         1.        ]\n",
      " [0.90693739 0.         1.33333333]\n",
      " [0.90693739 0.         1.66666667]\n",
      " [0.90693739 1.         0.33333333]\n",
      " [0.90693739 1.         0.66666667]\n",
      " [0.90693739 1.         1.        ]\n",
      " [0.90693739 1.         1.33333333]\n",
      " [0.90693739 1.         1.66666667]\n",
      " [0.90693739 2.         0.33333333]\n",
      " [0.90693739 2.         0.66666667]\n",
      " [0.90693739 2.         1.        ]\n",
      " [0.90693739 2.         1.33333333]\n",
      " [0.90693739 2.         1.66666667]]\n",
      "[[0.5741456642373223, 0.8814814814814815], [0.6598599266048748, 0.8955092592592592], [0.7756578554928267, 0.9097222222222223], [0.9407503103072674, 0.9247453703703704], [1.1951197389741843, 0.9400925925925926], [0.8026069896150227, 0.93125], [0.9224284945010854, 0.9399305555555556], [1.0843047033511548, 0.9486111111111111], [1.3150899625506725, 0.9560185185185185], [1.6706763513585288, 0.9664351851851851], [1.0310683149927233, 0.961574074074074], [1.1849970623972963, 0.9664351851851851], [1.3929515512094832, 0.9715277777777779], [1.6894279805227543, 0.9766666666666667], [2.1462329637428734, 0.9819444444444445], [0.5601138106549588, 0.9148148148148149], [0.6372066380832612, 0.9287037037037037], [0.7389079962444444, 0.9428240740740741], [0.8792379719673439, 0.9574074074074075], [1.085368613982662, 0.9724537037037037], [0.7831755035802798, 0.9671296296296297], [0.8909720400690643, 0.9756944444444444], [1.033186330627797, 0.9842592592592593], [1.2293969457103238, 0.9930555555555556], [1.517617036297983, 1.0020833333333334], [1.0062535392188345, 0.9988425925925926], [1.144754765330895, 1.0040046296296297], [1.3274532251118862, 1.0091898148148148], [1.5795722621665371, 1.0143518518518517], [1.9498883384118313, 1.0195601851851852], [0.5466980773615017, 0.9470601851851852], [0.6159748387587055, 0.9606481481481481], [0.7053547717045532, 0.9743055555555555], [0.8250749517685675, 0.9886574074074074], [0.9937464607811652, 1.0032407407407409], [0.7646183527035341, 1.001851851851852], [0.8615077623802181, 1.0103240740740742], [0.9865156273109617, 1.018888888888889], [1.1539573471527316, 1.0276064814814814], [1.3898611441370108, 1.0363425925925926], [0.9825369937742434, 1.0352083333333333], [1.1070406860017306, 1.0402777777777779], [1.2676764829173701, 1.0453703703703703], [1.482841376808219, 1.050462962962963], [1.7859774617641793, 1.0555555555555556], [0.5297049241412108, 0.988287037037037], [0.5896565333673262, 1.0011574074074074], [0.6649098249940553, 1.0145833333333334], [0.7621816541604053, 1.0282407407407408], [0.8927909840519632, 1.042361111111111], [0.7410962855464227, 1.0460648148148148], [0.8249736269465192, 1.0543981481481481], [0.9302582884113003, 1.0627314814814814], [1.0663489643214055, 1.0712962962962962], [1.2490801095288642, 1.0798611111111112], [0.952489281222958, 1.0814814814814815], [1.0602907205257124, 1.0863425925925927], [1.1956067518285451, 1.0914351851851851], [1.3705162744824058, 1.0967592592592592], [1.605370869277088, 1.1018518518518519]]\n",
      "[[0.57414566 0.88148148]\n",
      " [0.65985993 0.89550926]\n",
      " [0.77565786 0.90972222]\n",
      " [0.94075031 0.92474537]\n",
      " [1.19511974 0.94009259]\n",
      " [0.80260699 0.93125   ]\n",
      " [0.92242849 0.93993056]\n",
      " [1.0843047  0.94861111]\n",
      " [1.31508996 0.95601852]\n",
      " [1.67067635 0.96643519]\n",
      " [1.03106831 0.96157407]\n",
      " [1.18499706 0.96643519]\n",
      " [1.39295155 0.97152778]\n",
      " [1.68942798 0.97666667]\n",
      " [2.14623296 0.98194444]\n",
      " [0.56011381 0.91481481]\n",
      " [0.63720664 0.9287037 ]\n",
      " [0.738908   0.94282407]\n",
      " [0.87923797 0.95740741]\n",
      " [1.08536861 0.9724537 ]\n",
      " [0.7831755  0.96712963]\n",
      " [0.89097204 0.97569444]\n",
      " [1.03318633 0.98425926]\n",
      " [1.22939695 0.99305556]\n",
      " [1.51761704 1.00208333]\n",
      " [1.00625354 0.99884259]\n",
      " [1.14475477 1.00400463]\n",
      " [1.32745323 1.00918981]\n",
      " [1.57957226 1.01435185]\n",
      " [1.94988834 1.01956019]\n",
      " [0.54669808 0.94706019]\n",
      " [0.61597484 0.96064815]\n",
      " [0.70535477 0.97430556]\n",
      " [0.82507495 0.98865741]\n",
      " [0.99374646 1.00324074]\n",
      " [0.76461835 1.00185185]\n",
      " [0.86150776 1.01032407]\n",
      " [0.98651563 1.01888889]\n",
      " [1.15395735 1.02760648]\n",
      " [1.38986114 1.03634259]\n",
      " [0.98253699 1.03520833]\n",
      " [1.10704069 1.04027778]\n",
      " [1.26767648 1.04537037]\n",
      " [1.48284138 1.05046296]\n",
      " [1.78597746 1.05555556]\n",
      " [0.52970492 0.98828704]\n",
      " [0.58965653 1.00115741]\n",
      " [0.66490982 1.01458333]\n",
      " [0.76218165 1.02824074]\n",
      " [0.89279098 1.04236111]\n",
      " [0.74109629 1.04606481]\n",
      " [0.82497363 1.05439815]\n",
      " [0.93025829 1.06273148]\n",
      " [1.06634896 1.0712963 ]\n",
      " [1.24908011 1.07986111]\n",
      " [0.95248928 1.08148148]\n",
      " [1.06029072 1.08634259]\n",
      " [1.19560675 1.09143519]\n",
      " [1.37051627 1.09675926]\n",
      " [1.60537087 1.10185185]]\n"
     ]
    }
   ],
   "source": [
    "'''>>>>> start CodeP2.4F22\n",
    "    V.P. Carey ME249, Fall 2022\n",
    "\n",
    "Intro to Neural Network Modeling \n",
    "Keras model for hybrid solar/fossil-fuel gas turbine power system'''\n",
    "\n",
    "#import useful packages\n",
    "import statistics\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#create input data array\n",
    "# meadian values of input variables\n",
    "'''Tmed = 293.\n",
    "gamed = 0.25\n",
    "qsmed = 1250.'''\n",
    "#T1(K), gamma, , qsol(kW):\n",
    "xdata = []\n",
    "xdata =  [[ 318.0, 0.0, 500.0], [ 318.0, 0.0, 1000.0]]\n",
    "xdata.append([ 318.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 318.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 318.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 2500.0 ])\n",
    "  \n",
    "xdata.append([ 303.0 , 0.0 , 500.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 1000.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 2500.0 ])\n",
    "  \n",
    "xdata.append([ 288.0 , 0.0 , 500.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 1000.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 2500.0 ])\n",
    "  \n",
    "xdata.append([ 268.0 , 0.0 , 500.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 1000.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 2500.0 ])\n",
    "\n",
    "\n",
    "\n",
    "'''#convert to:\n",
    "xdata =  [[ 318.0/Tmed , 0.0/gamed , 500.0/qsmed ], [ 318.0/Tmed , 0.0/gamed , 1000.0/qsmed ]]\n",
    "xdata.append([ 318.0/Tmed  , 0.0/gamed , 1500.0/qsmed ])\n",
    "xdata.append([ 318.0/Tmed  , 0.0/gamed , 2000.0/qsmed ])\n",
    "xdata.append([ 318.0/Tmed  , 0.0/gamed , 2500.0/qsmed ])'''\n",
    "\n",
    "t1Values = []\n",
    "gammaValues = []\n",
    "qsolValues = []\n",
    "\n",
    "for i in range(len(xdata)):\n",
    "    t1Values.append(xdata[i][0])\n",
    "    gammaValues.append(xdata[i][1])\n",
    "    qsolValues.append(xdata[i][2])\n",
    "\n",
    "tmed = statistics.median(t1Values)\n",
    "gamed = statistics.median(gammaValues)\n",
    "qsmed = statistics.median(qsolValues)\n",
    "    \n",
    "for i in range(len(xdata)):\n",
    "    xdata[i][0] = xdata[i][0] / tmed\n",
    "    xdata[i][1] = xdata[i][1] / gamed\n",
    "    xdata[i][2] = xdata[i][2] / qsmed\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "print (xdata)\n",
    "print (xarray)\n",
    "# meadian values of output variables\n",
    "'''almed = 60.\n",
    "efmed = 0.4'''\n",
    "# alpha, effsys\n",
    "ydata = []\n",
    "ydata =  [[ 35.1316, 0.3808], [ 40.3764, 0.38686]]\n",
    "ydata.append([ 47.4620 , 0.3930 ])\n",
    "ydata.append([ 57.5639 , 0.39949 ])\n",
    "ydata.append([ 73.1286 , 0.40612 ])\n",
    "ydata.append([ 49.1110 , 0.4023 ])\n",
    "ydata.append([ 56.4428 , 0.40605 ])\n",
    "ydata.append([ 66.3479 , 0.4098 ])\n",
    "ydata.append([ 80.4695 , 0.413 ])\n",
    "ydata.append([ 102.2276 , 0.4175 ])\n",
    "ydata.append([ 63.0904 , 0.41540 ])\n",
    "ydata.append([ 72.5092 , 0.4175 ])\n",
    "ydata.append([ 85.2338, 0.4197 ])\n",
    "ydata.append([ 103.3750 , 0.42192 ])\n",
    "ydata.append([ 131.3266 , 0.4242 ])\n",
    "  \n",
    "ydata.append([ 34.273 , 0.3952 ])\n",
    "ydata.append([ 38.99026 , 0.4012 ])\n",
    "ydata.append([ 45.2133, 0.4073 ])\n",
    "ydata.append([ 53.8000 , 0.4136 ])\n",
    "ydata.append([ 66.4130 , 0.4201 ])\n",
    "ydata.append([ 47.922 , 0.4178 ])\n",
    "ydata.append([ 54.518 , 0.4215 ])\n",
    "ydata.append([ 63.220 , 0.4252 ])\n",
    "ydata.append([ 75.226 , 0.4290 ])\n",
    "ydata.append([ 92.862 , 0.4329 ])\n",
    "ydata.append([ 61.572 , 0.4315 ])\n",
    "ydata.append([ 70.0468 , 0.43373 ])\n",
    "ydata.append([ 81.226 , 0.43597 ])\n",
    "ydata.append([ 96.653 , 0.4382 ])\n",
    "ydata.append([ 119.3124 , 0.44045 ])\n",
    "  \n",
    "ydata.append([ 33.4521 , 0.40913 ])\n",
    "ydata.append([ 37.6911, 0.4150 ])\n",
    "ydata.append([ 43.1602 , 0.4209 ])\n",
    "ydata.append([ 50.4858 , 0.4271 ])\n",
    "ydata.append([ 60.8067 , 0.4334 ])\n",
    "ydata.append([ 46.7865 , 0.4328 ])\n",
    "ydata.append([ 52.7151 , 0.43646 ])\n",
    "ydata.append([ 60.36425 , 0.44016 ])\n",
    "ydata.append([ 70.6099 , 0.443926 ])\n",
    "ydata.append([ 85.0447 , 0.4477 ])\n",
    "ydata.append([ 60.1208 , 0.44721 ])\n",
    "ydata.append([ 67.7391 , 0.44940 ])\n",
    "ydata.append([ 77.56830 , 0.4516 ])\n",
    "ydata.append([ 90.73410 , 0.4538 ])\n",
    "ydata.append([ 109.2828 , 0.4560 ])\n",
    "  \n",
    "ydata.append([ 32.4123 , 0.42694 ])\n",
    "ydata.append([ 36.0807 , 0.4325 ])\n",
    "ydata.append([ 40.6854 , 0.4383 ])\n",
    "ydata.append([ 46.6374 , 0.4442 ])\n",
    "ydata.append([ 54.6293 , 0.4503 ])\n",
    "ydata.append([ 45.3472 , 0.4519 ])\n",
    "ydata.append([ 50.4796 , 0.4555 ])\n",
    "ydata.append([ 56.9219 , 0.4591 ])\n",
    "ydata.append([ 65.2492 , 0.4628 ])\n",
    "ydata.append([ 76.4304 , 0.4665 ])\n",
    "ydata.append([ 58.2822 , 0.4672 ])\n",
    "ydata.append([ 64.8785 , 0.4693 ])\n",
    "ydata.append([ 73.1584 , 0.4715 ])\n",
    "ydata.append([ 83.8610 , 0.4738 ])\n",
    "ydata.append([ 98.2316 , 0.4760 ])\n",
    "\n",
    "'''#convert to:\n",
    "ydata =  [[ 35.1316/almed , 0.3808/efmed ], [ 40.3764/almed , 0.38686/efmed ]]\n",
    "ydata.append([ 47.4620/almed , 0.3930/efmed ])\n",
    "ydata.append([ 57.5639/almed , 0.39949/efmed ])\n",
    "ydata.append([ 73.1286/almed , 0.40612/efmed ])'''\n",
    "\n",
    "alphaValues = []\n",
    "nsysValues = []\n",
    "\n",
    "for i in range(len(ydata)):\n",
    "    alphaValues.append(ydata[i][0])\n",
    "    nsysValues.append(ydata[i][1])\n",
    "\n",
    "almed = statistics.median(alphaValues)\n",
    "efmed = statistics.median(nsysValues)\n",
    "    \n",
    "\n",
    "for i in range(len(ydata)):\n",
    "    ydata[i][0] = ydata[i][0] / almed\n",
    "    ydata[i][1] = ydata[i][1] / efmed\n",
    "\n",
    "yarray= np.array(ydata)\n",
    "print (ydata)\n",
    "print (yarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b9d0246-9a34-4bbc-8f57-19f46b465d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "\n",
    "#As seen below, we have created four dense layers. \n",
    "#A dense layer is a layer in neural network that’s fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 1 in our case. \n",
    "#The activation function we have chosen is elu, which stands for exponential linear unit. .\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 1.2\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(16, activation=K.relu, input_shape=[3],  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(32, activation=K.relu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(16, activation =K.relu, kernel_initializer = initializer),\n",
    "    keras.layers.Dense(2,  kernel_initializer=initializer)\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "339829d8-2d01-413d-b777-af588178ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean squared error. After the compilation of the model, we’ll use the fit method with ~500 epochs.\n",
    "#Number of epochs can be varied.\n",
    "\n",
    "#from tf.keras import optimizers\n",
    "rms = keras.optimizers.RMSprop(0.001)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "691775db-9e04-4e8e-aa45-d438db0dfb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 10.7231\n",
      "Epoch 2/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0121\n",
      "Epoch 3/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9281\n",
      "Epoch 4/600\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0775\n",
      "Epoch 5/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.3579\n",
      "Epoch 6/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.7185\n",
      "Epoch 7/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.1424\n",
      "Epoch 8/600\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.6114\n",
      "Epoch 9/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.1150\n",
      "Epoch 10/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.6471\n",
      "Epoch 11/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.2049\n",
      "Epoch 12/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7878\n",
      "Epoch 13/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4580\n",
      "Epoch 14/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2196\n",
      "Epoch 15/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9962\n",
      "Epoch 16/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7836\n",
      "Epoch 17/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5791\n",
      "Epoch 18/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3793\n",
      "Epoch 19/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1815\n",
      "Epoch 20/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9900\n",
      "Epoch 21/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8063\n",
      "Epoch 22/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6292\n",
      "Epoch 23/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4731\n",
      "Epoch 24/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3323\n",
      "Epoch 25/600\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2425\n",
      "Epoch 26/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1964\n",
      "Epoch 27/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1859\n",
      "Epoch 28/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1741\n",
      "Epoch 29/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1824\n",
      "Epoch 30/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1694\n",
      "Epoch 31/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1695\n",
      "Epoch 32/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1661\n",
      "Epoch 33/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1824\n",
      "Epoch 34/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1647\n",
      "Epoch 35/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1535\n",
      "Epoch 36/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1676\n",
      "Epoch 37/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1760\n",
      "Epoch 38/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1661\n",
      "Epoch 39/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1626\n",
      "Epoch 40/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1668\n",
      "Epoch 41/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1473\n",
      "Epoch 42/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1393\n",
      "Epoch 43/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1514\n",
      "Epoch 44/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1588\n",
      "Epoch 45/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1487\n",
      "Epoch 46/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1368\n",
      "Epoch 47/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1598\n",
      "Epoch 48/600\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1339\n",
      "Epoch 49/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.1506\n",
      "Epoch 50/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1551\n",
      "Epoch 51/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1295\n",
      "Epoch 52/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1301\n",
      "Epoch 53/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1514\n",
      "Epoch 54/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1318\n",
      "Epoch 55/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1307\n",
      "Epoch 56/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1332\n",
      "Epoch 57/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1447\n",
      "Epoch 58/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1342\n",
      "Epoch 59/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1454\n",
      "Epoch 60/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1441\n",
      "Epoch 61/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1262\n",
      "Epoch 62/600\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1125\n",
      "Epoch 63/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1109\n",
      "Epoch 64/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1356\n",
      "Epoch 65/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1650\n",
      "Epoch 66/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1080\n",
      "Epoch 67/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1274\n",
      "Epoch 68/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1260\n",
      "Epoch 69/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1058\n",
      "Epoch 70/600\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.1166\n",
      "Epoch 71/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1278\n",
      "Epoch 72/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1204\n",
      "Epoch 73/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1130\n",
      "Epoch 74/600\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.1122\n",
      "Epoch 75/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1310\n",
      "Epoch 76/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1206\n",
      "Epoch 77/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1117\n",
      "Epoch 78/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.1308\n",
      "Epoch 79/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1179\n",
      "Epoch 80/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1091\n",
      "Epoch 81/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1101\n",
      "Epoch 82/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1081\n",
      "Epoch 83/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1026\n",
      "Epoch 84/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0962\n",
      "Epoch 85/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1085\n",
      "Epoch 86/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.1195\n",
      "Epoch 87/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1448\n",
      "Epoch 88/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1094\n",
      "Epoch 89/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0994\n",
      "Epoch 90/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0932\n",
      "Epoch 91/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0906\n",
      "Epoch 92/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1291\n",
      "Epoch 93/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1437\n",
      "Epoch 94/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1243\n",
      "Epoch 95/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1064\n",
      "Epoch 96/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1230\n",
      "Epoch 97/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1037\n",
      "Epoch 98/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1020\n",
      "Epoch 99/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1029\n",
      "Epoch 100/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0952\n",
      "Epoch 101/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1222\n",
      "Epoch 102/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1181\n",
      "Epoch 103/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1044\n",
      "Epoch 104/600\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0876\n",
      "Epoch 105/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0886\n",
      "Epoch 106/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0868\n",
      "Epoch 107/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0829\n",
      "Epoch 108/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1067\n",
      "Epoch 109/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1451\n",
      "Epoch 110/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1190\n",
      "Epoch 111/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0918\n",
      "Epoch 112/600\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0808\n",
      "Epoch 113/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0865\n",
      "Epoch 114/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1083\n",
      "Epoch 115/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0873\n",
      "Epoch 116/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0984\n",
      "Epoch 117/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1169\n",
      "Epoch 118/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1379\n",
      "Epoch 119/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.1169\n",
      "Epoch 120/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0943\n",
      "Epoch 121/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.1015\n",
      "Epoch 122/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0890\n",
      "Epoch 123/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1018\n",
      "Epoch 124/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1067\n",
      "Epoch 125/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0859\n",
      "Epoch 126/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1061\n",
      "Epoch 127/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0966\n",
      "Epoch 128/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1374\n",
      "Epoch 129/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0947\n",
      "Epoch 130/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1279\n",
      "Epoch 131/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1127\n",
      "Epoch 132/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0952\n",
      "Epoch 133/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0893\n",
      "Epoch 134/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0828\n",
      "Epoch 135/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0841\n",
      "Epoch 136/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0814\n",
      "Epoch 137/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1222\n",
      "Epoch 138/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1400\n",
      "Epoch 139/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1004\n",
      "Epoch 140/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.1072\n",
      "Epoch 141/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0845\n",
      "Epoch 142/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0964\n",
      "Epoch 143/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.1224\n",
      "Epoch 144/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1043\n",
      "Epoch 145/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0912\n",
      "Epoch 146/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0892\n",
      "Epoch 147/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0872\n",
      "Epoch 148/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0910\n",
      "Epoch 149/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1120\n",
      "Epoch 150/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0789\n",
      "Epoch 151/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0980\n",
      "Epoch 152/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0931\n",
      "Epoch 153/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0969\n",
      "Epoch 154/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1257\n",
      "Epoch 155/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1126\n",
      "Epoch 156/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0943\n",
      "Epoch 157/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1223\n",
      "Epoch 158/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0940\n",
      "Epoch 159/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0881\n",
      "Epoch 160/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0960\n",
      "Epoch 161/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0966\n",
      "Epoch 162/600\n",
      "2/2 [==============================] - 0s 976us/step - loss: 0.0972\n",
      "Epoch 163/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1107\n",
      "Epoch 164/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0900\n",
      "Epoch 165/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0917\n",
      "Epoch 166/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1139\n",
      "Epoch 167/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1077\n",
      "Epoch 168/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1076\n",
      "Epoch 169/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1143\n",
      "Epoch 170/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0872\n",
      "Epoch 171/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0953\n",
      "Epoch 172/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0756\n",
      "Epoch 173/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0757\n",
      "Epoch 174/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0769\n",
      "Epoch 175/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0946\n",
      "Epoch 176/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0802\n",
      "Epoch 177/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0852\n",
      "Epoch 178/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1315\n",
      "Epoch 179/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1287\n",
      "Epoch 180/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0945\n",
      "Epoch 181/600\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.1036\n",
      "Epoch 182/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1019\n",
      "Epoch 183/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0920\n",
      "Epoch 184/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0866\n",
      "Epoch 185/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.1077\n",
      "Epoch 186/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0941\n",
      "Epoch 187/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0755\n",
      "Epoch 188/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0834\n",
      "Epoch 189/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1235\n",
      "Epoch 190/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0949\n",
      "Epoch 191/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1209\n",
      "Epoch 192/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0946\n",
      "Epoch 193/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0916\n",
      "Epoch 194/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0775\n",
      "Epoch 195/600\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0732\n",
      "Epoch 196/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0857\n",
      "Epoch 197/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1045\n",
      "Epoch 198/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1093\n",
      "Epoch 199/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.1032\n",
      "Epoch 200/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1054\n",
      "Epoch 201/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1046\n",
      "Epoch 202/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0917\n",
      "Epoch 203/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0815\n",
      "Epoch 204/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0985\n",
      "Epoch 205/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0951\n",
      "Epoch 206/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1073\n",
      "Epoch 207/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1041\n",
      "Epoch 208/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0930\n",
      "Epoch 209/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0848\n",
      "Epoch 210/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0763\n",
      "Epoch 211/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0818\n",
      "Epoch 212/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1031\n",
      "Epoch 213/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0942\n",
      "Epoch 214/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0912\n",
      "Epoch 215/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0839\n",
      "Epoch 216/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0971\n",
      "Epoch 217/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1181\n",
      "Epoch 218/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0970\n",
      "Epoch 219/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0835\n",
      "Epoch 220/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1027\n",
      "Epoch 221/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1041\n",
      "Epoch 222/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1004\n",
      "Epoch 223/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0964\n",
      "Epoch 224/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0864\n",
      "Epoch 225/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0989\n",
      "Epoch 226/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0935\n",
      "Epoch 227/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0933\n",
      "Epoch 228/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0717\n",
      "Epoch 229/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0794\n",
      "Epoch 230/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0826\n",
      "Epoch 231/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1297\n",
      "Epoch 232/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0919\n",
      "Epoch 233/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0825\n",
      "Epoch 234/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0883\n",
      "Epoch 235/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0836\n",
      "Epoch 236/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0818\n",
      "Epoch 237/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1059\n",
      "Epoch 238/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0965\n",
      "Epoch 239/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1067\n",
      "Epoch 240/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0860\n",
      "Epoch 241/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0842\n",
      "Epoch 242/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0881\n",
      "Epoch 243/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1052\n",
      "Epoch 244/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0973\n",
      "Epoch 245/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0848\n",
      "Epoch 246/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0891\n",
      "Epoch 247/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0772\n",
      "Epoch 248/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0917\n",
      "Epoch 249/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0972\n",
      "Epoch 250/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0869\n",
      "Epoch 251/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0808\n",
      "Epoch 252/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0721\n",
      "Epoch 253/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0847\n",
      "Epoch 254/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0913\n",
      "Epoch 255/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0843\n",
      "Epoch 256/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0830\n",
      "Epoch 257/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0884\n",
      "Epoch 258/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1237\n",
      "Epoch 259/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0829\n",
      "Epoch 260/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0872\n",
      "Epoch 261/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0872\n",
      "Epoch 262/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1026\n",
      "Epoch 263/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0865\n",
      "Epoch 264/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0955\n",
      "Epoch 265/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0970\n",
      "Epoch 266/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0902\n",
      "Epoch 267/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0934\n",
      "Epoch 268/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0885\n",
      "Epoch 269/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.1048\n",
      "Epoch 270/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0918\n",
      "Epoch 271/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0820\n",
      "Epoch 272/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0790\n",
      "Epoch 273/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0873\n",
      "Epoch 274/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0995\n",
      "Epoch 275/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1096\n",
      "Epoch 276/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0851\n",
      "Epoch 277/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0835\n",
      "Epoch 278/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0831\n",
      "Epoch 279/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0870\n",
      "Epoch 280/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.1033\n",
      "Epoch 281/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0966\n",
      "Epoch 282/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0810\n",
      "Epoch 283/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0692\n",
      "Epoch 284/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0931\n",
      "Epoch 285/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0679\n",
      "Epoch 286/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0787\n",
      "Epoch 287/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1147\n",
      "Epoch 288/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1027\n",
      "Epoch 289/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0958\n",
      "Epoch 290/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0825\n",
      "Epoch 291/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0728\n",
      "Epoch 292/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0914\n",
      "Epoch 293/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0966\n",
      "Epoch 294/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1058\n",
      "Epoch 295/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0689\n",
      "Epoch 296/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0796\n",
      "Epoch 297/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1002\n",
      "Epoch 298/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0762\n",
      "Epoch 299/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0941\n",
      "Epoch 300/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0814\n",
      "Epoch 301/600\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.1013\n",
      "Epoch 302/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1023\n",
      "Epoch 303/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0703\n",
      "Epoch 304/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0769\n",
      "Epoch 305/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0987\n",
      "Epoch 306/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0993\n",
      "Epoch 307/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0751\n",
      "Epoch 308/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0674\n",
      "Epoch 309/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0848\n",
      "Epoch 310/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0868\n",
      "Epoch 311/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0856\n",
      "Epoch 312/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0936\n",
      "Epoch 313/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0824\n",
      "Epoch 314/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0752\n",
      "Epoch 315/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0652\n",
      "Epoch 316/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0781\n",
      "Epoch 317/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1039\n",
      "Epoch 318/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0938\n",
      "Epoch 319/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0854\n",
      "Epoch 320/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0723\n",
      "Epoch 321/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0786\n",
      "Epoch 322/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0837\n",
      "Epoch 323/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0990\n",
      "Epoch 324/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0794\n",
      "Epoch 325/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0741\n",
      "Epoch 326/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1138\n",
      "Epoch 327/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0925\n",
      "Epoch 328/600\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.0722\n",
      "Epoch 329/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0868\n",
      "Epoch 330/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0777\n",
      "Epoch 331/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0907\n",
      "Epoch 332/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0718\n",
      "Epoch 333/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0990\n",
      "Epoch 334/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0919\n",
      "Epoch 335/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0850\n",
      "Epoch 336/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0740\n",
      "Epoch 337/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0834\n",
      "Epoch 338/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0855\n",
      "Epoch 339/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0831\n",
      "Epoch 340/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0809\n",
      "Epoch 341/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0765\n",
      "Epoch 342/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0971\n",
      "Epoch 343/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0857\n",
      "Epoch 344/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0970\n",
      "Epoch 345/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0980\n",
      "Epoch 346/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0749\n",
      "Epoch 347/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0682\n",
      "Epoch 348/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0743\n",
      "Epoch 349/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0793\n",
      "Epoch 350/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0822\n",
      "Epoch 351/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0755\n",
      "Epoch 352/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0695\n",
      "Epoch 353/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0926\n",
      "Epoch 354/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1104\n",
      "Epoch 355/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0798\n",
      "Epoch 356/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0807\n",
      "Epoch 357/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0896\n",
      "Epoch 358/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0932\n",
      "Epoch 359/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0832\n",
      "Epoch 360/600\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0721\n",
      "Epoch 361/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0721\n",
      "Epoch 362/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0940\n",
      "Epoch 363/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0995\n",
      "Epoch 364/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0852\n",
      "Epoch 365/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0830\n",
      "Epoch 366/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0754\n",
      "Epoch 367/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0776\n",
      "Epoch 368/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0778\n",
      "Epoch 369/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0708\n",
      "Epoch 370/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0711\n",
      "Epoch 371/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0766\n",
      "Epoch 372/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0799\n",
      "Epoch 373/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0704\n",
      "Epoch 374/600\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.1142\n",
      "Epoch 375/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1037\n",
      "Epoch 376/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0844\n",
      "Epoch 377/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0952\n",
      "Epoch 378/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0774\n",
      "Epoch 379/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0770\n",
      "Epoch 380/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0894\n",
      "Epoch 381/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0822\n",
      "Epoch 382/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0808\n",
      "Epoch 383/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0621\n",
      "Epoch 384/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0642\n",
      "Epoch 385/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0770\n",
      "Epoch 386/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0795\n",
      "Epoch 387/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0946\n",
      "Epoch 388/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0922\n",
      "Epoch 389/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0922\n",
      "Epoch 390/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0858\n",
      "Epoch 391/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0737\n",
      "Epoch 392/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0798\n",
      "Epoch 393/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0820\n",
      "Epoch 394/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0712\n",
      "Epoch 395/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0705\n",
      "Epoch 396/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0955\n",
      "Epoch 397/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1035\n",
      "Epoch 398/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0878\n",
      "Epoch 399/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0771\n",
      "Epoch 400/600\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0715\n",
      "Epoch 401/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0760\n",
      "Epoch 402/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0625\n",
      "Epoch 403/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0860\n",
      "Epoch 404/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0674\n",
      "Epoch 405/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0722\n",
      "Epoch 406/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.1124\n",
      "Epoch 407/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0907\n",
      "Epoch 408/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0899\n",
      "Epoch 409/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0943\n",
      "Epoch 410/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0747\n",
      "Epoch 411/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0696\n",
      "Epoch 412/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 413/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0664\n",
      "Epoch 414/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0735\n",
      "Epoch 415/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0877\n",
      "Epoch 416/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0946\n",
      "Epoch 417/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0872\n",
      "Epoch 418/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0792\n",
      "Epoch 419/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0660\n",
      "Epoch 420/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0894\n",
      "Epoch 421/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0898\n",
      "Epoch 422/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0872\n",
      "Epoch 423/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0828\n",
      "Epoch 424/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0707\n",
      "Epoch 425/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0828\n",
      "Epoch 426/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0659\n",
      "Epoch 427/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0666\n",
      "Epoch 428/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0985\n",
      "Epoch 429/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0813\n",
      "Epoch 430/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0713\n",
      "Epoch 431/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0626\n",
      "Epoch 432/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0864\n",
      "Epoch 433/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1019\n",
      "Epoch 434/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0754\n",
      "Epoch 435/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0876\n",
      "Epoch 436/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0708\n",
      "Epoch 437/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0686\n",
      "Epoch 438/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0590\n",
      "Epoch 439/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0608\n",
      "Epoch 440/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0800\n",
      "Epoch 441/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1061\n",
      "Epoch 442/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0935\n",
      "Epoch 443/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0777\n",
      "Epoch 444/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0735\n",
      "Epoch 445/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0757\n",
      "Epoch 446/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0696\n",
      "Epoch 447/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0779\n",
      "Epoch 448/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0794\n",
      "Epoch 449/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0846\n",
      "Epoch 450/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0805\n",
      "Epoch 451/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0762\n",
      "Epoch 452/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0681\n",
      "Epoch 453/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0775\n",
      "Epoch 454/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0846\n",
      "Epoch 455/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0818\n",
      "Epoch 456/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0858\n",
      "Epoch 457/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0719\n",
      "Epoch 458/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0838\n",
      "Epoch 459/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0687\n",
      "Epoch 460/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0731\n",
      "Epoch 461/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0842\n",
      "Epoch 462/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0910\n",
      "Epoch 463/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0690\n",
      "Epoch 464/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0706\n",
      "Epoch 465/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0638\n",
      "Epoch 466/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0710\n",
      "Epoch 467/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0776\n",
      "Epoch 468/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0768\n",
      "Epoch 469/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0889\n",
      "Epoch 470/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0864\n",
      "Epoch 471/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0784\n",
      "Epoch 472/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0692\n",
      "Epoch 473/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0730\n",
      "Epoch 474/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0744\n",
      "Epoch 475/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0786\n",
      "Epoch 476/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0853\n",
      "Epoch 477/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0721\n",
      "Epoch 478/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0825\n",
      "Epoch 479/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0777\n",
      "Epoch 480/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0662\n",
      "Epoch 481/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0739\n",
      "Epoch 482/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0760\n",
      "Epoch 483/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0622\n",
      "Epoch 484/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0633\n",
      "Epoch 485/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0626\n",
      "Epoch 486/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0725\n",
      "Epoch 487/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0937\n",
      "Epoch 488/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0841\n",
      "Epoch 489/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0776\n",
      "Epoch 490/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0624\n",
      "Epoch 491/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0604\n",
      "Epoch 492/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0680\n",
      "Epoch 493/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0840\n",
      "Epoch 494/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0810\n",
      "Epoch 495/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0746\n",
      "Epoch 496/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0745\n",
      "Epoch 497/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0841\n",
      "Epoch 498/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0910\n",
      "Epoch 499/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0791\n",
      "Epoch 500/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0601\n",
      "Epoch 501/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0735\n",
      "Epoch 502/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0687\n",
      "Epoch 503/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0619\n",
      "Epoch 504/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0635\n",
      "Epoch 505/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0654\n",
      "Epoch 506/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1009\n",
      "Epoch 507/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0865\n",
      "Epoch 508/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0645\n",
      "Epoch 509/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0795\n",
      "Epoch 510/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0783\n",
      "Epoch 511/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0637\n",
      "Epoch 512/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0770\n",
      "Epoch 513/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0840\n",
      "Epoch 514/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0652\n",
      "Epoch 515/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0783\n",
      "Epoch 516/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0599\n",
      "Epoch 517/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0667\n",
      "Epoch 518/600\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0749Restoring model weights from the end of the best epoch: 438.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0692\n",
      "Epoch 518: early stopping\n",
      "best epoch =  438\n",
      "smallest loss = 0.058959342539310455\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 80, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(xarray,yarray,epochs=600,callbacks=[es])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b283bb9-c26d-49e4-b75a-5521fcb7016e",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 2.2 b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57c5a828-a8ed-49ec-99ba-9ad100bdc4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "T1 = np.linspace( 268/tmed,318/qsmed,20)\n",
    "Qs = np.linspace(500/qsmed,2500/qsmed,20)\n",
    "test = []\n",
    "outpt=[]\n",
    "Tmed = tmed\n",
    "alphaPredicted = []\n",
    "\n",
    "'''for i in range(len(T1)):\n",
    "    test = [[ T1[i], 0.25, Qs[i] ]]\n",
    "    testarray = np.array(test)\n",
    "    outpt = model.predict(testarray)\n",
    "    alphaPredicted =  outpt[0][0]*almed\n",
    "    print ('row [',i,'] data:  T1= ', T1[i]*Tmed, ', gam= ', 0.25*gamed, \\\n",
    "        ', qsol= ', Qs[i]*qsmed,\\\n",
    "        ',  predicted alpha = ', outpt[0][0]*almed)'''\n",
    "    \n",
    "function = np.zeros((len(T1),len(Qs)))\n",
    "for i in range(len(T1)):\n",
    "    for j in range(len(Qs)):\n",
    "        test = [[ T1[i], 0.25, Qs[j] ]]\n",
    "        testarray = np.array(test)\n",
    "        outpt = model.predict(testarray)\n",
    "        function[i][j] = outpt[0][0]*almed\n",
    "\n",
    "X,Y = np.meshgrid(Qs,T1)\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "        \n",
    "surf = ax.plot_surface(X, Y, function, cmap=plt.cm.coolwarm, linewidth = 0, antialiased = False)\n",
    "\n",
    "ax.set_xlabel(r'Qs', fontsize=20)\n",
    "ax.set_ylabel(r'T1', fontsize = 20)\n",
    "ax.zaxis.set_rotate_label(False)\n",
    "ax.set_zlabel(r'function', fontsize = 20, rotation = 90)\n",
    "fig.colorbar(surf,shrink=0.5,aspect=10)\n",
    "\n",
    "ax.view_init(30,225)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82567983-a021-4316-a110-f66e7cbbf538",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 2.3 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "919bdae2-40f6-42eb-a2b6-ef181f58a1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testData = []\n",
    "testData.append([ 318.0 , 0.0 , 500.0 ])\n",
    "testData.append([ 318.0 , 0.0 , 1500.0 ])\n",
    "testData.append([ 318.0 , 0.0 , 2500.0 ])\n",
    "testData.append([ 318.0 , 0.25 , 1500.0 ])\n",
    "testData.append([ 318.0 , 0.5 , 500.0 ])\n",
    "testData.append([ 318.0 , 0.5 , 1500.0 ])\n",
    "testData.append([ 318.0 , 0.5 , 2500.0 ])\n",
    "testData.append([ 303.0 , 0.0 , 1000.0 ])\n",
    "testData.append([ 303.0 , 0.0 , 2000.0 ])\n",
    "testData.append([ 303.0 , 0.25 , 1000.0 ])\n",
    "testData.append([ 303.0 , 0.25 , 2000.0 ])\n",
    "testData.append([ 303.0 , 0.5 , 1000.0 ])\n",
    "testData.append([ 303.0 , 0.5 , 2000.0 ])\n",
    "testData.append([ 288.0 , 0.0 , 500.0 ])\n",
    "testData.append([ 288.0 , 0.0 , 2500.0 ])\n",
    "testData.append([ 288.0 , 0.25 , 2500.0 ])\n",
    "testData.append([ 288.0 , 0.5 , 1500.0 ])\n",
    "testData.append([ 268.0 , 0.0 , 1500.0 ])\n",
    "testData.append([ 268.0 , 0.25 , 2000.0 ])\n",
    "testData.append([ 268.0 , 0.5 , 2500.0 ])\n",
    "\n",
    "testDataOutput = []\n",
    "testDataOutput.append([ 35.13 , 0.3808 ])\n",
    "testDataOutput.append([ 47.46 , 0.3930 ])\n",
    "testDataOutput.append([ 73.12 , 0.4061 ])\n",
    "testDataOutput.append([ 66.34 , 0.4098 ])\n",
    "testDataOutput.append([ 63.09, 0.4154 ])\n",
    "testDataOutput.append([ 85.23 , 0.4197 ])\n",
    "testDataOutput.append([131.32 , 0.4242 ])\n",
    "testDataOutput.append([ 38.99 , 0.4012 ])\n",
    "testDataOutput.append([ 53.80 , 0.4136 ])\n",
    "testDataOutput.append([ 54.51 , 0.4215 ])\n",
    "testDataOutput.append([ 75.22 , 0.4290 ])\n",
    "testDataOutput.append([ 70.04, 0.4337 ])\n",
    "testDataOutput.append([ 96.65, 0.4382 ])\n",
    "testDataOutput.append([ 33.45 , 0.4091 ])\n",
    "testDataOutput.append([ 60.80 , 0.4334 ])\n",
    "testDataOutput.append([ 85.044, 0.4477])\n",
    "testDataOutput.append([ 77.56 , 0.4516 ])\n",
    "testDataOutput.append([ 40.68 , 0.4383 ])\n",
    "testDataOutput.append([ 65.24 , 0.4628 ])\n",
    "testDataOutput.append([ 98.23 , 0.4760 ])\n",
    "\n",
    "alphaActual = []\n",
    "alphaPredicted = []\n",
    "test = []\n",
    "\n",
    "for i in range(len(testData)):\n",
    "    testData[i][0] = testData[i][0] / tmed\n",
    "    testData[i][1] = testData[i][1] / gamed\n",
    "    testData[i][2] = testData[i][2] / qsmed\n",
    "    \n",
    "for i in range(len(testDataOutput)):\n",
    "    alphaActual.append(testDataOutput[i][0])\n",
    "    testDataOutput[i][0] = testDataOutput[i][0] / almed\n",
    "    testDataOutput[i][1] = testDataOutput[i][1] / efmed\n",
    "\n",
    "for i in range(len(testData)):\n",
    "    test = [[ testData[i][0], testData[i][1] , testData[i][2] ]]\n",
    "    testarray = np.array(test)\n",
    "    outpt = model.predict(testarray)\n",
    "    alphaPredicted.append(outpt[0][0])\n",
    "\n",
    "for i in range(len(alphaPredicted)):\n",
    "    alphaPredicted[i] = alphaPredicted[i] * almed\n",
    "\n",
    "                          \n",
    "plt.scatter(alphaPredicted, alphaActual)\n",
    "plt.title('ANN Validation Set')\n",
    "plt.xlabel('Predicted Alpha Values')\n",
    "plt.ylabel('Data Alpha Values')\n",
    "plt.loglog()\n",
    "#plt.xlim(xmax = 1000, xmin = 10)\n",
    "#plt.ylim(ymax = 1000, ymin = 10)\n",
    "plt.show()\n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7346ce19-8184-4375-a3d9-424fe824f231",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 2.3 b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69df3b27-e21d-4879-9d1d-aadfc81e094e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = [9,10,11,12,13,14,15,16,17,18,19]\n",
    "alphaTime = []\n",
    "\n",
    "timeData = []\n",
    "timeData.append([ 287.0 ,  0.5, 490.0])\n",
    "timeData.append([ 295.0 ,  0.5, 720.0])\n",
    "timeData.append([ 301.0 ,  0.5, 980.0 ])\n",
    "timeData.append([ 305.0 ,  0.5, 2420.0])\n",
    "timeData.append([ 307.0 ,  0.5, 2570.0])\n",
    "timeData.append([ 308.0 ,  0.5, 2380.0])\n",
    "timeData.append([ 308.0 ,  0.5, 2075.0])\n",
    "timeData.append([ 305.0 ,  0.5, 1680.0])\n",
    "timeData.append([ 295.0 ,  0.5, 1000.0])\n",
    "timeData.append([ 292.0 ,  0.5, 800.0])\n",
    "timeData.append([ 295.0 ,  0.5, 250.0])\n",
    "\n",
    "for i in range(len(timeData)):\n",
    "    timeData[i][0] = timeData[i][0] / tmed\n",
    "    timeData[i][1] = timeData[i][1] / gamed\n",
    "    timeData[i][2] = timeData[i][2] / qsmed\n",
    "    \n",
    "for i in range(len(timeData)):\n",
    "    test = [[ timeData[i][0], timeData[i][1] , timeData[i][2] ]]\n",
    "    testarray = np.array(test)\n",
    "    outpt = model.predict(testarray)\n",
    "    alphaTime.append(outpt[0][0])\n",
    "\n",
    "for i in range(len(alphaTime)):\n",
    "    alphaTime[i] = alphaTime[i] * almed\n",
    "    \n",
    "plt.scatter(time, alphaTime)\n",
    "plt.title('Daylong Variation of Operating Conditions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Alpha Value')\n",
    "\n",
    "#plt.xlim(xmax = 1000, xmin = 10)\n",
    "#plt.ylim(ymax = 1000, ymin = 10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83c03302-2fc1-4313-9541-ccf0ee944e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = [9,10,11,12,13,14,15,16,17,18,19]\n",
    "alphaTime = []\n",
    "\n",
    "timeData = []\n",
    "timeData.append([ 287.0 ,  0, 490.0])\n",
    "timeData.append([ 295.0 ,  0, 720.0])\n",
    "timeData.append([ 301.0 ,  0, 980.0 ])\n",
    "timeData.append([ 305.0 ,  0, 2420.0])\n",
    "timeData.append([ 307.0 ,  0, 2570.0])\n",
    "timeData.append([ 308.0 ,  0, 2380.0])\n",
    "timeData.append([ 308.0 ,  0, 2075.0])\n",
    "timeData.append([ 305.0 ,  0, 1680.0])\n",
    "timeData.append([ 295.0 ,  0, 1000.0])\n",
    "timeData.append([ 292.0 ,  0, 800.0])\n",
    "timeData.append([ 295.0 ,  0, 250.0])\n",
    "\n",
    "for i in range(len(timeData)):\n",
    "    timeData[i][0] = timeData[i][0] / tmed\n",
    "    timeData[i][1] = timeData[i][1] / gamed\n",
    "    timeData[i][2] = timeData[i][2] / qsmed\n",
    "    \n",
    "for i in range(len(timeData)):\n",
    "    test = [[ timeData[i][0], timeData[i][1] , timeData[i][2] ]]\n",
    "    testarray = np.array(test)\n",
    "    outpt = model.predict(testarray)\n",
    "    alphaTime.append(outpt[0][0])\n",
    "\n",
    "for i in range(len(alphaTime)):\n",
    "    alphaTime[i] = alphaTime[i] * almed\n",
    "    \n",
    "plt.scatter(time, alphaTime)\n",
    "plt.title('Daylong Variation of Operating Conditions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Alpha Value')\n",
    "\n",
    "#plt.xlim(xmax = 1000, xmin = 10)\n",
    "#plt.ylim(ymax = 1000, ymin = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adeb519-5f94-4dfb-b88c-bf948090e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "outpt=[]\n",
    "Tmed = tmed\n",
    "\n",
    "#first point (row [0])comparison of data and prediction\n",
    "# put in a loop to print comparion for all data points\n",
    "\n",
    "#test = [[ xarray[0][0] , xarray[0][1] , xarray[0][2] ]]\n",
    "test = [[ xarray[0][0] , 0.25 , xarray[0][2] ]]\n",
    "\n",
    "testarray = np.array(test)\n",
    "outpt = model.predict(testarray)\n",
    "print ('row [0] data:  T1= ', xarray[0][0]*Tmed, ', gam= ', xarray[0][1]*gamed, \\\n",
    "    ', qsol= ', xarray[0][2]*qsmed,', alpha= ', yarray[0][0]*almed,\\\n",
    "    ',  predicted alpha = ', outpt[0][0]*almed)\n",
    "\n",
    "#20th point (row [20])comparison of data and prediction\n",
    "test = [[ xarray[20][0] , 0.25 , xarray[20][2] ]]\n",
    "testarray = np.array(test)\n",
    "outpt = model.predict(testarray)\n",
    "print ('row [20] data:  T1= ', xarray[20][0]*Tmed, ', gam= ', xarray[0][1]*gamed, \\\n",
    "    ', qsol= ', xarray[20][2]*qsmed,', alpha= ', yarray[20][0]*almed,\\\n",
    "    ',  predicted alpha = ', outpt[0][0]*almed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc47d66-3f43-4b6a-b920-0e3836e0d414",
   "metadata": {},
   "source": [
    "--- \n",
    "### Task 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ffac2d54-dcb0-493a-ae56-06894b36ace1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0761421319796953, 0.0, 0.3333333333333333], [1.0761421319796953, 0.0, 0.6666666666666666], [1.0761421319796953, 0.0, 1.0], [1.0761421319796953, 0.0, 1.3333333333333333], [1.0761421319796953, 0.0, 1.6666666666666667], [1.0761421319796953, 1.0, 0.3333333333333333], [1.0761421319796953, 1.0, 0.6666666666666666], [1.0761421319796953, 1.0, 1.0], [1.0761421319796953, 1.0, 1.3333333333333333], [1.0761421319796953, 1.0, 1.6666666666666667], [1.0761421319796953, 2.0, 0.3333333333333333], [1.0761421319796953, 2.0, 0.6666666666666666], [1.0761421319796953, 2.0, 1.0], [1.0761421319796953, 2.0, 1.3333333333333333], [1.0761421319796953, 2.0, 1.6666666666666667], [1.0253807106598984, 0.0, 0.3333333333333333], [1.0253807106598984, 0.0, 0.6666666666666666], [1.0253807106598984, 0.0, 1.0], [1.0253807106598984, 0.0, 1.3333333333333333], [1.0253807106598984, 0.0, 1.6666666666666667], [1.0253807106598984, 1.0, 0.3333333333333333], [1.0253807106598984, 1.0, 0.6666666666666666], [1.0253807106598984, 1.0, 1.0], [1.0253807106598984, 1.0, 1.3333333333333333], [1.0253807106598984, 1.0, 1.6666666666666667], [1.0253807106598984, 2.0, 0.3333333333333333], [1.0253807106598984, 2.0, 0.6666666666666666], [1.0253807106598984, 2.0, 1.0], [1.0253807106598984, 2.0, 1.3333333333333333], [1.0253807106598984, 2.0, 1.6666666666666667], [0.9746192893401016, 0.0, 0.3333333333333333], [0.9746192893401016, 0.0, 0.6666666666666666], [0.9746192893401016, 0.0, 1.0], [0.9746192893401016, 0.0, 1.3333333333333333], [0.9746192893401016, 0.0, 1.6666666666666667], [0.9746192893401016, 1.0, 0.3333333333333333], [0.9746192893401016, 1.0, 0.6666666666666666], [0.9746192893401016, 1.0, 1.0], [0.9746192893401016, 1.0, 1.3333333333333333], [0.9746192893401016, 1.0, 1.6666666666666667], [0.9746192893401016, 2.0, 0.3333333333333333], [0.9746192893401016, 2.0, 0.6666666666666666], [0.9746192893401016, 2.0, 1.0], [0.9746192893401016, 2.0, 1.3333333333333333], [0.9746192893401016, 2.0, 1.6666666666666667], [0.9069373942470389, 0.0, 0.3333333333333333], [0.9069373942470389, 0.0, 0.6666666666666666], [0.9069373942470389, 0.0, 1.0], [0.9069373942470389, 0.0, 1.3333333333333333], [0.9069373942470389, 0.0, 1.6666666666666667], [0.9069373942470389, 1.0, 0.3333333333333333], [0.9069373942470389, 1.0, 0.6666666666666666], [0.9069373942470389, 1.0, 1.0], [0.9069373942470389, 1.0, 1.3333333333333333], [0.9069373942470389, 1.0, 1.6666666666666667], [0.9069373942470389, 2.0, 0.3333333333333333], [0.9069373942470389, 2.0, 0.6666666666666666], [0.9069373942470389, 2.0, 1.0], [0.9069373942470389, 2.0, 1.3333333333333333], [0.9069373942470389, 2.0, 1.6666666666666667]]\n",
      "[[1.07614213 0.         0.33333333]\n",
      " [1.07614213 0.         0.66666667]\n",
      " [1.07614213 0.         1.        ]\n",
      " [1.07614213 0.         1.33333333]\n",
      " [1.07614213 0.         1.66666667]\n",
      " [1.07614213 1.         0.33333333]\n",
      " [1.07614213 1.         0.66666667]\n",
      " [1.07614213 1.         1.        ]\n",
      " [1.07614213 1.         1.33333333]\n",
      " [1.07614213 1.         1.66666667]\n",
      " [1.07614213 2.         0.33333333]\n",
      " [1.07614213 2.         0.66666667]\n",
      " [1.07614213 2.         1.        ]\n",
      " [1.07614213 2.         1.33333333]\n",
      " [1.07614213 2.         1.66666667]\n",
      " [1.02538071 0.         0.33333333]\n",
      " [1.02538071 0.         0.66666667]\n",
      " [1.02538071 0.         1.        ]\n",
      " [1.02538071 0.         1.33333333]\n",
      " [1.02538071 0.         1.66666667]\n",
      " [1.02538071 1.         0.33333333]\n",
      " [1.02538071 1.         0.66666667]\n",
      " [1.02538071 1.         1.        ]\n",
      " [1.02538071 1.         1.33333333]\n",
      " [1.02538071 1.         1.66666667]\n",
      " [1.02538071 2.         0.33333333]\n",
      " [1.02538071 2.         0.66666667]\n",
      " [1.02538071 2.         1.        ]\n",
      " [1.02538071 2.         1.33333333]\n",
      " [1.02538071 2.         1.66666667]\n",
      " [0.97461929 0.         0.33333333]\n",
      " [0.97461929 0.         0.66666667]\n",
      " [0.97461929 0.         1.        ]\n",
      " [0.97461929 0.         1.33333333]\n",
      " [0.97461929 0.         1.66666667]\n",
      " [0.97461929 1.         0.33333333]\n",
      " [0.97461929 1.         0.66666667]\n",
      " [0.97461929 1.         1.        ]\n",
      " [0.97461929 1.         1.33333333]\n",
      " [0.97461929 1.         1.66666667]\n",
      " [0.97461929 2.         0.33333333]\n",
      " [0.97461929 2.         0.66666667]\n",
      " [0.97461929 2.         1.        ]\n",
      " [0.97461929 2.         1.33333333]\n",
      " [0.97461929 2.         1.66666667]\n",
      " [0.90693739 0.         0.33333333]\n",
      " [0.90693739 0.         0.66666667]\n",
      " [0.90693739 0.         1.        ]\n",
      " [0.90693739 0.         1.33333333]\n",
      " [0.90693739 0.         1.66666667]\n",
      " [0.90693739 1.         0.33333333]\n",
      " [0.90693739 1.         0.66666667]\n",
      " [0.90693739 1.         1.        ]\n",
      " [0.90693739 1.         1.33333333]\n",
      " [0.90693739 1.         1.66666667]\n",
      " [0.90693739 2.         0.33333333]\n",
      " [0.90693739 2.         0.66666667]\n",
      " [0.90693739 2.         1.        ]\n",
      " [0.90693739 2.         1.33333333]\n",
      " [0.90693739 2.         1.66666667]]\n",
      "[[0.5741456642373223, 0.8814814814814815], [0.6598599266048748, 0.8955092592592592], [0.7756578554928267, 0.9097222222222223], [0.9407503103072674, 0.9247453703703704], [1.1951197389741843, 0.9400925925925926], [0.8026069896150227, 0.93125], [0.9224284945010854, 0.9399305555555556], [1.0843047033511548, 0.9486111111111111], [1.3150899625506725, 0.9560185185185185], [1.6706763513585288, 0.9664351851851851], [1.0310683149927233, 0.961574074074074], [1.1849970623972963, 0.9664351851851851], [1.3929515512094832, 0.9715277777777779], [1.6894279805227543, 0.9766666666666667], [2.1462329637428734, 0.9819444444444445], [0.5601138106549588, 0.9148148148148149], [0.6372066380832612, 0.9287037037037037], [0.7389079962444444, 0.9428240740740741], [0.8792379719673439, 0.9574074074074075], [1.085368613982662, 0.9724537037037037], [0.7831755035802798, 0.9671296296296297], [0.8909720400690643, 0.9756944444444444], [1.033186330627797, 0.9842592592592593], [1.2293969457103238, 0.9930555555555556], [1.517617036297983, 1.0020833333333334], [1.0062535392188345, 0.9988425925925926], [1.144754765330895, 1.0040046296296297], [1.3274532251118862, 1.0091898148148148], [1.5795722621665371, 1.0143518518518517], [1.9498883384118313, 1.0195601851851852], [0.5466980773615017, 0.9470601851851852], [0.6159748387587055, 0.9606481481481481], [0.7053547717045532, 0.9743055555555555], [0.8250749517685675, 0.9886574074074074], [0.9937464607811652, 1.0032407407407409], [0.7646183527035341, 1.001851851851852], [0.8615077623802181, 1.0103240740740742], [0.9865156273109617, 1.018888888888889], [1.1539573471527316, 1.0276064814814814], [1.3898611441370108, 1.0363425925925926], [0.9825369937742434, 1.0352083333333333], [1.1070406860017306, 1.0402777777777779], [1.2676764829173701, 1.0453703703703703], [1.482841376808219, 1.050462962962963], [1.7859774617641793, 1.0555555555555556], [0.5297049241412108, 0.988287037037037], [0.5896565333673262, 1.0011574074074074], [0.6649098249940553, 1.0145833333333334], [0.7621816541604053, 1.0282407407407408], [0.8927909840519632, 1.042361111111111], [0.7410962855464227, 1.0460648148148148], [0.8249736269465192, 1.0543981481481481], [0.9302582884113003, 1.0627314814814814], [1.0663489643214055, 1.0712962962962962], [1.2490801095288642, 1.0798611111111112], [0.952489281222958, 1.0814814814814815], [1.0602907205257124, 1.0863425925925927], [1.1956067518285451, 1.0914351851851851], [1.3705162744824058, 1.0967592592592592], [1.605370869277088, 1.1018518518518519]]\n",
      "[[0.57414566 0.88148148]\n",
      " [0.65985993 0.89550926]\n",
      " [0.77565786 0.90972222]\n",
      " [0.94075031 0.92474537]\n",
      " [1.19511974 0.94009259]\n",
      " [0.80260699 0.93125   ]\n",
      " [0.92242849 0.93993056]\n",
      " [1.0843047  0.94861111]\n",
      " [1.31508996 0.95601852]\n",
      " [1.67067635 0.96643519]\n",
      " [1.03106831 0.96157407]\n",
      " [1.18499706 0.96643519]\n",
      " [1.39295155 0.97152778]\n",
      " [1.68942798 0.97666667]\n",
      " [2.14623296 0.98194444]\n",
      " [0.56011381 0.91481481]\n",
      " [0.63720664 0.9287037 ]\n",
      " [0.738908   0.94282407]\n",
      " [0.87923797 0.95740741]\n",
      " [1.08536861 0.9724537 ]\n",
      " [0.7831755  0.96712963]\n",
      " [0.89097204 0.97569444]\n",
      " [1.03318633 0.98425926]\n",
      " [1.22939695 0.99305556]\n",
      " [1.51761704 1.00208333]\n",
      " [1.00625354 0.99884259]\n",
      " [1.14475477 1.00400463]\n",
      " [1.32745323 1.00918981]\n",
      " [1.57957226 1.01435185]\n",
      " [1.94988834 1.01956019]\n",
      " [0.54669808 0.94706019]\n",
      " [0.61597484 0.96064815]\n",
      " [0.70535477 0.97430556]\n",
      " [0.82507495 0.98865741]\n",
      " [0.99374646 1.00324074]\n",
      " [0.76461835 1.00185185]\n",
      " [0.86150776 1.01032407]\n",
      " [0.98651563 1.01888889]\n",
      " [1.15395735 1.02760648]\n",
      " [1.38986114 1.03634259]\n",
      " [0.98253699 1.03520833]\n",
      " [1.10704069 1.04027778]\n",
      " [1.26767648 1.04537037]\n",
      " [1.48284138 1.05046296]\n",
      " [1.78597746 1.05555556]\n",
      " [0.52970492 0.98828704]\n",
      " [0.58965653 1.00115741]\n",
      " [0.66490982 1.01458333]\n",
      " [0.76218165 1.02824074]\n",
      " [0.89279098 1.04236111]\n",
      " [0.74109629 1.04606481]\n",
      " [0.82497363 1.05439815]\n",
      " [0.93025829 1.06273148]\n",
      " [1.06634896 1.0712963 ]\n",
      " [1.24908011 1.07986111]\n",
      " [0.95248928 1.08148148]\n",
      " [1.06029072 1.08634259]\n",
      " [1.19560675 1.09143519]\n",
      " [1.37051627 1.09675926]\n",
      " [1.60537087 1.10185185]]\n"
     ]
    }
   ],
   "source": [
    "'''>>>>> start CodeP2.4F22\n",
    "    V.P. Carey ME249, Fall 2022\n",
    "\n",
    "Intro to Neural Network Modeling \n",
    "Keras model for hybrid solar/fossil-fuel gas turbine power system'''\n",
    "\n",
    "#import useful packages\n",
    "import statistics\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#create input data array\n",
    "# meadian values of input variables\n",
    "'''Tmed = 293.\n",
    "gamed = 0.25\n",
    "qsmed = 1250.'''\n",
    "#T1(K), gamma, , qsol(kW):\n",
    "xdata = []\n",
    "xdata =  [[ 318.0, 0.0, 500.0], [ 318.0, 0.0, 1000.0]]\n",
    "xdata.append([ 318.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 318.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 318.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 318.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 318.0 , 0.5 , 2500.0 ])\n",
    "  \n",
    "xdata.append([ 303.0 , 0.0 , 500.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 1000.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 303.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 303.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 303.0 , 0.5 , 2500.0 ])\n",
    "  \n",
    "xdata.append([ 288.0 , 0.0 , 500.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 1000.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 288.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 288.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 288.0 , 0.5 , 2500.0 ])\n",
    "  \n",
    "xdata.append([ 268.0 , 0.0 , 500.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 1000.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 1500.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 2000.0 ])\n",
    "xdata.append([ 268.0 , 0.0 , 2500.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 500.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 1000.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 1500.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 2000.0 ])\n",
    "xdata.append([ 268.0 , 0.25 , 2500.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 500.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 1000.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 1500.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 2000.0 ])\n",
    "xdata.append([ 268.0 , 0.5 , 2500.0 ])\n",
    "\n",
    "\n",
    "\n",
    "'''#convert to:\n",
    "xdata =  [[ 318.0/Tmed , 0.0/gamed , 500.0/qsmed ], [ 318.0/Tmed , 0.0/gamed , 1000.0/qsmed ]]\n",
    "xdata.append([ 318.0/Tmed  , 0.0/gamed , 1500.0/qsmed ])\n",
    "xdata.append([ 318.0/Tmed  , 0.0/gamed , 2000.0/qsmed ])\n",
    "xdata.append([ 318.0/Tmed  , 0.0/gamed , 2500.0/qsmed ])'''\n",
    "\n",
    "t1Values = []\n",
    "gammaValues = []\n",
    "qsolValues = []\n",
    "\n",
    "for i in range(len(xdata)):\n",
    "    t1Values.append(xdata[i][0])\n",
    "    gammaValues.append(xdata[i][1])\n",
    "    qsolValues.append(xdata[i][2])\n",
    "\n",
    "tmed = statistics.median(t1Values)\n",
    "gamed = statistics.median(gammaValues)\n",
    "qsmed = statistics.median(qsolValues)\n",
    "    \n",
    "for i in range(len(xdata)):\n",
    "    xdata[i][0] = xdata[i][0] / tmed\n",
    "    xdata[i][1] = xdata[i][1] / gamed\n",
    "    xdata[i][2] = xdata[i][2] / qsmed\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "print (xdata)\n",
    "print (xarray)\n",
    "# meadian values of output variables\n",
    "'''almed = 60.\n",
    "efmed = 0.4'''\n",
    "# alpha, effsys\n",
    "ydata = []\n",
    "ydata =  [[ 35.1316, 0.3808], [ 40.3764, 0.38686]]\n",
    "ydata.append([ 47.4620 , 0.3930 ])\n",
    "ydata.append([ 57.5639 , 0.39949 ])\n",
    "ydata.append([ 73.1286 , 0.40612 ])\n",
    "ydata.append([ 49.1110 , 0.4023 ])\n",
    "ydata.append([ 56.4428 , 0.40605 ])\n",
    "ydata.append([ 66.3479 , 0.4098 ])\n",
    "ydata.append([ 80.4695 , 0.413 ])\n",
    "ydata.append([ 102.2276 , 0.4175 ])\n",
    "ydata.append([ 63.0904 , 0.41540 ])\n",
    "ydata.append([ 72.5092 , 0.4175 ])\n",
    "ydata.append([ 85.2338, 0.4197 ])\n",
    "ydata.append([ 103.3750 , 0.42192 ])\n",
    "ydata.append([ 131.3266 , 0.4242 ])\n",
    "  \n",
    "ydata.append([ 34.273 , 0.3952 ])\n",
    "ydata.append([ 38.99026 , 0.4012 ])\n",
    "ydata.append([ 45.2133, 0.4073 ])\n",
    "ydata.append([ 53.8000 , 0.4136 ])\n",
    "ydata.append([ 66.4130 , 0.4201 ])\n",
    "ydata.append([ 47.922 , 0.4178 ])\n",
    "ydata.append([ 54.518 , 0.4215 ])\n",
    "ydata.append([ 63.220 , 0.4252 ])\n",
    "ydata.append([ 75.226 , 0.4290 ])\n",
    "ydata.append([ 92.862 , 0.4329 ])\n",
    "ydata.append([ 61.572 , 0.4315 ])\n",
    "ydata.append([ 70.0468 , 0.43373 ])\n",
    "ydata.append([ 81.226 , 0.43597 ])\n",
    "ydata.append([ 96.653 , 0.4382 ])\n",
    "ydata.append([ 119.3124 , 0.44045 ])\n",
    "  \n",
    "ydata.append([ 33.4521 , 0.40913 ])\n",
    "ydata.append([ 37.6911, 0.4150 ])\n",
    "ydata.append([ 43.1602 , 0.4209 ])\n",
    "ydata.append([ 50.4858 , 0.4271 ])\n",
    "ydata.append([ 60.8067 , 0.4334 ])\n",
    "ydata.append([ 46.7865 , 0.4328 ])\n",
    "ydata.append([ 52.7151 , 0.43646 ])\n",
    "ydata.append([ 60.36425 , 0.44016 ])\n",
    "ydata.append([ 70.6099 , 0.443926 ])\n",
    "ydata.append([ 85.0447 , 0.4477 ])\n",
    "ydata.append([ 60.1208 , 0.44721 ])\n",
    "ydata.append([ 67.7391 , 0.44940 ])\n",
    "ydata.append([ 77.56830 , 0.4516 ])\n",
    "ydata.append([ 90.73410 , 0.4538 ])\n",
    "ydata.append([ 109.2828 , 0.4560 ])\n",
    "  \n",
    "ydata.append([ 32.4123 , 0.42694 ])\n",
    "ydata.append([ 36.0807 , 0.4325 ])\n",
    "ydata.append([ 40.6854 , 0.4383 ])\n",
    "ydata.append([ 46.6374 , 0.4442 ])\n",
    "ydata.append([ 54.6293 , 0.4503 ])\n",
    "ydata.append([ 45.3472 , 0.4519 ])\n",
    "ydata.append([ 50.4796 , 0.4555 ])\n",
    "ydata.append([ 56.9219 , 0.4591 ])\n",
    "ydata.append([ 65.2492 , 0.4628 ])\n",
    "ydata.append([ 76.4304 , 0.4665 ])\n",
    "ydata.append([ 58.2822 , 0.4672 ])\n",
    "ydata.append([ 64.8785 , 0.4693 ])\n",
    "ydata.append([ 73.1584 , 0.4715 ])\n",
    "ydata.append([ 83.8610 , 0.4738 ])\n",
    "ydata.append([ 98.2316 , 0.4760 ])\n",
    "\n",
    "'''#convert to:\n",
    "ydata =  [[ 35.1316/almed , 0.3808/efmed ], [ 40.3764/almed , 0.38686/efmed ]]\n",
    "ydata.append([ 47.4620/almed , 0.3930/efmed ])\n",
    "ydata.append([ 57.5639/almed , 0.39949/efmed ])\n",
    "ydata.append([ 73.1286/almed , 0.40612/efmed ])'''\n",
    "\n",
    "alphaValues = []\n",
    "nsysValues = []\n",
    "\n",
    "for i in range(len(ydata)):\n",
    "    alphaValues.append(ydata[i][0])\n",
    "    nsysValues.append(ydata[i][1])\n",
    "\n",
    "almed = statistics.median(alphaValues)\n",
    "efmed = statistics.median(nsysValues)\n",
    "    \n",
    "\n",
    "for i in range(len(ydata)):\n",
    "    ydata[i][0] = ydata[i][0] / almed\n",
    "    ydata[i][1] = ydata[i][1] / efmed\n",
    "\n",
    "yarray= np.array(ydata)\n",
    "print (ydata)\n",
    "print (yarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e269f49-0273-46ee-b534-7b8089d8bff0",
   "metadata": {},
   "source": [
    "### Task 2.4 Data Table\n",
    "\n",
    "**Iteration one: the baseline neural network with the relu activation function changed to ELU.**  \n",
    "* Minimum loss = 0.042138777673244476  \n",
    "* Convergence time in epochs: 600  \n",
    "\n",
    "**Iteration Two: the baseline neural network with an added layer and the number of neurons in the layers set to 12, 24, 12, 12, 2 (activation functions will be relu for all, as in the baseline).**  \n",
    "* Minimum loss =   0.037394069135189056  \n",
    "* Convergence time in epochs:  597  \n",
    "\n",
    "**Iteration Three: the baseline neural network with the numbers of neurons changed to 8, 16, 8, 2.**   \n",
    "* Minimum loss =   0.04750993102788925  \n",
    "* Convergence time in epochs:  598  \n",
    "\n",
    "**Iteration Four:  the baseline neural network with the number of neurons in the layers set to 20, 40, 20, 2.**   \n",
    "* Minimum loss = 0.04378645494580269    \n",
    "* Convergence time in epochs: 625\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "798f538f-cac3-46c8-ab79-c7fda9b0821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "\n",
    "#As seen below, we have created four dense layers. \n",
    "#A dense layer is a layer in neural network that’s fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 1 in our case. \n",
    "#The activation function we have chosen is elu, which stands for exponential linear unit. .\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 1.2\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(20, activation=K.relu, input_shape=[3],  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(40, activation=K.relu,  kernel_initializer=initializer),\n",
    "    keras.layers.Dense(20, activation =K.relu, kernel_initializer = initializer),\n",
    "    keras.layers.Dense(2,  kernel_initializer=initializer)\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e6d1471-965c-4f25-8821-d91ba1009dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean squared error. After the compilation of the model, we’ll use the fit method with ~500 epochs.\n",
    "#Number of epochs can be varied.\n",
    "\n",
    "#from tf.keras import optimizers\n",
    "rms = keras.optimizers.RMSprop(0.001)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d8619e8-06a6-4abd-80c7-2736f7ed041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0756\n",
      "Epoch 2/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0624\n",
      "Epoch 3/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0757\n",
      "Epoch 4/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0724\n",
      "Epoch 5/600\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0596\n",
      "Epoch 6/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0930\n",
      "Epoch 7/600\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0783\n",
      "Epoch 8/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0714\n",
      "Epoch 9/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0710\n",
      "Epoch 10/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0780\n",
      "Epoch 11/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0515\n",
      "Epoch 12/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0784\n",
      "Epoch 13/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0776\n",
      "Epoch 14/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0667\n",
      "Epoch 15/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0878\n",
      "Epoch 16/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0667\n",
      "Epoch 17/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0710\n",
      "Epoch 18/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0743\n",
      "Epoch 19/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0625\n",
      "Epoch 20/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0677\n",
      "Epoch 21/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0623\n",
      "Epoch 22/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0603\n",
      "Epoch 23/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0718\n",
      "Epoch 24/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0575\n",
      "Epoch 25/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0709\n",
      "Epoch 26/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0789\n",
      "Epoch 27/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0776\n",
      "Epoch 28/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0869\n",
      "Epoch 29/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0753\n",
      "Epoch 30/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0725\n",
      "Epoch 31/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0667\n",
      "Epoch 32/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0800\n",
      "Epoch 33/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0666\n",
      "Epoch 34/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0693\n",
      "Epoch 35/600\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.0727\n",
      "Epoch 36/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0778\n",
      "Epoch 37/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0666\n",
      "Epoch 38/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0513\n",
      "Epoch 39/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0724\n",
      "Epoch 40/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0824\n",
      "Epoch 41/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0583\n",
      "Epoch 42/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0697\n",
      "Epoch 43/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0667\n",
      "Epoch 44/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0501\n",
      "Epoch 45/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0511\n",
      "Epoch 46/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0975\n",
      "Epoch 47/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0821\n",
      "Epoch 48/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0700\n",
      "Epoch 49/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0601\n",
      "Epoch 50/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0650\n",
      "Epoch 51/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0735\n",
      "Epoch 52/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0527\n",
      "Epoch 53/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0588\n",
      "Epoch 54/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0688\n",
      "Epoch 55/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0847\n",
      "Epoch 56/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0793\n",
      "Epoch 57/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0690\n",
      "Epoch 58/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0725\n",
      "Epoch 59/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0650\n",
      "Epoch 60/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0614\n",
      "Epoch 61/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0774\n",
      "Epoch 62/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0608\n",
      "Epoch 63/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0598\n",
      "Epoch 64/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0613\n",
      "Epoch 65/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0797\n",
      "Epoch 66/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0675\n",
      "Epoch 67/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0683\n",
      "Epoch 68/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0891\n",
      "Epoch 69/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0639\n",
      "Epoch 70/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0660\n",
      "Epoch 71/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0638\n",
      "Epoch 72/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0700\n",
      "Epoch 73/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0806\n",
      "Epoch 74/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0702\n",
      "Epoch 75/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0588\n",
      "Epoch 76/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0551\n",
      "Epoch 77/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0775\n",
      "Epoch 78/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0728\n",
      "Epoch 79/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0562\n",
      "Epoch 80/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0591\n",
      "Epoch 81/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0615\n",
      "Epoch 82/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0583\n",
      "Epoch 83/600\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0872\n",
      "Epoch 84/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0785\n",
      "Epoch 85/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0534\n",
      "Epoch 86/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0719\n",
      "Epoch 87/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0637\n",
      "Epoch 88/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0672\n",
      "Epoch 89/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0825\n",
      "Epoch 90/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0599\n",
      "Epoch 91/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0705\n",
      "Epoch 92/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0676\n",
      "Epoch 93/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0589\n",
      "Epoch 94/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0802\n",
      "Epoch 95/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0685\n",
      "Epoch 96/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0681\n",
      "Epoch 97/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0588\n",
      "Epoch 98/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0651\n",
      "Epoch 99/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0798\n",
      "Epoch 100/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0661\n",
      "Epoch 101/600\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.0659\n",
      "Epoch 102/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0723\n",
      "Epoch 103/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0709\n",
      "Epoch 104/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0703\n",
      "Epoch 105/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0535\n",
      "Epoch 106/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0438\n",
      "Epoch 107/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0736\n",
      "Epoch 108/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0695\n",
      "Epoch 109/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0671\n",
      "Epoch 110/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0619\n",
      "Epoch 111/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0768\n",
      "Epoch 112/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0701\n",
      "Epoch 113/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0589\n",
      "Epoch 114/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0704\n",
      "Epoch 115/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0700\n",
      "Epoch 116/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0614\n",
      "Epoch 117/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0566\n",
      "Epoch 118/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0587\n",
      "Epoch 119/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0723\n",
      "Epoch 120/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0737\n",
      "Epoch 121/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0569\n",
      "Epoch 122/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0638\n",
      "Epoch 123/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0717\n",
      "Epoch 124/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0614\n",
      "Epoch 125/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0803\n",
      "Epoch 126/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0773\n",
      "Epoch 127/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0562\n",
      "Epoch 128/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0454\n",
      "Epoch 129/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0537\n",
      "Epoch 130/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0614\n",
      "Epoch 131/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0609\n",
      "Epoch 132/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0843\n",
      "Epoch 133/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0691\n",
      "Epoch 134/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0562\n",
      "Epoch 135/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0476\n",
      "Epoch 136/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0905\n",
      "Epoch 137/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0820\n",
      "Epoch 138/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0642\n",
      "Epoch 139/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0602\n",
      "Epoch 140/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0795\n",
      "Epoch 141/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0541\n",
      "Epoch 142/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0589\n",
      "Epoch 143/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0701\n",
      "Epoch 144/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0512\n",
      "Epoch 145/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0590\n",
      "Epoch 146/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0677\n",
      "Epoch 147/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0603\n",
      "Epoch 148/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0554\n",
      "Epoch 149/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0531\n",
      "Epoch 150/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0688\n",
      "Epoch 151/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0869\n",
      "Epoch 152/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0507\n",
      "Epoch 153/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0492\n",
      "Epoch 154/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0647\n",
      "Epoch 155/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0669\n",
      "Epoch 156/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0793\n",
      "Epoch 157/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0658\n",
      "Epoch 158/600\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.0690\n",
      "Epoch 159/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0668\n",
      "Epoch 160/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0604\n",
      "Epoch 161/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0613\n",
      "Epoch 162/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0566\n",
      "Epoch 163/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0603\n",
      "Epoch 164/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0635\n",
      "Epoch 165/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0617\n",
      "Epoch 166/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0645\n",
      "Epoch 167/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0609\n",
      "Epoch 168/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0665\n",
      "Epoch 169/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0494\n",
      "Epoch 170/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0624\n",
      "Epoch 171/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0718\n",
      "Epoch 172/600\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0520\n",
      "Epoch 173/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0725\n",
      "Epoch 174/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0574\n",
      "Epoch 175/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0609\n",
      "Epoch 176/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0558\n",
      "Epoch 177/600\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0766\n",
      "Epoch 178/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0588\n",
      "Epoch 179/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0602\n",
      "Epoch 180/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0814\n",
      "Epoch 181/600\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0571\n",
      "Epoch 182/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0606\n",
      "Epoch 183/600\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.0647\n",
      "Epoch 184/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0499\n",
      "Epoch 185/600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0515\n",
      "Epoch 186/600\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0648Restoring model weights from the end of the best epoch: 106.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0673\n",
      "Epoch 186: early stopping\n",
      "best epoch =  106\n",
      "smallest loss = 0.04378645494580269\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 80, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(xarray,yarray,epochs=600,callbacks=[es])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe4633-dcde-4349-b5aa-996425f1af39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
